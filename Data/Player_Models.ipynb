{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This notebook is used to look at individual player performances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, FunctionTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer,  make_column_selector as selector\n",
    "\n",
    "\n",
    "from sklearn.metrics import plot_confusion_matrix, recall_score,\\\n",
    "    accuracy_score, precision_score, f1_score\n",
    "\n",
    "from sklearn.dummy import DummyRegressor\n",
    "\n",
    "from sklearn.metrics import plot_roc_curve\n",
    "\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "from imblearn.pipeline import Pipeline as ImPipeline\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LinearRegression,ElasticNet,Ridge,Lasso\n",
    "from sklearn.svm import SVR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.losses import MeanSquaredLogarithmicError"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tom Brady "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These stats were gathered for Tom Brady using the "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./tb_stats.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 83 entries, 0 to 82\n",
      "Data columns (total 61 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   Rk           83 non-null     float64\n",
      " 1   Year         83 non-null     int64  \n",
      " 2   Date         83 non-null     object \n",
      " 3   G#           83 non-null     float64\n",
      " 4   Week         83 non-null     float64\n",
      " 5   Age          83 non-null     float64\n",
      " 6   Tm           83 non-null     object \n",
      " 7   Home         83 non-null     float64\n",
      " 8   Opp          83 non-null     object \n",
      " 9   Cmp          83 non-null     float64\n",
      " 10  Att          83 non-null     float64\n",
      " 11  Cmp%         83 non-null     float64\n",
      " 12  Yds          83 non-null     float64\n",
      " 13  TD_left      83 non-null     float64\n",
      " 14  Int          83 non-null     float64\n",
      " 15  Rate         83 non-null     float64\n",
      " 16  Sk           83 non-null     float64\n",
      " 17  Sk_Yds       83 non-null     float64\n",
      " 18  Y/A          83 non-null     float64\n",
      " 19  AY/A         83 non-null     float64\n",
      " 20  Ru_Att       83 non-null     float64\n",
      " 21  Ru_Yds       83 non-null     float64\n",
      " 22  Ru_Y/A       62 non-null     float64\n",
      " 23  Ru_TB        83 non-null     float64\n",
      " 24  Re_Tgt       83 non-null     float64\n",
      " 25  Re_Rec       83 non-null     float64\n",
      " 26  Re_Yds       83 non-null     float64\n",
      " 27  Re_Y/R       1 non-null      float64\n",
      " 28  Re_TD        83 non-null     float64\n",
      " 29  Re_Ctch%     0 non-null      float64\n",
      " 30  Re_Y/Tgt     1 non-null      float64\n",
      " 31  Total_NP_TD  83 non-null     float64\n",
      " 32  Pts          83 non-null     float64\n",
      " 33  Fmb          83 non-null     float64\n",
      " 34  FL           83 non-null     float64\n",
      " 35  Dome         83 non-null     int64  \n",
      " 36  Total        83 non-null     float64\n",
      " 37  RANK         83 non-null     int64  \n",
      " 38  NAME         83 non-null     object \n",
      " 39  PTS          83 non-null     int64  \n",
      " 40  FPTS         83 non-null     int64  \n",
      " 41  SACKS        83 non-null     int64  \n",
      " 42  INT          83 non-null     int64  \n",
      " 43  TO           83 non-null     int64  \n",
      " 44  PTS.1        83 non-null     int64  \n",
      " 45  PLAYS        83 non-null     int64  \n",
      " 46  YDS          83 non-null     int64  \n",
      " 47  PASS YDS     83 non-null     int64  \n",
      " 48  PASS ATT     83 non-null     int64  \n",
      " 49  PASS COMP    83 non-null     int64  \n",
      " 50  PASS TD      83 non-null     int64  \n",
      " 51  RUSH YDS     83 non-null     int64  \n",
      " 52  RUSH ATT     83 non-null     int64  \n",
      " 53  RUSH TD      83 non-null     int64  \n",
      " 54  TD_right     83 non-null     int64  \n",
      " 55  RZ ATT       83 non-null     int64  \n",
      " 56  RZ TD        83 non-null     int64  \n",
      " 57  RZ TD%       83 non-null     float64\n",
      " 58  1D           83 non-null     int64  \n",
      " 59  3D%          83 non-null     float64\n",
      " 60  4D%          83 non-null     float64\n",
      "dtypes: float64(35), int64(22), object(4)\n",
      "memory usage: 39.7+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rk</th>\n",
       "      <th>Year</th>\n",
       "      <th>Date</th>\n",
       "      <th>G#</th>\n",
       "      <th>Week</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tm</th>\n",
       "      <th>Home</th>\n",
       "      <th>Opp</th>\n",
       "      <th>Cmp</th>\n",
       "      <th>...</th>\n",
       "      <th>RUSH YDS</th>\n",
       "      <th>RUSH ATT</th>\n",
       "      <th>RUSH TD</th>\n",
       "      <th>TD_right</th>\n",
       "      <th>RZ ATT</th>\n",
       "      <th>RZ TD</th>\n",
       "      <th>RZ TD%</th>\n",
       "      <th>1D</th>\n",
       "      <th>3D%</th>\n",
       "      <th>4D%</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>273.0</td>\n",
       "      <td>2017</td>\n",
       "      <td>2017-09-07</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>40.035</td>\n",
       "      <td>NWE</td>\n",
       "      <td>1.0</td>\n",
       "      <td>KAN</td>\n",
       "      <td>16.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1890</td>\n",
       "      <td>443</td>\n",
       "      <td>15</td>\n",
       "      <td>39</td>\n",
       "      <td>51</td>\n",
       "      <td>28</td>\n",
       "      <td>54.9</td>\n",
       "      <td>352</td>\n",
       "      <td>40.1</td>\n",
       "      <td>52.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>274.0</td>\n",
       "      <td>2017</td>\n",
       "      <td>2017-09-17</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>40.045</td>\n",
       "      <td>NWE</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NOR</td>\n",
       "      <td>30.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1787</td>\n",
       "      <td>406</td>\n",
       "      <td>11</td>\n",
       "      <td>36</td>\n",
       "      <td>48</td>\n",
       "      <td>25</td>\n",
       "      <td>52.1</td>\n",
       "      <td>308</td>\n",
       "      <td>41.0</td>\n",
       "      <td>33.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>275.0</td>\n",
       "      <td>2017</td>\n",
       "      <td>2017-09-24</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>40.052</td>\n",
       "      <td>NWE</td>\n",
       "      <td>1.0</td>\n",
       "      <td>HOU</td>\n",
       "      <td>25.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1747</td>\n",
       "      <td>440</td>\n",
       "      <td>14</td>\n",
       "      <td>48</td>\n",
       "      <td>54</td>\n",
       "      <td>33</td>\n",
       "      <td>61.1</td>\n",
       "      <td>301</td>\n",
       "      <td>35.3</td>\n",
       "      <td>62.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>276.0</td>\n",
       "      <td>2017</td>\n",
       "      <td>2017-10-01</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>40.059</td>\n",
       "      <td>NWE</td>\n",
       "      <td>1.0</td>\n",
       "      <td>CAR</td>\n",
       "      <td>32.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1409</td>\n",
       "      <td>353</td>\n",
       "      <td>7</td>\n",
       "      <td>34</td>\n",
       "      <td>44</td>\n",
       "      <td>21</td>\n",
       "      <td>47.7</td>\n",
       "      <td>282</td>\n",
       "      <td>37.9</td>\n",
       "      <td>35.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>277.0</td>\n",
       "      <td>2017</td>\n",
       "      <td>2017-10-05</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>40.063</td>\n",
       "      <td>NWE</td>\n",
       "      <td>0.0</td>\n",
       "      <td>TAM</td>\n",
       "      <td>30.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1880</td>\n",
       "      <td>440</td>\n",
       "      <td>18</td>\n",
       "      <td>44</td>\n",
       "      <td>53</td>\n",
       "      <td>29</td>\n",
       "      <td>54.7</td>\n",
       "      <td>327</td>\n",
       "      <td>48.1</td>\n",
       "      <td>22.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 61 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Rk  Year        Date   G#  Week     Age   Tm  Home  Opp   Cmp  ...  \\\n",
       "0  273.0  2017  2017-09-07  1.0   1.0  40.035  NWE   1.0  KAN  16.0  ...   \n",
       "1  274.0  2017  2017-09-17  2.0   2.0  40.045  NWE   0.0  NOR  30.0  ...   \n",
       "2  275.0  2017  2017-09-24  3.0   3.0  40.052  NWE   1.0  HOU  25.0  ...   \n",
       "3  276.0  2017  2017-10-01  4.0   4.0  40.059  NWE   1.0  CAR  32.0  ...   \n",
       "4  277.0  2017  2017-10-05  5.0   5.0  40.063  NWE   0.0  TAM  30.0  ...   \n",
       "\n",
       "   RUSH YDS  RUSH ATT  RUSH TD  TD_right  RZ ATT  RZ TD  RZ TD%   1D   3D%  \\\n",
       "0      1890       443       15        39      51     28    54.9  352  40.1   \n",
       "1      1787       406       11        36      48     25    52.1  308  41.0   \n",
       "2      1747       440       14        48      54     33    61.1  301  35.3   \n",
       "3      1409       353        7        34      44     21    47.7  282  37.9   \n",
       "4      1880       440       18        44      53     29    54.7  327  48.1   \n",
       "\n",
       "    4D%  \n",
       "0  52.9  \n",
       "1  33.3  \n",
       "2  62.5  \n",
       "3  35.0  \n",
       "4  22.2  \n",
       "\n",
       "[5 rows x 61 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas_profiling import ProfileReport"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "profile = ProfileReport(df, title=\"QBs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#profile.to_notebook_iframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rk</th>\n",
       "      <th>Year</th>\n",
       "      <th>G#</th>\n",
       "      <th>Week</th>\n",
       "      <th>Age</th>\n",
       "      <th>Home</th>\n",
       "      <th>Cmp</th>\n",
       "      <th>Att</th>\n",
       "      <th>Cmp%</th>\n",
       "      <th>Yds</th>\n",
       "      <th>...</th>\n",
       "      <th>RUSH YDS</th>\n",
       "      <th>RUSH ATT</th>\n",
       "      <th>RUSH TD</th>\n",
       "      <th>TD_right</th>\n",
       "      <th>RZ ATT</th>\n",
       "      <th>RZ TD</th>\n",
       "      <th>RZ TD%</th>\n",
       "      <th>1D</th>\n",
       "      <th>3D%</th>\n",
       "      <th>4D%</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Rk</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.980590</td>\n",
       "      <td>0.135077</td>\n",
       "      <td>0.134844</td>\n",
       "      <td>0.985092</td>\n",
       "      <td>-0.046498</td>\n",
       "      <td>0.208034</td>\n",
       "      <td>0.218235</td>\n",
       "      <td>0.054054</td>\n",
       "      <td>0.070734</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.108005</td>\n",
       "      <td>-0.165325</td>\n",
       "      <td>0.052792</td>\n",
       "      <td>-0.067936</td>\n",
       "      <td>-0.014056</td>\n",
       "      <td>0.063924</td>\n",
       "      <td>0.062106</td>\n",
       "      <td>-0.109885</td>\n",
       "      <td>0.085507</td>\n",
       "      <td>0.230744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Year</th>\n",
       "      <td>0.980590</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.061693</td>\n",
       "      <td>-0.061698</td>\n",
       "      <td>0.999699</td>\n",
       "      <td>-0.055236</td>\n",
       "      <td>0.236149</td>\n",
       "      <td>0.242484</td>\n",
       "      <td>0.064499</td>\n",
       "      <td>0.091371</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.161226</td>\n",
       "      <td>-0.215983</td>\n",
       "      <td>-0.013860</td>\n",
       "      <td>-0.123106</td>\n",
       "      <td>-0.063719</td>\n",
       "      <td>0.012621</td>\n",
       "      <td>0.027217</td>\n",
       "      <td>-0.159172</td>\n",
       "      <td>0.093306</td>\n",
       "      <td>0.220464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>G#</th>\n",
       "      <td>0.135077</td>\n",
       "      <td>-0.061693</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.998630</td>\n",
       "      <td>-0.037241</td>\n",
       "      <td>0.043728</td>\n",
       "      <td>-0.126658</td>\n",
       "      <td>-0.105949</td>\n",
       "      <td>-0.048957</td>\n",
       "      <td>-0.093605</td>\n",
       "      <td>...</td>\n",
       "      <td>0.288906</td>\n",
       "      <td>0.278139</td>\n",
       "      <td>0.355925</td>\n",
       "      <td>0.298930</td>\n",
       "      <td>0.277307</td>\n",
       "      <td>0.284140</td>\n",
       "      <td>0.189121</td>\n",
       "      <td>0.273857</td>\n",
       "      <td>-0.019220</td>\n",
       "      <td>0.069353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Week</th>\n",
       "      <td>0.134844</td>\n",
       "      <td>-0.061698</td>\n",
       "      <td>0.998630</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.037221</td>\n",
       "      <td>0.038845</td>\n",
       "      <td>-0.134845</td>\n",
       "      <td>-0.115244</td>\n",
       "      <td>-0.050050</td>\n",
       "      <td>-0.100059</td>\n",
       "      <td>...</td>\n",
       "      <td>0.286071</td>\n",
       "      <td>0.276143</td>\n",
       "      <td>0.353815</td>\n",
       "      <td>0.300122</td>\n",
       "      <td>0.276797</td>\n",
       "      <td>0.282864</td>\n",
       "      <td>0.187354</td>\n",
       "      <td>0.270207</td>\n",
       "      <td>-0.024762</td>\n",
       "      <td>0.064446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Age</th>\n",
       "      <td>0.985092</td>\n",
       "      <td>0.999699</td>\n",
       "      <td>-0.037241</td>\n",
       "      <td>-0.037221</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.054377</td>\n",
       "      <td>0.233168</td>\n",
       "      <td>0.239951</td>\n",
       "      <td>0.063439</td>\n",
       "      <td>0.089154</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.154346</td>\n",
       "      <td>-0.209406</td>\n",
       "      <td>-0.005062</td>\n",
       "      <td>-0.115800</td>\n",
       "      <td>-0.056814</td>\n",
       "      <td>0.019770</td>\n",
       "      <td>0.031969</td>\n",
       "      <td>-0.152582</td>\n",
       "      <td>0.092977</td>\n",
       "      <td>0.222458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Home</th>\n",
       "      <td>-0.046498</td>\n",
       "      <td>-0.055236</td>\n",
       "      <td>0.043728</td>\n",
       "      <td>0.038845</td>\n",
       "      <td>-0.054377</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.096654</td>\n",
       "      <td>-0.097390</td>\n",
       "      <td>-0.033416</td>\n",
       "      <td>-0.047588</td>\n",
       "      <td>...</td>\n",
       "      <td>0.049819</td>\n",
       "      <td>0.062670</td>\n",
       "      <td>-0.016843</td>\n",
       "      <td>-0.028553</td>\n",
       "      <td>0.016639</td>\n",
       "      <td>0.003549</td>\n",
       "      <td>0.018192</td>\n",
       "      <td>0.049679</td>\n",
       "      <td>-0.193663</td>\n",
       "      <td>0.145605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Cmp</th>\n",
       "      <td>0.208034</td>\n",
       "      <td>0.236149</td>\n",
       "      <td>-0.126658</td>\n",
       "      <td>-0.134845</td>\n",
       "      <td>0.233168</td>\n",
       "      <td>-0.096654</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.807666</td>\n",
       "      <td>0.606008</td>\n",
       "      <td>0.767032</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.029138</td>\n",
       "      <td>0.041605</td>\n",
       "      <td>0.121216</td>\n",
       "      <td>0.032495</td>\n",
       "      <td>0.117018</td>\n",
       "      <td>0.079056</td>\n",
       "      <td>-0.017212</td>\n",
       "      <td>0.091688</td>\n",
       "      <td>0.214352</td>\n",
       "      <td>0.002511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Att</th>\n",
       "      <td>0.218235</td>\n",
       "      <td>0.242484</td>\n",
       "      <td>-0.105949</td>\n",
       "      <td>-0.115244</td>\n",
       "      <td>0.239951</td>\n",
       "      <td>-0.097390</td>\n",
       "      <td>0.807666</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.030870</td>\n",
       "      <td>0.558316</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.025004</td>\n",
       "      <td>0.026854</td>\n",
       "      <td>0.000637</td>\n",
       "      <td>-0.049268</td>\n",
       "      <td>0.060606</td>\n",
       "      <td>-0.001761</td>\n",
       "      <td>-0.084492</td>\n",
       "      <td>0.049291</td>\n",
       "      <td>0.123413</td>\n",
       "      <td>-0.108816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Cmp%</th>\n",
       "      <td>0.054054</td>\n",
       "      <td>0.064499</td>\n",
       "      <td>-0.048957</td>\n",
       "      <td>-0.050050</td>\n",
       "      <td>0.063439</td>\n",
       "      <td>-0.033416</td>\n",
       "      <td>0.606008</td>\n",
       "      <td>0.030870</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.561411</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.020199</td>\n",
       "      <td>0.032362</td>\n",
       "      <td>0.199296</td>\n",
       "      <td>0.116312</td>\n",
       "      <td>0.115350</td>\n",
       "      <td>0.135190</td>\n",
       "      <td>0.087613</td>\n",
       "      <td>0.096173</td>\n",
       "      <td>0.186627</td>\n",
       "      <td>0.154311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Yds</th>\n",
       "      <td>0.070734</td>\n",
       "      <td>0.091371</td>\n",
       "      <td>-0.093605</td>\n",
       "      <td>-0.100059</td>\n",
       "      <td>0.089154</td>\n",
       "      <td>-0.047588</td>\n",
       "      <td>0.767032</td>\n",
       "      <td>0.558316</td>\n",
       "      <td>0.561411</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.166622</td>\n",
       "      <td>0.169893</td>\n",
       "      <td>0.248432</td>\n",
       "      <td>0.216943</td>\n",
       "      <td>0.233722</td>\n",
       "      <td>0.230792</td>\n",
       "      <td>0.109590</td>\n",
       "      <td>0.247586</td>\n",
       "      <td>0.269464</td>\n",
       "      <td>0.112492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TD_left</th>\n",
       "      <td>0.118966</td>\n",
       "      <td>0.130219</td>\n",
       "      <td>-0.044436</td>\n",
       "      <td>-0.043991</td>\n",
       "      <td>0.129576</td>\n",
       "      <td>0.161573</td>\n",
       "      <td>0.242372</td>\n",
       "      <td>0.047316</td>\n",
       "      <td>0.348164</td>\n",
       "      <td>0.467253</td>\n",
       "      <td>...</td>\n",
       "      <td>0.253622</td>\n",
       "      <td>0.244680</td>\n",
       "      <td>0.234910</td>\n",
       "      <td>0.368652</td>\n",
       "      <td>0.322633</td>\n",
       "      <td>0.349228</td>\n",
       "      <td>0.211765</td>\n",
       "      <td>0.263795</td>\n",
       "      <td>0.325096</td>\n",
       "      <td>0.162639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Int</th>\n",
       "      <td>0.051058</td>\n",
       "      <td>0.042063</td>\n",
       "      <td>0.050528</td>\n",
       "      <td>0.047520</td>\n",
       "      <td>0.043311</td>\n",
       "      <td>0.042780</td>\n",
       "      <td>0.031495</td>\n",
       "      <td>0.090734</td>\n",
       "      <td>-0.071141</td>\n",
       "      <td>-0.116396</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.085813</td>\n",
       "      <td>-0.012721</td>\n",
       "      <td>-0.068013</td>\n",
       "      <td>0.010673</td>\n",
       "      <td>-0.015873</td>\n",
       "      <td>0.094067</td>\n",
       "      <td>0.262825</td>\n",
       "      <td>0.034359</td>\n",
       "      <td>0.083749</td>\n",
       "      <td>-0.054077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Rate</th>\n",
       "      <td>0.014633</td>\n",
       "      <td>0.024156</td>\n",
       "      <td>-0.043723</td>\n",
       "      <td>-0.042776</td>\n",
       "      <td>0.023336</td>\n",
       "      <td>0.071056</td>\n",
       "      <td>0.311031</td>\n",
       "      <td>-0.107847</td>\n",
       "      <td>0.691593</td>\n",
       "      <td>0.605887</td>\n",
       "      <td>...</td>\n",
       "      <td>0.213523</td>\n",
       "      <td>0.191172</td>\n",
       "      <td>0.277265</td>\n",
       "      <td>0.303396</td>\n",
       "      <td>0.259772</td>\n",
       "      <td>0.246374</td>\n",
       "      <td>0.079022</td>\n",
       "      <td>0.222420</td>\n",
       "      <td>0.224374</td>\n",
       "      <td>0.217468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sk</th>\n",
       "      <td>-0.197425</td>\n",
       "      <td>-0.176356</td>\n",
       "      <td>-0.117896</td>\n",
       "      <td>-0.122038</td>\n",
       "      <td>-0.179567</td>\n",
       "      <td>-0.033972</td>\n",
       "      <td>0.033433</td>\n",
       "      <td>0.114084</td>\n",
       "      <td>-0.086722</td>\n",
       "      <td>0.101702</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.067343</td>\n",
       "      <td>-0.091498</td>\n",
       "      <td>-0.119594</td>\n",
       "      <td>-0.137984</td>\n",
       "      <td>-0.116657</td>\n",
       "      <td>-0.152268</td>\n",
       "      <td>-0.125653</td>\n",
       "      <td>-0.093308</td>\n",
       "      <td>-0.044932</td>\n",
       "      <td>-0.061918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sk_Yds</th>\n",
       "      <td>-0.126034</td>\n",
       "      <td>-0.105648</td>\n",
       "      <td>-0.110537</td>\n",
       "      <td>-0.117215</td>\n",
       "      <td>-0.108688</td>\n",
       "      <td>-0.054331</td>\n",
       "      <td>0.051504</td>\n",
       "      <td>0.157066</td>\n",
       "      <td>-0.115458</td>\n",
       "      <td>0.151943</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.060191</td>\n",
       "      <td>-0.087334</td>\n",
       "      <td>-0.121350</td>\n",
       "      <td>-0.102688</td>\n",
       "      <td>-0.098659</td>\n",
       "      <td>-0.125533</td>\n",
       "      <td>-0.090011</td>\n",
       "      <td>-0.084669</td>\n",
       "      <td>-0.028034</td>\n",
       "      <td>-0.005910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Y/A</th>\n",
       "      <td>-0.097204</td>\n",
       "      <td>-0.097336</td>\n",
       "      <td>-0.000632</td>\n",
       "      <td>-0.000293</td>\n",
       "      <td>-0.097303</td>\n",
       "      <td>0.022397</td>\n",
       "      <td>0.237832</td>\n",
       "      <td>-0.162494</td>\n",
       "      <td>0.653493</td>\n",
       "      <td>0.713256</td>\n",
       "      <td>...</td>\n",
       "      <td>0.202785</td>\n",
       "      <td>0.176617</td>\n",
       "      <td>0.295578</td>\n",
       "      <td>0.296937</td>\n",
       "      <td>0.224560</td>\n",
       "      <td>0.273352</td>\n",
       "      <td>0.196155</td>\n",
       "      <td>0.254095</td>\n",
       "      <td>0.197926</td>\n",
       "      <td>0.224368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AY/A</th>\n",
       "      <td>-0.049372</td>\n",
       "      <td>-0.044113</td>\n",
       "      <td>-0.025474</td>\n",
       "      <td>-0.024289</td>\n",
       "      <td>-0.044587</td>\n",
       "      <td>0.052275</td>\n",
       "      <td>0.201033</td>\n",
       "      <td>-0.146047</td>\n",
       "      <td>0.566411</td>\n",
       "      <td>0.640760</td>\n",
       "      <td>...</td>\n",
       "      <td>0.247045</td>\n",
       "      <td>0.203586</td>\n",
       "      <td>0.293914</td>\n",
       "      <td>0.313789</td>\n",
       "      <td>0.254973</td>\n",
       "      <td>0.253864</td>\n",
       "      <td>0.095552</td>\n",
       "      <td>0.244254</td>\n",
       "      <td>0.191813</td>\n",
       "      <td>0.215548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ru_Att</th>\n",
       "      <td>0.019992</td>\n",
       "      <td>0.046681</td>\n",
       "      <td>-0.133904</td>\n",
       "      <td>-0.130188</td>\n",
       "      <td>0.043429</td>\n",
       "      <td>0.071748</td>\n",
       "      <td>0.069253</td>\n",
       "      <td>-0.016727</td>\n",
       "      <td>0.133841</td>\n",
       "      <td>0.116461</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.075068</td>\n",
       "      <td>-0.074499</td>\n",
       "      <td>0.020127</td>\n",
       "      <td>-0.110852</td>\n",
       "      <td>-0.075976</td>\n",
       "      <td>-0.125627</td>\n",
       "      <td>-0.147454</td>\n",
       "      <td>-0.040871</td>\n",
       "      <td>-0.087120</td>\n",
       "      <td>-0.064829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ru_Yds</th>\n",
       "      <td>0.057179</td>\n",
       "      <td>0.064481</td>\n",
       "      <td>-0.027840</td>\n",
       "      <td>-0.021878</td>\n",
       "      <td>0.063994</td>\n",
       "      <td>0.021364</td>\n",
       "      <td>0.205104</td>\n",
       "      <td>0.157422</td>\n",
       "      <td>0.140835</td>\n",
       "      <td>0.231689</td>\n",
       "      <td>...</td>\n",
       "      <td>0.119743</td>\n",
       "      <td>0.119724</td>\n",
       "      <td>0.080436</td>\n",
       "      <td>-0.024177</td>\n",
       "      <td>0.117907</td>\n",
       "      <td>0.049392</td>\n",
       "      <td>-0.034148</td>\n",
       "      <td>0.099034</td>\n",
       "      <td>0.035073</td>\n",
       "      <td>0.033370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ru_Y/A</th>\n",
       "      <td>0.065188</td>\n",
       "      <td>0.056987</td>\n",
       "      <td>0.059733</td>\n",
       "      <td>0.063185</td>\n",
       "      <td>0.058377</td>\n",
       "      <td>0.046022</td>\n",
       "      <td>0.104477</td>\n",
       "      <td>0.129424</td>\n",
       "      <td>0.028171</td>\n",
       "      <td>0.199151</td>\n",
       "      <td>...</td>\n",
       "      <td>0.195391</td>\n",
       "      <td>0.180715</td>\n",
       "      <td>0.090918</td>\n",
       "      <td>0.102939</td>\n",
       "      <td>0.197326</td>\n",
       "      <td>0.189211</td>\n",
       "      <td>0.117776</td>\n",
       "      <td>0.141961</td>\n",
       "      <td>0.134433</td>\n",
       "      <td>0.073471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ru_TB</th>\n",
       "      <td>0.041656</td>\n",
       "      <td>0.076844</td>\n",
       "      <td>-0.171169</td>\n",
       "      <td>-0.176664</td>\n",
       "      <td>0.072430</td>\n",
       "      <td>0.004025</td>\n",
       "      <td>0.286117</td>\n",
       "      <td>0.144488</td>\n",
       "      <td>0.264978</td>\n",
       "      <td>0.258290</td>\n",
       "      <td>...</td>\n",
       "      <td>0.050531</td>\n",
       "      <td>0.075222</td>\n",
       "      <td>0.210893</td>\n",
       "      <td>0.158256</td>\n",
       "      <td>0.100574</td>\n",
       "      <td>0.133814</td>\n",
       "      <td>0.113793</td>\n",
       "      <td>0.158104</td>\n",
       "      <td>0.144328</td>\n",
       "      <td>0.198498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Re_Tgt</th>\n",
       "      <td>-0.077314</td>\n",
       "      <td>-0.085562</td>\n",
       "      <td>0.038129</td>\n",
       "      <td>0.026638</td>\n",
       "      <td>-0.085044</td>\n",
       "      <td>-0.109109</td>\n",
       "      <td>-0.073860</td>\n",
       "      <td>0.047762</td>\n",
       "      <td>-0.175182</td>\n",
       "      <td>-0.040700</td>\n",
       "      <td>...</td>\n",
       "      <td>0.017556</td>\n",
       "      <td>0.011272</td>\n",
       "      <td>-0.120184</td>\n",
       "      <td>-0.097848</td>\n",
       "      <td>-0.037606</td>\n",
       "      <td>-0.111939</td>\n",
       "      <td>-0.166729</td>\n",
       "      <td>-0.037804</td>\n",
       "      <td>-0.057456</td>\n",
       "      <td>0.038400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Re_Rec</th>\n",
       "      <td>-0.077314</td>\n",
       "      <td>-0.085562</td>\n",
       "      <td>0.038129</td>\n",
       "      <td>0.026638</td>\n",
       "      <td>-0.085044</td>\n",
       "      <td>-0.109109</td>\n",
       "      <td>-0.073860</td>\n",
       "      <td>0.047762</td>\n",
       "      <td>-0.175182</td>\n",
       "      <td>-0.040700</td>\n",
       "      <td>...</td>\n",
       "      <td>0.017556</td>\n",
       "      <td>0.011272</td>\n",
       "      <td>-0.120184</td>\n",
       "      <td>-0.097848</td>\n",
       "      <td>-0.037606</td>\n",
       "      <td>-0.111939</td>\n",
       "      <td>-0.166729</td>\n",
       "      <td>-0.037804</td>\n",
       "      <td>-0.057456</td>\n",
       "      <td>0.038400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Re_Yds</th>\n",
       "      <td>-0.077314</td>\n",
       "      <td>-0.085562</td>\n",
       "      <td>0.038129</td>\n",
       "      <td>0.026638</td>\n",
       "      <td>-0.085044</td>\n",
       "      <td>-0.109109</td>\n",
       "      <td>-0.073860</td>\n",
       "      <td>0.047762</td>\n",
       "      <td>-0.175182</td>\n",
       "      <td>-0.040700</td>\n",
       "      <td>...</td>\n",
       "      <td>0.017556</td>\n",
       "      <td>0.011272</td>\n",
       "      <td>-0.120184</td>\n",
       "      <td>-0.097848</td>\n",
       "      <td>-0.037606</td>\n",
       "      <td>-0.111939</td>\n",
       "      <td>-0.166729</td>\n",
       "      <td>-0.037804</td>\n",
       "      <td>-0.057456</td>\n",
       "      <td>0.038400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Re_Y/R</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Re_TD</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Re_Ctch%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Re_Y/Tgt</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Total_NP_TD</th>\n",
       "      <td>0.041656</td>\n",
       "      <td>0.076844</td>\n",
       "      <td>-0.171169</td>\n",
       "      <td>-0.176664</td>\n",
       "      <td>0.072430</td>\n",
       "      <td>0.004025</td>\n",
       "      <td>0.286117</td>\n",
       "      <td>0.144488</td>\n",
       "      <td>0.264978</td>\n",
       "      <td>0.258290</td>\n",
       "      <td>...</td>\n",
       "      <td>0.050531</td>\n",
       "      <td>0.075222</td>\n",
       "      <td>0.210893</td>\n",
       "      <td>0.158256</td>\n",
       "      <td>0.100574</td>\n",
       "      <td>0.133814</td>\n",
       "      <td>0.113793</td>\n",
       "      <td>0.158104</td>\n",
       "      <td>0.144328</td>\n",
       "      <td>0.198498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pts</th>\n",
       "      <td>0.041656</td>\n",
       "      <td>0.076844</td>\n",
       "      <td>-0.171169</td>\n",
       "      <td>-0.176664</td>\n",
       "      <td>0.072430</td>\n",
       "      <td>0.004025</td>\n",
       "      <td>0.286117</td>\n",
       "      <td>0.144488</td>\n",
       "      <td>0.264978</td>\n",
       "      <td>0.258290</td>\n",
       "      <td>...</td>\n",
       "      <td>0.050531</td>\n",
       "      <td>0.075222</td>\n",
       "      <td>0.210893</td>\n",
       "      <td>0.158256</td>\n",
       "      <td>0.100574</td>\n",
       "      <td>0.133814</td>\n",
       "      <td>0.113793</td>\n",
       "      <td>0.158104</td>\n",
       "      <td>0.144328</td>\n",
       "      <td>0.198498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fmb</th>\n",
       "      <td>-0.144647</td>\n",
       "      <td>-0.092192</td>\n",
       "      <td>-0.269974</td>\n",
       "      <td>-0.270178</td>\n",
       "      <td>-0.098924</td>\n",
       "      <td>0.087340</td>\n",
       "      <td>0.037897</td>\n",
       "      <td>-0.016313</td>\n",
       "      <td>0.085696</td>\n",
       "      <td>0.081104</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.071634</td>\n",
       "      <td>-0.024774</td>\n",
       "      <td>0.058754</td>\n",
       "      <td>0.019357</td>\n",
       "      <td>0.011890</td>\n",
       "      <td>0.009791</td>\n",
       "      <td>-0.030766</td>\n",
       "      <td>-0.005930</td>\n",
       "      <td>-0.017956</td>\n",
       "      <td>-0.090975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FL</th>\n",
       "      <td>-0.038008</td>\n",
       "      <td>0.006596</td>\n",
       "      <td>-0.229256</td>\n",
       "      <td>-0.227217</td>\n",
       "      <td>0.000999</td>\n",
       "      <td>0.111318</td>\n",
       "      <td>-0.009339</td>\n",
       "      <td>-0.060969</td>\n",
       "      <td>0.071658</td>\n",
       "      <td>0.001932</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.082389</td>\n",
       "      <td>-0.054092</td>\n",
       "      <td>0.038405</td>\n",
       "      <td>-0.006067</td>\n",
       "      <td>-0.059166</td>\n",
       "      <td>-0.046998</td>\n",
       "      <td>-0.093648</td>\n",
       "      <td>-0.062821</td>\n",
       "      <td>0.091811</td>\n",
       "      <td>-0.256841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Dome</th>\n",
       "      <td>0.186980</td>\n",
       "      <td>0.215330</td>\n",
       "      <td>-0.137435</td>\n",
       "      <td>-0.132035</td>\n",
       "      <td>0.212590</td>\n",
       "      <td>0.059566</td>\n",
       "      <td>0.141955</td>\n",
       "      <td>0.124891</td>\n",
       "      <td>0.082454</td>\n",
       "      <td>0.192841</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.203884</td>\n",
       "      <td>-0.182435</td>\n",
       "      <td>-0.142989</td>\n",
       "      <td>-0.110012</td>\n",
       "      <td>-0.121461</td>\n",
       "      <td>-0.066636</td>\n",
       "      <td>-0.020564</td>\n",
       "      <td>-0.073447</td>\n",
       "      <td>0.070518</td>\n",
       "      <td>0.015414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Total</th>\n",
       "      <td>0.119064</td>\n",
       "      <td>0.146949</td>\n",
       "      <td>-0.127168</td>\n",
       "      <td>-0.129682</td>\n",
       "      <td>0.144137</td>\n",
       "      <td>0.086614</td>\n",
       "      <td>0.524501</td>\n",
       "      <td>0.269819</td>\n",
       "      <td>0.525856</td>\n",
       "      <td>0.782607</td>\n",
       "      <td>...</td>\n",
       "      <td>0.253391</td>\n",
       "      <td>0.242902</td>\n",
       "      <td>0.308188</td>\n",
       "      <td>0.354164</td>\n",
       "      <td>0.327519</td>\n",
       "      <td>0.330658</td>\n",
       "      <td>0.155994</td>\n",
       "      <td>0.301105</td>\n",
       "      <td>0.341437</td>\n",
       "      <td>0.215686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RANK</th>\n",
       "      <td>-0.032962</td>\n",
       "      <td>-0.071687</td>\n",
       "      <td>0.196179</td>\n",
       "      <td>0.206036</td>\n",
       "      <td>-0.066702</td>\n",
       "      <td>-0.058058</td>\n",
       "      <td>-0.084397</td>\n",
       "      <td>-0.216286</td>\n",
       "      <td>0.123145</td>\n",
       "      <td>0.104935</td>\n",
       "      <td>...</td>\n",
       "      <td>0.469723</td>\n",
       "      <td>0.409643</td>\n",
       "      <td>0.582435</td>\n",
       "      <td>0.732926</td>\n",
       "      <td>0.539530</td>\n",
       "      <td>0.609654</td>\n",
       "      <td>0.367257</td>\n",
       "      <td>0.420176</td>\n",
       "      <td>0.439243</td>\n",
       "      <td>0.212193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PTS</th>\n",
       "      <td>-0.252162</td>\n",
       "      <td>-0.216235</td>\n",
       "      <td>-0.182430</td>\n",
       "      <td>-0.183531</td>\n",
       "      <td>-0.221077</td>\n",
       "      <td>0.061771</td>\n",
       "      <td>0.184913</td>\n",
       "      <td>0.148295</td>\n",
       "      <td>0.146716</td>\n",
       "      <td>0.121336</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.026762</td>\n",
       "      <td>0.072434</td>\n",
       "      <td>-0.086350</td>\n",
       "      <td>0.002585</td>\n",
       "      <td>0.060516</td>\n",
       "      <td>-0.008386</td>\n",
       "      <td>-0.054548</td>\n",
       "      <td>0.110437</td>\n",
       "      <td>-0.018415</td>\n",
       "      <td>-0.147382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FPTS</th>\n",
       "      <td>-0.828520</td>\n",
       "      <td>-0.841965</td>\n",
       "      <td>0.034724</td>\n",
       "      <td>0.038743</td>\n",
       "      <td>-0.842528</td>\n",
       "      <td>0.048877</td>\n",
       "      <td>-0.275342</td>\n",
       "      <td>-0.223504</td>\n",
       "      <td>-0.166209</td>\n",
       "      <td>-0.161946</td>\n",
       "      <td>...</td>\n",
       "      <td>0.155002</td>\n",
       "      <td>0.177915</td>\n",
       "      <td>-0.056903</td>\n",
       "      <td>0.121550</td>\n",
       "      <td>0.011789</td>\n",
       "      <td>-0.051604</td>\n",
       "      <td>-0.049178</td>\n",
       "      <td>0.082523</td>\n",
       "      <td>-0.134737</td>\n",
       "      <td>-0.213838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SACKS</th>\n",
       "      <td>-0.213090</td>\n",
       "      <td>-0.215506</td>\n",
       "      <td>0.021640</td>\n",
       "      <td>0.012826</td>\n",
       "      <td>-0.215451</td>\n",
       "      <td>0.126779</td>\n",
       "      <td>0.067426</td>\n",
       "      <td>0.138364</td>\n",
       "      <td>-0.058163</td>\n",
       "      <td>0.065546</td>\n",
       "      <td>...</td>\n",
       "      <td>0.130811</td>\n",
       "      <td>0.232306</td>\n",
       "      <td>-0.077493</td>\n",
       "      <td>-0.010617</td>\n",
       "      <td>0.109157</td>\n",
       "      <td>-0.029581</td>\n",
       "      <td>-0.073654</td>\n",
       "      <td>0.213551</td>\n",
       "      <td>-0.173857</td>\n",
       "      <td>0.036353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>INT</th>\n",
       "      <td>-0.158240</td>\n",
       "      <td>-0.150920</td>\n",
       "      <td>-0.026099</td>\n",
       "      <td>-0.026112</td>\n",
       "      <td>-0.151744</td>\n",
       "      <td>0.083719</td>\n",
       "      <td>0.165773</td>\n",
       "      <td>0.207941</td>\n",
       "      <td>0.015761</td>\n",
       "      <td>0.225976</td>\n",
       "      <td>...</td>\n",
       "      <td>0.325303</td>\n",
       "      <td>0.374551</td>\n",
       "      <td>0.054154</td>\n",
       "      <td>0.100820</td>\n",
       "      <td>0.205802</td>\n",
       "      <td>0.114604</td>\n",
       "      <td>0.029030</td>\n",
       "      <td>0.312346</td>\n",
       "      <td>0.015906</td>\n",
       "      <td>0.025415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TO</th>\n",
       "      <td>-0.201731</td>\n",
       "      <td>-0.189515</td>\n",
       "      <td>-0.049386</td>\n",
       "      <td>-0.050879</td>\n",
       "      <td>-0.190971</td>\n",
       "      <td>0.138987</td>\n",
       "      <td>0.196715</td>\n",
       "      <td>0.246369</td>\n",
       "      <td>0.015365</td>\n",
       "      <td>0.222629</td>\n",
       "      <td>...</td>\n",
       "      <td>0.313033</td>\n",
       "      <td>0.387385</td>\n",
       "      <td>0.043313</td>\n",
       "      <td>0.115228</td>\n",
       "      <td>0.244044</td>\n",
       "      <td>0.159194</td>\n",
       "      <td>0.076688</td>\n",
       "      <td>0.375765</td>\n",
       "      <td>0.120129</td>\n",
       "      <td>0.020966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PTS.1</th>\n",
       "      <td>-0.054201</td>\n",
       "      <td>-0.107674</td>\n",
       "      <td>0.292354</td>\n",
       "      <td>0.292570</td>\n",
       "      <td>-0.100445</td>\n",
       "      <td>-0.010899</td>\n",
       "      <td>0.056903</td>\n",
       "      <td>-0.041420</td>\n",
       "      <td>0.149435</td>\n",
       "      <td>0.234457</td>\n",
       "      <td>...</td>\n",
       "      <td>0.804082</td>\n",
       "      <td>0.828409</td>\n",
       "      <td>0.768764</td>\n",
       "      <td>0.976168</td>\n",
       "      <td>0.902938</td>\n",
       "      <td>0.883679</td>\n",
       "      <td>0.504125</td>\n",
       "      <td>0.883457</td>\n",
       "      <td>0.628120</td>\n",
       "      <td>0.384184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PLAYS</th>\n",
       "      <td>-0.191115</td>\n",
       "      <td>-0.237871</td>\n",
       "      <td>0.261506</td>\n",
       "      <td>0.257894</td>\n",
       "      <td>-0.231719</td>\n",
       "      <td>0.061153</td>\n",
       "      <td>0.147777</td>\n",
       "      <td>0.151728</td>\n",
       "      <td>0.057390</td>\n",
       "      <td>0.230710</td>\n",
       "      <td>...</td>\n",
       "      <td>0.796842</td>\n",
       "      <td>0.910977</td>\n",
       "      <td>0.608559</td>\n",
       "      <td>0.752141</td>\n",
       "      <td>0.858322</td>\n",
       "      <td>0.712165</td>\n",
       "      <td>0.302709</td>\n",
       "      <td>0.921974</td>\n",
       "      <td>0.486446</td>\n",
       "      <td>0.241927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>YDS</th>\n",
       "      <td>-0.164671</td>\n",
       "      <td>-0.214000</td>\n",
       "      <td>0.271409</td>\n",
       "      <td>0.270286</td>\n",
       "      <td>-0.207545</td>\n",
       "      <td>0.012438</td>\n",
       "      <td>0.105252</td>\n",
       "      <td>0.082305</td>\n",
       "      <td>0.074409</td>\n",
       "      <td>0.272011</td>\n",
       "      <td>...</td>\n",
       "      <td>0.859746</td>\n",
       "      <td>0.870886</td>\n",
       "      <td>0.699949</td>\n",
       "      <td>0.884664</td>\n",
       "      <td>0.904454</td>\n",
       "      <td>0.806942</td>\n",
       "      <td>0.383882</td>\n",
       "      <td>0.965521</td>\n",
       "      <td>0.640405</td>\n",
       "      <td>0.314770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PASS YDS</th>\n",
       "      <td>-0.176241</td>\n",
       "      <td>-0.218131</td>\n",
       "      <td>0.232526</td>\n",
       "      <td>0.232421</td>\n",
       "      <td>-0.212606</td>\n",
       "      <td>-0.008460</td>\n",
       "      <td>0.163952</td>\n",
       "      <td>0.129366</td>\n",
       "      <td>0.115698</td>\n",
       "      <td>0.297281</td>\n",
       "      <td>...</td>\n",
       "      <td>0.692245</td>\n",
       "      <td>0.754275</td>\n",
       "      <td>0.602368</td>\n",
       "      <td>0.831719</td>\n",
       "      <td>0.832603</td>\n",
       "      <td>0.753080</td>\n",
       "      <td>0.388091</td>\n",
       "      <td>0.920215</td>\n",
       "      <td>0.614002</td>\n",
       "      <td>0.291941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PASS ATT</th>\n",
       "      <td>-0.175621</td>\n",
       "      <td>-0.215455</td>\n",
       "      <td>0.226161</td>\n",
       "      <td>0.222416</td>\n",
       "      <td>-0.210115</td>\n",
       "      <td>0.041783</td>\n",
       "      <td>0.215394</td>\n",
       "      <td>0.226760</td>\n",
       "      <td>0.079465</td>\n",
       "      <td>0.255744</td>\n",
       "      <td>...</td>\n",
       "      <td>0.631276</td>\n",
       "      <td>0.746734</td>\n",
       "      <td>0.506025</td>\n",
       "      <td>0.648270</td>\n",
       "      <td>0.776872</td>\n",
       "      <td>0.642162</td>\n",
       "      <td>0.286894</td>\n",
       "      <td>0.875498</td>\n",
       "      <td>0.465187</td>\n",
       "      <td>0.235781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PASS COMP</th>\n",
       "      <td>-0.105246</td>\n",
       "      <td>-0.146998</td>\n",
       "      <td>0.237432</td>\n",
       "      <td>0.233451</td>\n",
       "      <td>-0.141295</td>\n",
       "      <td>0.018622</td>\n",
       "      <td>0.267945</td>\n",
       "      <td>0.213488</td>\n",
       "      <td>0.181421</td>\n",
       "      <td>0.284086</td>\n",
       "      <td>...</td>\n",
       "      <td>0.645904</td>\n",
       "      <td>0.743283</td>\n",
       "      <td>0.566170</td>\n",
       "      <td>0.705512</td>\n",
       "      <td>0.823828</td>\n",
       "      <td>0.713873</td>\n",
       "      <td>0.340724</td>\n",
       "      <td>0.902370</td>\n",
       "      <td>0.578147</td>\n",
       "      <td>0.276196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PASS TD</th>\n",
       "      <td>-0.074795</td>\n",
       "      <td>-0.107404</td>\n",
       "      <td>0.182310</td>\n",
       "      <td>0.183655</td>\n",
       "      <td>-0.102935</td>\n",
       "      <td>-0.018665</td>\n",
       "      <td>-0.031259</td>\n",
       "      <td>-0.055274</td>\n",
       "      <td>0.025434</td>\n",
       "      <td>0.151978</td>\n",
       "      <td>...</td>\n",
       "      <td>0.602222</td>\n",
       "      <td>0.633760</td>\n",
       "      <td>0.394614</td>\n",
       "      <td>0.890552</td>\n",
       "      <td>0.700489</td>\n",
       "      <td>0.793770</td>\n",
       "      <td>0.615772</td>\n",
       "      <td>0.741285</td>\n",
       "      <td>0.575164</td>\n",
       "      <td>0.352421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RUSH YDS</th>\n",
       "      <td>-0.108005</td>\n",
       "      <td>-0.161226</td>\n",
       "      <td>0.288906</td>\n",
       "      <td>0.286071</td>\n",
       "      <td>-0.154346</td>\n",
       "      <td>0.049819</td>\n",
       "      <td>-0.029138</td>\n",
       "      <td>-0.025004</td>\n",
       "      <td>-0.020199</td>\n",
       "      <td>0.166622</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.911425</td>\n",
       "      <td>0.739913</td>\n",
       "      <td>0.800488</td>\n",
       "      <td>0.852306</td>\n",
       "      <td>0.740816</td>\n",
       "      <td>0.295340</td>\n",
       "      <td>0.849774</td>\n",
       "      <td>0.556654</td>\n",
       "      <td>0.292454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RUSH ATT</th>\n",
       "      <td>-0.165325</td>\n",
       "      <td>-0.215983</td>\n",
       "      <td>0.278139</td>\n",
       "      <td>0.276143</td>\n",
       "      <td>-0.209406</td>\n",
       "      <td>0.062670</td>\n",
       "      <td>0.041605</td>\n",
       "      <td>0.026854</td>\n",
       "      <td>0.032362</td>\n",
       "      <td>0.169893</td>\n",
       "      <td>...</td>\n",
       "      <td>0.911425</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.689434</td>\n",
       "      <td>0.814237</td>\n",
       "      <td>0.866795</td>\n",
       "      <td>0.738431</td>\n",
       "      <td>0.305405</td>\n",
       "      <td>0.868289</td>\n",
       "      <td>0.492564</td>\n",
       "      <td>0.223349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RUSH TD</th>\n",
       "      <td>0.052792</td>\n",
       "      <td>-0.013860</td>\n",
       "      <td>0.355925</td>\n",
       "      <td>0.353815</td>\n",
       "      <td>-0.005062</td>\n",
       "      <td>-0.016843</td>\n",
       "      <td>0.121216</td>\n",
       "      <td>0.000637</td>\n",
       "      <td>0.199296</td>\n",
       "      <td>0.248432</td>\n",
       "      <td>...</td>\n",
       "      <td>0.739913</td>\n",
       "      <td>0.689434</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.745442</td>\n",
       "      <td>0.792632</td>\n",
       "      <td>0.757575</td>\n",
       "      <td>0.372647</td>\n",
       "      <td>0.738563</td>\n",
       "      <td>0.522233</td>\n",
       "      <td>0.284535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TD_right</th>\n",
       "      <td>-0.067936</td>\n",
       "      <td>-0.123106</td>\n",
       "      <td>0.298930</td>\n",
       "      <td>0.300122</td>\n",
       "      <td>-0.115800</td>\n",
       "      <td>-0.028553</td>\n",
       "      <td>0.032495</td>\n",
       "      <td>-0.049268</td>\n",
       "      <td>0.116312</td>\n",
       "      <td>0.216943</td>\n",
       "      <td>...</td>\n",
       "      <td>0.800488</td>\n",
       "      <td>0.814237</td>\n",
       "      <td>0.745442</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.873593</td>\n",
       "      <td>0.910967</td>\n",
       "      <td>0.592111</td>\n",
       "      <td>0.870352</td>\n",
       "      <td>0.636853</td>\n",
       "      <td>0.349711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RZ ATT</th>\n",
       "      <td>-0.014056</td>\n",
       "      <td>-0.063719</td>\n",
       "      <td>0.277307</td>\n",
       "      <td>0.276797</td>\n",
       "      <td>-0.056814</td>\n",
       "      <td>0.016639</td>\n",
       "      <td>0.117018</td>\n",
       "      <td>0.060606</td>\n",
       "      <td>0.115350</td>\n",
       "      <td>0.233722</td>\n",
       "      <td>...</td>\n",
       "      <td>0.852306</td>\n",
       "      <td>0.866795</td>\n",
       "      <td>0.792632</td>\n",
       "      <td>0.873593</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.889701</td>\n",
       "      <td>0.383152</td>\n",
       "      <td>0.940382</td>\n",
       "      <td>0.629662</td>\n",
       "      <td>0.373583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RZ TD</th>\n",
       "      <td>0.063924</td>\n",
       "      <td>0.012621</td>\n",
       "      <td>0.284140</td>\n",
       "      <td>0.282864</td>\n",
       "      <td>0.019770</td>\n",
       "      <td>0.003549</td>\n",
       "      <td>0.079056</td>\n",
       "      <td>-0.001761</td>\n",
       "      <td>0.135190</td>\n",
       "      <td>0.230792</td>\n",
       "      <td>...</td>\n",
       "      <td>0.740816</td>\n",
       "      <td>0.738431</td>\n",
       "      <td>0.757575</td>\n",
       "      <td>0.910967</td>\n",
       "      <td>0.889701</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.744231</td>\n",
       "      <td>0.869635</td>\n",
       "      <td>0.670148</td>\n",
       "      <td>0.401773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RZ TD%</th>\n",
       "      <td>0.062106</td>\n",
       "      <td>0.027217</td>\n",
       "      <td>0.189121</td>\n",
       "      <td>0.187354</td>\n",
       "      <td>0.031969</td>\n",
       "      <td>0.018192</td>\n",
       "      <td>-0.017212</td>\n",
       "      <td>-0.084492</td>\n",
       "      <td>0.087613</td>\n",
       "      <td>0.109590</td>\n",
       "      <td>...</td>\n",
       "      <td>0.295340</td>\n",
       "      <td>0.305405</td>\n",
       "      <td>0.372647</td>\n",
       "      <td>0.592111</td>\n",
       "      <td>0.383152</td>\n",
       "      <td>0.744231</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.451707</td>\n",
       "      <td>0.399210</td>\n",
       "      <td>0.327199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1D</th>\n",
       "      <td>-0.109885</td>\n",
       "      <td>-0.159172</td>\n",
       "      <td>0.273857</td>\n",
       "      <td>0.270207</td>\n",
       "      <td>-0.152582</td>\n",
       "      <td>0.049679</td>\n",
       "      <td>0.091688</td>\n",
       "      <td>0.049291</td>\n",
       "      <td>0.096173</td>\n",
       "      <td>0.247586</td>\n",
       "      <td>...</td>\n",
       "      <td>0.849774</td>\n",
       "      <td>0.868289</td>\n",
       "      <td>0.738563</td>\n",
       "      <td>0.870352</td>\n",
       "      <td>0.940382</td>\n",
       "      <td>0.869635</td>\n",
       "      <td>0.451707</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.650645</td>\n",
       "      <td>0.367379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3D%</th>\n",
       "      <td>0.085507</td>\n",
       "      <td>0.093306</td>\n",
       "      <td>-0.019220</td>\n",
       "      <td>-0.024762</td>\n",
       "      <td>0.092977</td>\n",
       "      <td>-0.193663</td>\n",
       "      <td>0.214352</td>\n",
       "      <td>0.123413</td>\n",
       "      <td>0.186627</td>\n",
       "      <td>0.269464</td>\n",
       "      <td>...</td>\n",
       "      <td>0.556654</td>\n",
       "      <td>0.492564</td>\n",
       "      <td>0.522233</td>\n",
       "      <td>0.636853</td>\n",
       "      <td>0.629662</td>\n",
       "      <td>0.670148</td>\n",
       "      <td>0.399210</td>\n",
       "      <td>0.650645</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.185137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4D%</th>\n",
       "      <td>0.230744</td>\n",
       "      <td>0.220464</td>\n",
       "      <td>0.069353</td>\n",
       "      <td>0.064446</td>\n",
       "      <td>0.222458</td>\n",
       "      <td>0.145605</td>\n",
       "      <td>0.002511</td>\n",
       "      <td>-0.108816</td>\n",
       "      <td>0.154311</td>\n",
       "      <td>0.112492</td>\n",
       "      <td>...</td>\n",
       "      <td>0.292454</td>\n",
       "      <td>0.223349</td>\n",
       "      <td>0.284535</td>\n",
       "      <td>0.349711</td>\n",
       "      <td>0.373583</td>\n",
       "      <td>0.401773</td>\n",
       "      <td>0.327199</td>\n",
       "      <td>0.367379</td>\n",
       "      <td>0.185137</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>57 rows × 57 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Rk      Year        G#      Week       Age      Home  \\\n",
       "Rk           1.000000  0.980590  0.135077  0.134844  0.985092 -0.046498   \n",
       "Year         0.980590  1.000000 -0.061693 -0.061698  0.999699 -0.055236   \n",
       "G#           0.135077 -0.061693  1.000000  0.998630 -0.037241  0.043728   \n",
       "Week         0.134844 -0.061698  0.998630  1.000000 -0.037221  0.038845   \n",
       "Age          0.985092  0.999699 -0.037241 -0.037221  1.000000 -0.054377   \n",
       "Home        -0.046498 -0.055236  0.043728  0.038845 -0.054377  1.000000   \n",
       "Cmp          0.208034  0.236149 -0.126658 -0.134845  0.233168 -0.096654   \n",
       "Att          0.218235  0.242484 -0.105949 -0.115244  0.239951 -0.097390   \n",
       "Cmp%         0.054054  0.064499 -0.048957 -0.050050  0.063439 -0.033416   \n",
       "Yds          0.070734  0.091371 -0.093605 -0.100059  0.089154 -0.047588   \n",
       "TD_left      0.118966  0.130219 -0.044436 -0.043991  0.129576  0.161573   \n",
       "Int          0.051058  0.042063  0.050528  0.047520  0.043311  0.042780   \n",
       "Rate         0.014633  0.024156 -0.043723 -0.042776  0.023336  0.071056   \n",
       "Sk          -0.197425 -0.176356 -0.117896 -0.122038 -0.179567 -0.033972   \n",
       "Sk_Yds      -0.126034 -0.105648 -0.110537 -0.117215 -0.108688 -0.054331   \n",
       "Y/A         -0.097204 -0.097336 -0.000632 -0.000293 -0.097303  0.022397   \n",
       "AY/A        -0.049372 -0.044113 -0.025474 -0.024289 -0.044587  0.052275   \n",
       "Ru_Att       0.019992  0.046681 -0.133904 -0.130188  0.043429  0.071748   \n",
       "Ru_Yds       0.057179  0.064481 -0.027840 -0.021878  0.063994  0.021364   \n",
       "Ru_Y/A       0.065188  0.056987  0.059733  0.063185  0.058377  0.046022   \n",
       "Ru_TB        0.041656  0.076844 -0.171169 -0.176664  0.072430  0.004025   \n",
       "Re_Tgt      -0.077314 -0.085562  0.038129  0.026638 -0.085044 -0.109109   \n",
       "Re_Rec      -0.077314 -0.085562  0.038129  0.026638 -0.085044 -0.109109   \n",
       "Re_Yds      -0.077314 -0.085562  0.038129  0.026638 -0.085044 -0.109109   \n",
       "Re_Y/R            NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "Re_TD             NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "Re_Ctch%          NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "Re_Y/Tgt          NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "Total_NP_TD  0.041656  0.076844 -0.171169 -0.176664  0.072430  0.004025   \n",
       "Pts          0.041656  0.076844 -0.171169 -0.176664  0.072430  0.004025   \n",
       "Fmb         -0.144647 -0.092192 -0.269974 -0.270178 -0.098924  0.087340   \n",
       "FL          -0.038008  0.006596 -0.229256 -0.227217  0.000999  0.111318   \n",
       "Dome         0.186980  0.215330 -0.137435 -0.132035  0.212590  0.059566   \n",
       "Total        0.119064  0.146949 -0.127168 -0.129682  0.144137  0.086614   \n",
       "RANK        -0.032962 -0.071687  0.196179  0.206036 -0.066702 -0.058058   \n",
       "PTS         -0.252162 -0.216235 -0.182430 -0.183531 -0.221077  0.061771   \n",
       "FPTS        -0.828520 -0.841965  0.034724  0.038743 -0.842528  0.048877   \n",
       "SACKS       -0.213090 -0.215506  0.021640  0.012826 -0.215451  0.126779   \n",
       "INT         -0.158240 -0.150920 -0.026099 -0.026112 -0.151744  0.083719   \n",
       "TO          -0.201731 -0.189515 -0.049386 -0.050879 -0.190971  0.138987   \n",
       "PTS.1       -0.054201 -0.107674  0.292354  0.292570 -0.100445 -0.010899   \n",
       "PLAYS       -0.191115 -0.237871  0.261506  0.257894 -0.231719  0.061153   \n",
       "YDS         -0.164671 -0.214000  0.271409  0.270286 -0.207545  0.012438   \n",
       "PASS YDS    -0.176241 -0.218131  0.232526  0.232421 -0.212606 -0.008460   \n",
       "PASS ATT    -0.175621 -0.215455  0.226161  0.222416 -0.210115  0.041783   \n",
       "PASS COMP   -0.105246 -0.146998  0.237432  0.233451 -0.141295  0.018622   \n",
       "PASS TD     -0.074795 -0.107404  0.182310  0.183655 -0.102935 -0.018665   \n",
       "RUSH YDS    -0.108005 -0.161226  0.288906  0.286071 -0.154346  0.049819   \n",
       "RUSH ATT    -0.165325 -0.215983  0.278139  0.276143 -0.209406  0.062670   \n",
       "RUSH TD      0.052792 -0.013860  0.355925  0.353815 -0.005062 -0.016843   \n",
       "TD_right    -0.067936 -0.123106  0.298930  0.300122 -0.115800 -0.028553   \n",
       "RZ ATT      -0.014056 -0.063719  0.277307  0.276797 -0.056814  0.016639   \n",
       "RZ TD        0.063924  0.012621  0.284140  0.282864  0.019770  0.003549   \n",
       "RZ TD%       0.062106  0.027217  0.189121  0.187354  0.031969  0.018192   \n",
       "1D          -0.109885 -0.159172  0.273857  0.270207 -0.152582  0.049679   \n",
       "3D%          0.085507  0.093306 -0.019220 -0.024762  0.092977 -0.193663   \n",
       "4D%          0.230744  0.220464  0.069353  0.064446  0.222458  0.145605   \n",
       "\n",
       "                  Cmp       Att      Cmp%       Yds  ...  RUSH YDS  RUSH ATT  \\\n",
       "Rk           0.208034  0.218235  0.054054  0.070734  ... -0.108005 -0.165325   \n",
       "Year         0.236149  0.242484  0.064499  0.091371  ... -0.161226 -0.215983   \n",
       "G#          -0.126658 -0.105949 -0.048957 -0.093605  ...  0.288906  0.278139   \n",
       "Week        -0.134845 -0.115244 -0.050050 -0.100059  ...  0.286071  0.276143   \n",
       "Age          0.233168  0.239951  0.063439  0.089154  ... -0.154346 -0.209406   \n",
       "Home        -0.096654 -0.097390 -0.033416 -0.047588  ...  0.049819  0.062670   \n",
       "Cmp          1.000000  0.807666  0.606008  0.767032  ... -0.029138  0.041605   \n",
       "Att          0.807666  1.000000  0.030870  0.558316  ... -0.025004  0.026854   \n",
       "Cmp%         0.606008  0.030870  1.000000  0.561411  ... -0.020199  0.032362   \n",
       "Yds          0.767032  0.558316  0.561411  1.000000  ...  0.166622  0.169893   \n",
       "TD_left      0.242372  0.047316  0.348164  0.467253  ...  0.253622  0.244680   \n",
       "Int          0.031495  0.090734 -0.071141 -0.116396  ... -0.085813 -0.012721   \n",
       "Rate         0.311031 -0.107847  0.691593  0.605887  ...  0.213523  0.191172   \n",
       "Sk           0.033433  0.114084 -0.086722  0.101702  ... -0.067343 -0.091498   \n",
       "Sk_Yds       0.051504  0.157066 -0.115458  0.151943  ... -0.060191 -0.087334   \n",
       "Y/A          0.237832 -0.162494  0.653493  0.713256  ...  0.202785  0.176617   \n",
       "AY/A         0.201033 -0.146047  0.566411  0.640760  ...  0.247045  0.203586   \n",
       "Ru_Att       0.069253 -0.016727  0.133841  0.116461  ... -0.075068 -0.074499   \n",
       "Ru_Yds       0.205104  0.157422  0.140835  0.231689  ...  0.119743  0.119724   \n",
       "Ru_Y/A       0.104477  0.129424  0.028171  0.199151  ...  0.195391  0.180715   \n",
       "Ru_TB        0.286117  0.144488  0.264978  0.258290  ...  0.050531  0.075222   \n",
       "Re_Tgt      -0.073860  0.047762 -0.175182 -0.040700  ...  0.017556  0.011272   \n",
       "Re_Rec      -0.073860  0.047762 -0.175182 -0.040700  ...  0.017556  0.011272   \n",
       "Re_Yds      -0.073860  0.047762 -0.175182 -0.040700  ...  0.017556  0.011272   \n",
       "Re_Y/R            NaN       NaN       NaN       NaN  ...       NaN       NaN   \n",
       "Re_TD             NaN       NaN       NaN       NaN  ...       NaN       NaN   \n",
       "Re_Ctch%          NaN       NaN       NaN       NaN  ...       NaN       NaN   \n",
       "Re_Y/Tgt          NaN       NaN       NaN       NaN  ...       NaN       NaN   \n",
       "Total_NP_TD  0.286117  0.144488  0.264978  0.258290  ...  0.050531  0.075222   \n",
       "Pts          0.286117  0.144488  0.264978  0.258290  ...  0.050531  0.075222   \n",
       "Fmb          0.037897 -0.016313  0.085696  0.081104  ... -0.071634 -0.024774   \n",
       "FL          -0.009339 -0.060969  0.071658  0.001932  ... -0.082389 -0.054092   \n",
       "Dome         0.141955  0.124891  0.082454  0.192841  ... -0.203884 -0.182435   \n",
       "Total        0.524501  0.269819  0.525856  0.782607  ...  0.253391  0.242902   \n",
       "RANK        -0.084397 -0.216286  0.123145  0.104935  ...  0.469723  0.409643   \n",
       "PTS          0.184913  0.148295  0.146716  0.121336  ... -0.026762  0.072434   \n",
       "FPTS        -0.275342 -0.223504 -0.166209 -0.161946  ...  0.155002  0.177915   \n",
       "SACKS        0.067426  0.138364 -0.058163  0.065546  ...  0.130811  0.232306   \n",
       "INT          0.165773  0.207941  0.015761  0.225976  ...  0.325303  0.374551   \n",
       "TO           0.196715  0.246369  0.015365  0.222629  ...  0.313033  0.387385   \n",
       "PTS.1        0.056903 -0.041420  0.149435  0.234457  ...  0.804082  0.828409   \n",
       "PLAYS        0.147777  0.151728  0.057390  0.230710  ...  0.796842  0.910977   \n",
       "YDS          0.105252  0.082305  0.074409  0.272011  ...  0.859746  0.870886   \n",
       "PASS YDS     0.163952  0.129366  0.115698  0.297281  ...  0.692245  0.754275   \n",
       "PASS ATT     0.215394  0.226760  0.079465  0.255744  ...  0.631276  0.746734   \n",
       "PASS COMP    0.267945  0.213488  0.181421  0.284086  ...  0.645904  0.743283   \n",
       "PASS TD     -0.031259 -0.055274  0.025434  0.151978  ...  0.602222  0.633760   \n",
       "RUSH YDS    -0.029138 -0.025004 -0.020199  0.166622  ...  1.000000  0.911425   \n",
       "RUSH ATT     0.041605  0.026854  0.032362  0.169893  ...  0.911425  1.000000   \n",
       "RUSH TD      0.121216  0.000637  0.199296  0.248432  ...  0.739913  0.689434   \n",
       "TD_right     0.032495 -0.049268  0.116312  0.216943  ...  0.800488  0.814237   \n",
       "RZ ATT       0.117018  0.060606  0.115350  0.233722  ...  0.852306  0.866795   \n",
       "RZ TD        0.079056 -0.001761  0.135190  0.230792  ...  0.740816  0.738431   \n",
       "RZ TD%      -0.017212 -0.084492  0.087613  0.109590  ...  0.295340  0.305405   \n",
       "1D           0.091688  0.049291  0.096173  0.247586  ...  0.849774  0.868289   \n",
       "3D%          0.214352  0.123413  0.186627  0.269464  ...  0.556654  0.492564   \n",
       "4D%          0.002511 -0.108816  0.154311  0.112492  ...  0.292454  0.223349   \n",
       "\n",
       "              RUSH TD  TD_right    RZ ATT     RZ TD    RZ TD%        1D  \\\n",
       "Rk           0.052792 -0.067936 -0.014056  0.063924  0.062106 -0.109885   \n",
       "Year        -0.013860 -0.123106 -0.063719  0.012621  0.027217 -0.159172   \n",
       "G#           0.355925  0.298930  0.277307  0.284140  0.189121  0.273857   \n",
       "Week         0.353815  0.300122  0.276797  0.282864  0.187354  0.270207   \n",
       "Age         -0.005062 -0.115800 -0.056814  0.019770  0.031969 -0.152582   \n",
       "Home        -0.016843 -0.028553  0.016639  0.003549  0.018192  0.049679   \n",
       "Cmp          0.121216  0.032495  0.117018  0.079056 -0.017212  0.091688   \n",
       "Att          0.000637 -0.049268  0.060606 -0.001761 -0.084492  0.049291   \n",
       "Cmp%         0.199296  0.116312  0.115350  0.135190  0.087613  0.096173   \n",
       "Yds          0.248432  0.216943  0.233722  0.230792  0.109590  0.247586   \n",
       "TD_left      0.234910  0.368652  0.322633  0.349228  0.211765  0.263795   \n",
       "Int         -0.068013  0.010673 -0.015873  0.094067  0.262825  0.034359   \n",
       "Rate         0.277265  0.303396  0.259772  0.246374  0.079022  0.222420   \n",
       "Sk          -0.119594 -0.137984 -0.116657 -0.152268 -0.125653 -0.093308   \n",
       "Sk_Yds      -0.121350 -0.102688 -0.098659 -0.125533 -0.090011 -0.084669   \n",
       "Y/A          0.295578  0.296937  0.224560  0.273352  0.196155  0.254095   \n",
       "AY/A         0.293914  0.313789  0.254973  0.253864  0.095552  0.244254   \n",
       "Ru_Att       0.020127 -0.110852 -0.075976 -0.125627 -0.147454 -0.040871   \n",
       "Ru_Yds       0.080436 -0.024177  0.117907  0.049392 -0.034148  0.099034   \n",
       "Ru_Y/A       0.090918  0.102939  0.197326  0.189211  0.117776  0.141961   \n",
       "Ru_TB        0.210893  0.158256  0.100574  0.133814  0.113793  0.158104   \n",
       "Re_Tgt      -0.120184 -0.097848 -0.037606 -0.111939 -0.166729 -0.037804   \n",
       "Re_Rec      -0.120184 -0.097848 -0.037606 -0.111939 -0.166729 -0.037804   \n",
       "Re_Yds      -0.120184 -0.097848 -0.037606 -0.111939 -0.166729 -0.037804   \n",
       "Re_Y/R            NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "Re_TD             NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "Re_Ctch%          NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "Re_Y/Tgt          NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "Total_NP_TD  0.210893  0.158256  0.100574  0.133814  0.113793  0.158104   \n",
       "Pts          0.210893  0.158256  0.100574  0.133814  0.113793  0.158104   \n",
       "Fmb          0.058754  0.019357  0.011890  0.009791 -0.030766 -0.005930   \n",
       "FL           0.038405 -0.006067 -0.059166 -0.046998 -0.093648 -0.062821   \n",
       "Dome        -0.142989 -0.110012 -0.121461 -0.066636 -0.020564 -0.073447   \n",
       "Total        0.308188  0.354164  0.327519  0.330658  0.155994  0.301105   \n",
       "RANK         0.582435  0.732926  0.539530  0.609654  0.367257  0.420176   \n",
       "PTS         -0.086350  0.002585  0.060516 -0.008386 -0.054548  0.110437   \n",
       "FPTS        -0.056903  0.121550  0.011789 -0.051604 -0.049178  0.082523   \n",
       "SACKS       -0.077493 -0.010617  0.109157 -0.029581 -0.073654  0.213551   \n",
       "INT          0.054154  0.100820  0.205802  0.114604  0.029030  0.312346   \n",
       "TO           0.043313  0.115228  0.244044  0.159194  0.076688  0.375765   \n",
       "PTS.1        0.768764  0.976168  0.902938  0.883679  0.504125  0.883457   \n",
       "PLAYS        0.608559  0.752141  0.858322  0.712165  0.302709  0.921974   \n",
       "YDS          0.699949  0.884664  0.904454  0.806942  0.383882  0.965521   \n",
       "PASS YDS     0.602368  0.831719  0.832603  0.753080  0.388091  0.920215   \n",
       "PASS ATT     0.506025  0.648270  0.776872  0.642162  0.286894  0.875498   \n",
       "PASS COMP    0.566170  0.705512  0.823828  0.713873  0.340724  0.902370   \n",
       "PASS TD      0.394614  0.890552  0.700489  0.793770  0.615772  0.741285   \n",
       "RUSH YDS     0.739913  0.800488  0.852306  0.740816  0.295340  0.849774   \n",
       "RUSH ATT     0.689434  0.814237  0.866795  0.738431  0.305405  0.868289   \n",
       "RUSH TD      1.000000  0.745442  0.792632  0.757575  0.372647  0.738563   \n",
       "TD_right     0.745442  1.000000  0.873593  0.910967  0.592111  0.870352   \n",
       "RZ ATT       0.792632  0.873593  1.000000  0.889701  0.383152  0.940382   \n",
       "RZ TD        0.757575  0.910967  0.889701  1.000000  0.744231  0.869635   \n",
       "RZ TD%       0.372647  0.592111  0.383152  0.744231  1.000000  0.451707   \n",
       "1D           0.738563  0.870352  0.940382  0.869635  0.451707  1.000000   \n",
       "3D%          0.522233  0.636853  0.629662  0.670148  0.399210  0.650645   \n",
       "4D%          0.284535  0.349711  0.373583  0.401773  0.327199  0.367379   \n",
       "\n",
       "                  3D%       4D%  \n",
       "Rk           0.085507  0.230744  \n",
       "Year         0.093306  0.220464  \n",
       "G#          -0.019220  0.069353  \n",
       "Week        -0.024762  0.064446  \n",
       "Age          0.092977  0.222458  \n",
       "Home        -0.193663  0.145605  \n",
       "Cmp          0.214352  0.002511  \n",
       "Att          0.123413 -0.108816  \n",
       "Cmp%         0.186627  0.154311  \n",
       "Yds          0.269464  0.112492  \n",
       "TD_left      0.325096  0.162639  \n",
       "Int          0.083749 -0.054077  \n",
       "Rate         0.224374  0.217468  \n",
       "Sk          -0.044932 -0.061918  \n",
       "Sk_Yds      -0.028034 -0.005910  \n",
       "Y/A          0.197926  0.224368  \n",
       "AY/A         0.191813  0.215548  \n",
       "Ru_Att      -0.087120 -0.064829  \n",
       "Ru_Yds       0.035073  0.033370  \n",
       "Ru_Y/A       0.134433  0.073471  \n",
       "Ru_TB        0.144328  0.198498  \n",
       "Re_Tgt      -0.057456  0.038400  \n",
       "Re_Rec      -0.057456  0.038400  \n",
       "Re_Yds      -0.057456  0.038400  \n",
       "Re_Y/R            NaN       NaN  \n",
       "Re_TD             NaN       NaN  \n",
       "Re_Ctch%          NaN       NaN  \n",
       "Re_Y/Tgt          NaN       NaN  \n",
       "Total_NP_TD  0.144328  0.198498  \n",
       "Pts          0.144328  0.198498  \n",
       "Fmb         -0.017956 -0.090975  \n",
       "FL           0.091811 -0.256841  \n",
       "Dome         0.070518  0.015414  \n",
       "Total        0.341437  0.215686  \n",
       "RANK         0.439243  0.212193  \n",
       "PTS         -0.018415 -0.147382  \n",
       "FPTS        -0.134737 -0.213838  \n",
       "SACKS       -0.173857  0.036353  \n",
       "INT          0.015906  0.025415  \n",
       "TO           0.120129  0.020966  \n",
       "PTS.1        0.628120  0.384184  \n",
       "PLAYS        0.486446  0.241927  \n",
       "YDS          0.640405  0.314770  \n",
       "PASS YDS     0.614002  0.291941  \n",
       "PASS ATT     0.465187  0.235781  \n",
       "PASS COMP    0.578147  0.276196  \n",
       "PASS TD      0.575164  0.352421  \n",
       "RUSH YDS     0.556654  0.292454  \n",
       "RUSH ATT     0.492564  0.223349  \n",
       "RUSH TD      0.522233  0.284535  \n",
       "TD_right     0.636853  0.349711  \n",
       "RZ ATT       0.629662  0.373583  \n",
       "RZ TD        0.670148  0.401773  \n",
       "RZ TD%       0.399210  0.327199  \n",
       "1D           0.650645  0.367379  \n",
       "3D%          1.000000  0.185137  \n",
       "4D%          0.185137  1.000000  \n",
       "\n",
       "[57 rows x 57 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 83 entries, 0 to 82\n",
      "Data columns (total 61 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   Rk           83 non-null     float64\n",
      " 1   Year         83 non-null     int64  \n",
      " 2   Date         83 non-null     object \n",
      " 3   G#           83 non-null     float64\n",
      " 4   Week         83 non-null     float64\n",
      " 5   Age          83 non-null     float64\n",
      " 6   Tm           83 non-null     object \n",
      " 7   Home         83 non-null     float64\n",
      " 8   Opp          83 non-null     object \n",
      " 9   Cmp          83 non-null     float64\n",
      " 10  Att          83 non-null     float64\n",
      " 11  Cmp%         83 non-null     float64\n",
      " 12  Yds          83 non-null     float64\n",
      " 13  TD_left      83 non-null     float64\n",
      " 14  Int          83 non-null     float64\n",
      " 15  Rate         83 non-null     float64\n",
      " 16  Sk           83 non-null     float64\n",
      " 17  Sk_Yds       83 non-null     float64\n",
      " 18  Y/A          83 non-null     float64\n",
      " 19  AY/A         83 non-null     float64\n",
      " 20  Ru_Att       83 non-null     float64\n",
      " 21  Ru_Yds       83 non-null     float64\n",
      " 22  Ru_Y/A       62 non-null     float64\n",
      " 23  Ru_TB        83 non-null     float64\n",
      " 24  Re_Tgt       83 non-null     float64\n",
      " 25  Re_Rec       83 non-null     float64\n",
      " 26  Re_Yds       83 non-null     float64\n",
      " 27  Re_Y/R       1 non-null      float64\n",
      " 28  Re_TD        83 non-null     float64\n",
      " 29  Re_Ctch%     0 non-null      float64\n",
      " 30  Re_Y/Tgt     1 non-null      float64\n",
      " 31  Total_NP_TD  83 non-null     float64\n",
      " 32  Pts          83 non-null     float64\n",
      " 33  Fmb          83 non-null     float64\n",
      " 34  FL           83 non-null     float64\n",
      " 35  Dome         83 non-null     int64  \n",
      " 36  Total        83 non-null     float64\n",
      " 37  RANK         83 non-null     int64  \n",
      " 38  NAME         83 non-null     object \n",
      " 39  PTS          83 non-null     int64  \n",
      " 40  FPTS         83 non-null     int64  \n",
      " 41  SACKS        83 non-null     int64  \n",
      " 42  INT          83 non-null     int64  \n",
      " 43  TO           83 non-null     int64  \n",
      " 44  PTS.1        83 non-null     int64  \n",
      " 45  PLAYS        83 non-null     int64  \n",
      " 46  YDS          83 non-null     int64  \n",
      " 47  PASS YDS     83 non-null     int64  \n",
      " 48  PASS ATT     83 non-null     int64  \n",
      " 49  PASS COMP    83 non-null     int64  \n",
      " 50  PASS TD      83 non-null     int64  \n",
      " 51  RUSH YDS     83 non-null     int64  \n",
      " 52  RUSH ATT     83 non-null     int64  \n",
      " 53  RUSH TD      83 non-null     int64  \n",
      " 54  TD_right     83 non-null     int64  \n",
      " 55  RZ ATT       83 non-null     int64  \n",
      " 56  RZ TD        83 non-null     int64  \n",
      " 57  RZ TD%       83 non-null     float64\n",
      " 58  1D           83 non-null     int64  \n",
      " 59  3D%          83 non-null     float64\n",
      " 60  4D%          83 non-null     float64\n",
      "dtypes: float64(35), int64(22), object(4)\n",
      "memory usage: 39.7+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(['Total','Date', 'Tm', 'Re_Y/R', 'Re_Ctch%', 'Re_Y/Tgt'], axis=1)\n",
    "y = df['Total']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42,test_size=.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#subpipes that scale numeric data and use one hot encoder on categorical \n",
    "subpipe_num = Pipeline(steps=[\n",
    "    ('num_impute', SimpleImputer(strategy='mean')),\n",
    "    ('ss', StandardScaler())\n",
    "])\n",
    "\n",
    "subpipe_cat = Pipeline(steps=[\n",
    "    ('cat_impute',SimpleImputer(strategy='most_frequent')),\n",
    "    ('ohe', OneHotEncoder(sparse=False, handle_unknown='ignore'))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cat_feat = ['Player', 'Team', 'Opp', 'Day']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "CT = ColumnTransformer(transformers=[\n",
    "    ('subpipe_num', subpipe_num, selector(dtype_include=np.number)),\n",
    "     ('subpipe_cat', subpipe_cat, selector(dtype_include=object))], remainder='passthrough')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(66, 55)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a pipeline for dummy model\n",
    "dummy_model_pipe = Pipeline(steps=[\n",
    "    ('ct', CT),\n",
    "    ('dum', DummyRegressor(strategy='median'))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.010661927004583127"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dummy_model_pipe.fit(X_train, y_train)\n",
    "dummy_model_pipe.score(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rk</th>\n",
       "      <th>Year</th>\n",
       "      <th>G#</th>\n",
       "      <th>Week</th>\n",
       "      <th>Age</th>\n",
       "      <th>Home</th>\n",
       "      <th>Opp</th>\n",
       "      <th>Cmp</th>\n",
       "      <th>Att</th>\n",
       "      <th>Cmp%</th>\n",
       "      <th>...</th>\n",
       "      <th>RUSH YDS</th>\n",
       "      <th>RUSH ATT</th>\n",
       "      <th>RUSH TD</th>\n",
       "      <th>TD_right</th>\n",
       "      <th>RZ ATT</th>\n",
       "      <th>RZ TD</th>\n",
       "      <th>RZ TD%</th>\n",
       "      <th>1D</th>\n",
       "      <th>3D%</th>\n",
       "      <th>4D%</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>340.0</td>\n",
       "      <td>2021</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>44.061</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NWE</td>\n",
       "      <td>22.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>51.16</td>\n",
       "      <td>...</td>\n",
       "      <td>2103</td>\n",
       "      <td>464</td>\n",
       "      <td>9</td>\n",
       "      <td>35</td>\n",
       "      <td>48</td>\n",
       "      <td>23</td>\n",
       "      <td>47.9</td>\n",
       "      <td>308</td>\n",
       "      <td>36.5</td>\n",
       "      <td>53.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>328.0</td>\n",
       "      <td>2020</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>43.091</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NYG</td>\n",
       "      <td>28.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>70.00</td>\n",
       "      <td>...</td>\n",
       "      <td>1782</td>\n",
       "      <td>432</td>\n",
       "      <td>14</td>\n",
       "      <td>37</td>\n",
       "      <td>59</td>\n",
       "      <td>30</td>\n",
       "      <td>50.8</td>\n",
       "      <td>353</td>\n",
       "      <td>44.6</td>\n",
       "      <td>61.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>312.0</td>\n",
       "      <td>2019</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>42.085</td>\n",
       "      <td>1.0</td>\n",
       "      <td>CLE</td>\n",
       "      <td>20.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>55.56</td>\n",
       "      <td>...</td>\n",
       "      <td>2315</td>\n",
       "      <td>463</td>\n",
       "      <td>19</td>\n",
       "      <td>46</td>\n",
       "      <td>57</td>\n",
       "      <td>35</td>\n",
       "      <td>61.4</td>\n",
       "      <td>345</td>\n",
       "      <td>37.9</td>\n",
       "      <td>35.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>281.0</td>\n",
       "      <td>2017</td>\n",
       "      <td>9.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>40.101</td>\n",
       "      <td>0.0</td>\n",
       "      <td>DEN</td>\n",
       "      <td>25.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>73.53</td>\n",
       "      <td>...</td>\n",
       "      <td>1430</td>\n",
       "      <td>428</td>\n",
       "      <td>9</td>\n",
       "      <td>44</td>\n",
       "      <td>41</td>\n",
       "      <td>24</td>\n",
       "      <td>58.5</td>\n",
       "      <td>266</td>\n",
       "      <td>31.6</td>\n",
       "      <td>33.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>336.0</td>\n",
       "      <td>2020</td>\n",
       "      <td>16.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>43.153</td>\n",
       "      <td>1.0</td>\n",
       "      <td>ATL</td>\n",
       "      <td>26.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>63.41</td>\n",
       "      <td>...</td>\n",
       "      <td>1677</td>\n",
       "      <td>380</td>\n",
       "      <td>15</td>\n",
       "      <td>49</td>\n",
       "      <td>56</td>\n",
       "      <td>36</td>\n",
       "      <td>64.3</td>\n",
       "      <td>367</td>\n",
       "      <td>41.0</td>\n",
       "      <td>43.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>293.0</td>\n",
       "      <td>2018</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>41.062</td>\n",
       "      <td>1.0</td>\n",
       "      <td>IND</td>\n",
       "      <td>34.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>77.27</td>\n",
       "      <td>...</td>\n",
       "      <td>1626</td>\n",
       "      <td>415</td>\n",
       "      <td>12</td>\n",
       "      <td>37</td>\n",
       "      <td>43</td>\n",
       "      <td>23</td>\n",
       "      <td>53.5</td>\n",
       "      <td>315</td>\n",
       "      <td>41.0</td>\n",
       "      <td>46.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>334.0</td>\n",
       "      <td>2020</td>\n",
       "      <td>14.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>43.139</td>\n",
       "      <td>0.0</td>\n",
       "      <td>ATL</td>\n",
       "      <td>31.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>68.89</td>\n",
       "      <td>...</td>\n",
       "      <td>1677</td>\n",
       "      <td>380</td>\n",
       "      <td>15</td>\n",
       "      <td>49</td>\n",
       "      <td>56</td>\n",
       "      <td>36</td>\n",
       "      <td>64.3</td>\n",
       "      <td>367</td>\n",
       "      <td>41.0</td>\n",
       "      <td>43.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>344.0</td>\n",
       "      <td>2021</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>44.089</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NOR</td>\n",
       "      <td>28.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>70.00</td>\n",
       "      <td>...</td>\n",
       "      <td>1589</td>\n",
       "      <td>426</td>\n",
       "      <td>12</td>\n",
       "      <td>35</td>\n",
       "      <td>46</td>\n",
       "      <td>20</td>\n",
       "      <td>43.5</td>\n",
       "      <td>304</td>\n",
       "      <td>37.1</td>\n",
       "      <td>42.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>286.0</td>\n",
       "      <td>2017</td>\n",
       "      <td>14.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>40.136</td>\n",
       "      <td>0.0</td>\n",
       "      <td>PIT</td>\n",
       "      <td>22.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>62.86</td>\n",
       "      <td>...</td>\n",
       "      <td>1693</td>\n",
       "      <td>385</td>\n",
       "      <td>14</td>\n",
       "      <td>36</td>\n",
       "      <td>39</td>\n",
       "      <td>24</td>\n",
       "      <td>61.5</td>\n",
       "      <td>270</td>\n",
       "      <td>36.2</td>\n",
       "      <td>31.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>323.0</td>\n",
       "      <td>2020</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>43.055</td>\n",
       "      <td>0.0</td>\n",
       "      <td>DEN</td>\n",
       "      <td>25.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>65.79</td>\n",
       "      <td>...</td>\n",
       "      <td>2080</td>\n",
       "      <td>434</td>\n",
       "      <td>22</td>\n",
       "      <td>44</td>\n",
       "      <td>61</td>\n",
       "      <td>29</td>\n",
       "      <td>47.5</td>\n",
       "      <td>333</td>\n",
       "      <td>40.2</td>\n",
       "      <td>50.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>66 rows × 55 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Rk  Year    G#  Week     Age  Home  Opp   Cmp   Att   Cmp%  ...  \\\n",
       "67  340.0  2021   4.0   4.0  44.061   0.0  NWE  22.0  43.0  51.16  ...   \n",
       "56  328.0  2020   8.0   8.0  43.091   0.0  NYG  28.0  40.0  70.00  ...   \n",
       "40  312.0  2019   8.0   8.0  42.085   1.0  CLE  20.0  36.0  55.56  ...   \n",
       "9   281.0  2017   9.0  10.0  40.101   0.0  DEN  25.0  34.0  73.53  ...   \n",
       "61  336.0  2020  16.0  17.0  43.153   1.0  ATL  26.0  41.0  63.41  ...   \n",
       "..    ...   ...   ...   ...     ...   ...  ...   ...   ...    ...  ...   \n",
       "20  293.0  2018   5.0   5.0  41.062   1.0  IND  34.0  44.0  77.27  ...   \n",
       "60  334.0  2020  14.0  15.0  43.139   0.0  ATL  31.0  45.0  68.89  ...   \n",
       "71  344.0  2021   8.0   8.0  44.089   0.0  NOR  28.0  40.0  70.00  ...   \n",
       "14  286.0  2017  14.0  15.0  40.136   0.0  PIT  22.0  35.0  62.86  ...   \n",
       "51  323.0  2020   3.0   3.0  43.055   0.0  DEN  25.0  38.0  65.79  ...   \n",
       "\n",
       "    RUSH YDS  RUSH ATT  RUSH TD  TD_right  RZ ATT  RZ TD  RZ TD%   1D   3D%  \\\n",
       "67      2103       464        9        35      48     23    47.9  308  36.5   \n",
       "56      1782       432       14        37      59     30    50.8  353  44.6   \n",
       "40      2315       463       19        46      57     35    61.4  345  37.9   \n",
       "9       1430       428        9        44      41     24    58.5  266  31.6   \n",
       "61      1677       380       15        49      56     36    64.3  367  41.0   \n",
       "..       ...       ...      ...       ...     ...    ...     ...  ...   ...   \n",
       "20      1626       415       12        37      43     23    53.5  315  41.0   \n",
       "60      1677       380       15        49      56     36    64.3  367  41.0   \n",
       "71      1589       426       12        35      46     20    43.5  304  37.1   \n",
       "14      1693       385       14        36      39     24    61.5  270  36.2   \n",
       "51      2080       434       22        44      61     29    47.5  333  40.2   \n",
       "\n",
       "     4D%  \n",
       "67  53.1  \n",
       "56  61.1  \n",
       "40  35.3  \n",
       "9   33.3  \n",
       "61  43.5  \n",
       "..   ...  \n",
       "20  46.7  \n",
       "60  43.5  \n",
       "71  42.9  \n",
       "14  31.6  \n",
       "51  50.0  \n",
       "\n",
       "[66 rows x 55 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple Regression Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "regressors = [\n",
    "    \n",
    "    LinearRegression(),\n",
    "    Ridge(),\n",
    "    Lasso(),\n",
    "    SVR(),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LinearRegression()\n",
      "model score: 1.000\n",
      "Ridge()\n",
      "model score: 0.995\n",
      "Lasso()\n",
      "model score: 0.882\n",
      "SVR()\n",
      "model score: 0.006\n"
     ]
    }
   ],
   "source": [
    "for regressor in regressors:\n",
    "    steps = [\n",
    "        ('ct', CT),\n",
    "        ('rg', regressor)\n",
    "    ]\n",
    "    pipeline = Pipeline(steps)\n",
    "    pipeline.fit(X_train, y_train)   \n",
    "    print(regressor)\n",
    "    print(\"model score: %.3f\" % pipeline.score(X_test, y_test))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "GB = xgb.XGBRegressor(random_state=42, max_depth=4, n_estimators=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_model_pipe = Pipeline(steps=[\n",
    "    ('ct', CT),\n",
    "    ('xgb', GB)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9999999951970597"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_model_pipe.fit(X_train, y_train)\n",
    "xgb_model_pipe.score(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.772922067366111"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_model_pipe.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'f66': 394.49909728727283,\n",
       " 'f4': 49.48782446925227,\n",
       " 'f0': 32.77533458432616,\n",
       " 'f7': 95.7566926228182,\n",
       " 'f120': 108.0439642,\n",
       " 'f17': 106.89743047416665,\n",
       " 'f116': 117.87890103333332,\n",
       " 'f139': 153.315918,\n",
       " 'f119': 58.44504729,\n",
       " 'f86': 31.365922056,\n",
       " 'f18': 80.54382482749999,\n",
       " 'f90': 227.4006612714286,\n",
       " 'f138': 302.35917179999996,\n",
       " 'f53': 242.19234423777777,\n",
       " 'f91': 240.1742121141667,\n",
       " 'f10': 94.47490656310528,\n",
       " 'f9': 64.01977525695654,\n",
       " 'f40': 186.08434643333337,\n",
       " 'f6': 52.74347865137364,\n",
       " 'f1': 85.21952926511959,\n",
       " 'f3': 52.656180856960006,\n",
       " 'f152': 13.80699062,\n",
       " 'f161': 100.91599275,\n",
       " 'f70': 251.10892278666668,\n",
       " 'f2': 45.36051557522641,\n",
       " 'f114': 52.3935547,\n",
       " 'f108': 100.860588,\n",
       " 'f46': 119.4721825875,\n",
       " 'f29': 97.45327227400001,\n",
       " 'f137': 177.47263665,\n",
       " 'f75': 263.22943291999997,\n",
       " 'f169': 123.57600858399996,\n",
       " 'f5': 55.885211533279055,\n",
       " 'f11': 82.54917195242103,\n",
       " 'f74': 254.3821975566667,\n",
       " 'f16': 79.23280558942858,\n",
       " 'f13': 91.40847152347825,\n",
       " 'f20': 257.29550504428573,\n",
       " 'f146': 100.63993733428572,\n",
       " 'f158': 67.11204592000001,\n",
       " 'f14': 72.44167999833334,\n",
       " 'f163': 90.6266289,\n",
       " 'f8': 48.54900191846155,\n",
       " 'f22': 182.166171074,\n",
       " 'f26': 122.76755837153843,\n",
       " 'f143': 165.12831356666666,\n",
       " 'f34': 89.79246000333332,\n",
       " 'f155': 391.405273,\n",
       " 'f15': 100.68799466476193,\n",
       " 'f12': 45.090845082914576,\n",
       " 'f174': 130.94055155,\n",
       " 'f44': 144.63236407249997,\n",
       " 'f35': 103.47151960000001,\n",
       " 'f45': 50.39903998,\n",
       " 'f59': 106.08894552111111,\n",
       " 'f94': 132.95574456625002,\n",
       " 'f19': 67.6620659148077,\n",
       " 'f153': 13.0860596,\n",
       " 'f97': 121.37165712857141,\n",
       " 'f39': 113.19948617285714,\n",
       " 'f62': 112.31163043625,\n",
       " 'f140': 118.98683620000001,\n",
       " 'f170': 99.4350586,\n",
       " 'f79': 91.96220725714285,\n",
       " 'f31': 74.19271645,\n",
       " 'f124': 91.05327254000001,\n",
       " 'f115': 113.93980197750001,\n",
       " 'f102': 72.12188120249999,\n",
       " 'f183': 42.40933605,\n",
       " 'f76': 69.54513459699999,\n",
       " 'f41': 97.9312263,\n",
       " 'f27': 59.571549661999995,\n",
       " 'f118': 125.52669655428572,\n",
       " 'f93': 46.193933660000006,\n",
       " 'f37': 74.217729005,\n",
       " 'f72': 54.314639851428566,\n",
       " 'f121': 120.73129916666666,\n",
       " 'f182': 95.03342594,\n",
       " 'f48': 42.12025575636364,\n",
       " 'f47': 55.691961263333326,\n",
       " 'f56': 102.65211626666667,\n",
       " 'f132': 49.48593846166667,\n",
       " 'f133': 80.90090987500001,\n",
       " 'f61': 92.12213168333334,\n",
       " 'f162': 44.1726246,\n",
       " 'f30': 71.64256098,\n",
       " 'f38': 40.3766345825,\n",
       " 'f32': 45.44292917,\n",
       " 'f128': 113.54514465,\n",
       " 'f125': 78.73130713999998,\n",
       " 'f64': 36.790704464,\n",
       " 'f52': 31.84106221444445,\n",
       " 'f99': 30.862356951111103,\n",
       " 'f43': 36.84626213833333,\n",
       " 'f117': 94.1980288,\n",
       " 'f67': 32.002074084444445,\n",
       " 'f65': 34.98047237428572,\n",
       " 'f78': 81.7234612,\n",
       " 'f147': 68.9689255,\n",
       " 'f71': 24.976455848888886,\n",
       " 'f63': 40.86307465000001,\n",
       " 'f154': 43.44188943333333,\n",
       " 'f107': 19.496956361250003,\n",
       " 'f21': 18.58976833166667,\n",
       " 'f112': 92.51280492818181,\n",
       " 'f136': 77.4363098,\n",
       " 'f51': 31.665536001666666,\n",
       " 'f96': 57.8795605,\n",
       " 'f81': 64.7625236125,\n",
       " 'f101': 34.87286728714285,\n",
       " 'f109': 33.716606139999996,\n",
       " 'f42': 51.20114028571429,\n",
       " 'f95': 32.690521724999996,\n",
       " 'f24': 15.817671611666668,\n",
       " 'f87': 18.1100018,\n",
       " 'f89': 57.743082655,\n",
       " 'f23': 46.801144985714295,\n",
       " 'f122': 21.865064,\n",
       " 'f88': 20.933763508,\n",
       " 'f180': 29.213501685199997,\n",
       " 'f131': 28.8476219,\n",
       " 'f104': 13.445484826000001,\n",
       " 'f123': 24.0326023,\n",
       " 'f172': 38.3412094,\n",
       " 'f149': 38.751811000000004,\n",
       " 'f58': 28.36852835,\n",
       " 'f179': 12.831754397999998,\n",
       " 'f98': 40.053521311428575,\n",
       " 'f54': 14.687716503333334,\n",
       " 'f36': 9.2381136048,\n",
       " 'f83': 12.12855126,\n",
       " 'f85': 36.747711179999996,\n",
       " 'f84': 41.51636754,\n",
       " 'f113': 43.13056634,\n",
       " 'f82': 49.963058466666666,\n",
       " 'f111': 51.4013939,\n",
       " 'f68': 11.20457935,\n",
       " 'f157': 14.242964749999999,\n",
       " 'f49': 35.23819666666667,\n",
       " 'f160': 19.4940872,\n",
       " 'f103': 31.287251500000004,\n",
       " 'f129': 33.670103075,\n",
       " 'f148': 10.395926793333333,\n",
       " 'f178': 10.2987356,\n",
       " 'f134': 53.67634963333334,\n",
       " 'f25': 56.5009136,\n",
       " 'f77': 49.9825935,\n",
       " 'f165': 8.71640873,\n",
       " 'f57': 13.37225105,\n",
       " 'f141': 34.3215446,\n",
       " 'f151': 19.4145241,\n",
       " 'f69': 27.24300005,\n",
       " 'f110': 15.0260401,\n",
       " 'f127': 52.791377999999995,\n",
       " 'f175': 51.9302788,\n",
       " 'f60': 14.5200768}"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GB.get_booster().get_score(importance_type='gain')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.00270671, 0.00703774, 0.00374604, 0.00434854, 0.00408689,\n",
       "       0.0046152 , 0.00435575, 0.00790794, 0.00400935, 0.00528699,\n",
       "       0.00780208, 0.00681721, 0.00372377, 0.00754885, 0.0059825 ,\n",
       "       0.00831518, 0.00654333, 0.00882798, 0.0066516 , 0.00558778,\n",
       "       0.0212484 , 0.00153521, 0.01504395, 0.00386501, 0.00130628,\n",
       "       0.00466605, 0.01013859, 0.00491964, 0.        , 0.00804805,\n",
       "       0.0059165 , 0.00612711, 0.00375284, 0.        , 0.00741539,\n",
       "       0.00854506, 0.00076292, 0.00612917, 0.00333445, 0.00934843,\n",
       "       0.01536753, 0.00808752, 0.00422838, 0.0030429 , 0.01194427,\n",
       "       0.00416214, 0.00986645, 0.00459925, 0.00347844, 0.0029101 ,\n",
       "       0.        , 0.00261506, 0.00262955, 0.02000113, 0.00121297,\n",
       "       0.        , 0.00847739, 0.00110433, 0.00234278, 0.00876121,\n",
       "       0.00119912, 0.00760778, 0.0092751 , 0.00337462, 0.00303831,\n",
       "       0.00288882, 0.03257918, 0.00264285, 0.00092532, 0.00224983,\n",
       "       0.02073749, 0.00206265, 0.0044855 , 0.        , 0.02100781,\n",
       "       0.02173845, 0.00574329, 0.00412775, 0.00674902, 0.00759458,\n",
       "       0.        , 0.00534833, 0.00412613, 0.00100162, 0.00342857,\n",
       "       0.00303476, 0.00259031, 0.00149559, 0.00172879, 0.00476864,\n",
       "       0.01877958, 0.01983446, 0.        , 0.00381486, 0.01097997,\n",
       "       0.0026997 , 0.00477991, 0.01002332, 0.00330777, 0.00254873,\n",
       "       0.        , 0.00287993, 0.00595609, 0.00258382, 0.00111038,\n",
       "       0.        , 0.        , 0.00161013, 0.00832944, 0.00278444,\n",
       "       0.00124091, 0.00424492, 0.00764005, 0.00356188, 0.00432685,\n",
       "       0.00940957, 0.00973487, 0.00777922, 0.01036645, 0.00482661,\n",
       "       0.00892267, 0.00997043, 0.0018057 , 0.0019847 , 0.00751951,\n",
       "       0.00650192, 0.        , 0.0043597 , 0.00937697, 0.0027806 ,\n",
       "       0.        , 0.00238234, 0.00408673, 0.00668109, 0.00443279,\n",
       "       0.        , 0.00639497, 0.01465634, 0.02496992, 0.01266139,\n",
       "       0.00982637, 0.0028344 , 0.        , 0.0136369 , 0.        ,\n",
       "       0.        , 0.00831121, 0.00569571, 0.00085853, 0.00320027,\n",
       "       0.        , 0.00160332, 0.00114023, 0.00108069, 0.00358759,\n",
       "       0.03232368, 0.        , 0.00117624, 0.00554236, 0.        ,\n",
       "       0.00160989, 0.00833401, 0.00364794, 0.00748428, 0.        ,\n",
       "       0.00071983, 0.        , 0.        , 0.        , 0.01020536,\n",
       "       0.00821171, 0.        , 0.00316636, 0.        , 0.01081355,\n",
       "       0.00428859, 0.        , 0.        , 0.00085051, 0.00105969,\n",
       "       0.00241256, 0.        , 0.00784821, 0.00350232, 0.        ,\n",
       "       0.        ], dtype=float32)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GB.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer_pipe = Pipeline(steps=[\n",
    "    ('ct', CT)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 1011 entries, 32 to 1126\n",
      "Data columns (total 24 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   Player    1011 non-null   object \n",
      " 1   Day       1011 non-null   object \n",
      " 2   Week      1011 non-null   int64  \n",
      " 3   Age       1011 non-null   int64  \n",
      " 4   Team      1011 non-null   object \n",
      " 5   Home      1011 non-null   int64  \n",
      " 6   Opp       1011 non-null   object \n",
      " 7   Dome      1011 non-null   int64  \n",
      " 8   RANK      1011 non-null   int64  \n",
      " 9   PTS       1011 non-null   int64  \n",
      " 10  SACKS     1011 non-null   int64  \n",
      " 11  INT       1011 non-null   int64  \n",
      " 12  TO        1011 non-null   int64  \n",
      " 13  PTS.1     1011 non-null   int64  \n",
      " 14  PASS YDS  1011 non-null   int64  \n",
      " 15  PASS TD   1011 non-null   int64  \n",
      " 16  RUSH YDS  1011 non-null   int64  \n",
      " 17  RUSH TD   1011 non-null   int64  \n",
      " 18  RZ ATT    1011 non-null   int64  \n",
      " 19  RZ TD     1011 non-null   int64  \n",
      " 20  RZ TD%    1011 non-null   float64\n",
      " 21  1D        1011 non-null   int64  \n",
      " 22  3D%       1011 non-null   float64\n",
      " 23  4D%       1011 non-null   float64\n",
      "dtypes: float64(3), int64(17), object(4)\n",
      "memory usage: 197.5+ KB\n"
     ]
    }
   ],
   "source": [
    "X_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "ohe = OneHotEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_ohe = ohe.fit_transform(X_train[['Day', 'Team', 'Opp']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_ohe = ohe.transform(X_test[['Day', 'Team', 'Opp']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Network "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<1011x71 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 3033 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_ohe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Day</th>\n",
       "      <th>Week</th>\n",
       "      <th>Age</th>\n",
       "      <th>Team</th>\n",
       "      <th>Home</th>\n",
       "      <th>Opp</th>\n",
       "      <th>Dome</th>\n",
       "      <th>RANK</th>\n",
       "      <th>PTS</th>\n",
       "      <th>SACKS</th>\n",
       "      <th>...</th>\n",
       "      <th>PASS YDS</th>\n",
       "      <th>PASS TD</th>\n",
       "      <th>RUSH YDS</th>\n",
       "      <th>RUSH TD</th>\n",
       "      <th>RZ ATT</th>\n",
       "      <th>RZ TD</th>\n",
       "      <th>RZ TD%</th>\n",
       "      <th>1D</th>\n",
       "      <th>3D%</th>\n",
       "      <th>4D%</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>Sun</td>\n",
       "      <td>16</td>\n",
       "      <td>27</td>\n",
       "      <td>WAS</td>\n",
       "      <td>1</td>\n",
       "      <td>CAR</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "      <td>29</td>\n",
       "      <td>...</td>\n",
       "      <td>3825</td>\n",
       "      <td>28</td>\n",
       "      <td>1936</td>\n",
       "      <td>17</td>\n",
       "      <td>57</td>\n",
       "      <td>36</td>\n",
       "      <td>63.2</td>\n",
       "      <td>360</td>\n",
       "      <td>49.2</td>\n",
       "      <td>60.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156</th>\n",
       "      <td>Sun</td>\n",
       "      <td>5</td>\n",
       "      <td>23</td>\n",
       "      <td>ARI</td>\n",
       "      <td>0</td>\n",
       "      <td>NYJ</td>\n",
       "      <td>1</td>\n",
       "      <td>26</td>\n",
       "      <td>8</td>\n",
       "      <td>31</td>\n",
       "      <td>...</td>\n",
       "      <td>4409</td>\n",
       "      <td>34</td>\n",
       "      <td>1792</td>\n",
       "      <td>16</td>\n",
       "      <td>60</td>\n",
       "      <td>36</td>\n",
       "      <td>60.0</td>\n",
       "      <td>381</td>\n",
       "      <td>44.6</td>\n",
       "      <td>41.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>382</th>\n",
       "      <td>Thu</td>\n",
       "      <td>1</td>\n",
       "      <td>24</td>\n",
       "      <td>KAN</td>\n",
       "      <td>1</td>\n",
       "      <td>HOU</td>\n",
       "      <td>1</td>\n",
       "      <td>27</td>\n",
       "      <td>6</td>\n",
       "      <td>34</td>\n",
       "      <td>...</td>\n",
       "      <td>4104</td>\n",
       "      <td>30</td>\n",
       "      <td>2564</td>\n",
       "      <td>24</td>\n",
       "      <td>63</td>\n",
       "      <td>40</td>\n",
       "      <td>63.5</td>\n",
       "      <td>390</td>\n",
       "      <td>47.5</td>\n",
       "      <td>52.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1166</th>\n",
       "      <td>Sun</td>\n",
       "      <td>8</td>\n",
       "      <td>44</td>\n",
       "      <td>TAM</td>\n",
       "      <td>0</td>\n",
       "      <td>NOR</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>12</td>\n",
       "      <td>46</td>\n",
       "      <td>...</td>\n",
       "      <td>3821</td>\n",
       "      <td>20</td>\n",
       "      <td>1589</td>\n",
       "      <td>12</td>\n",
       "      <td>46</td>\n",
       "      <td>20</td>\n",
       "      <td>43.5</td>\n",
       "      <td>304</td>\n",
       "      <td>37.1</td>\n",
       "      <td>42.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>365</th>\n",
       "      <td>Thu</td>\n",
       "      <td>5</td>\n",
       "      <td>31</td>\n",
       "      <td>CHI</td>\n",
       "      <td>1</td>\n",
       "      <td>TAM</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>8</td>\n",
       "      <td>48</td>\n",
       "      <td>...</td>\n",
       "      <td>3945</td>\n",
       "      <td>29</td>\n",
       "      <td>1289</td>\n",
       "      <td>10</td>\n",
       "      <td>51</td>\n",
       "      <td>32</td>\n",
       "      <td>62.7</td>\n",
       "      <td>319</td>\n",
       "      <td>40.0</td>\n",
       "      <td>56.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1044</th>\n",
       "      <td>Sun</td>\n",
       "      <td>17</td>\n",
       "      <td>23</td>\n",
       "      <td>BAL</td>\n",
       "      <td>1</td>\n",
       "      <td>LAR</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>49</td>\n",
       "      <td>...</td>\n",
       "      <td>4109</td>\n",
       "      <td>17</td>\n",
       "      <td>1754</td>\n",
       "      <td>18</td>\n",
       "      <td>56</td>\n",
       "      <td>29</td>\n",
       "      <td>51.8</td>\n",
       "      <td>347</td>\n",
       "      <td>41.3</td>\n",
       "      <td>53.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1095</th>\n",
       "      <td>Thu</td>\n",
       "      <td>11</td>\n",
       "      <td>24</td>\n",
       "      <td>ATL</td>\n",
       "      <td>1</td>\n",
       "      <td>NWE</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>18</td>\n",
       "      <td>36</td>\n",
       "      <td>...</td>\n",
       "      <td>3181</td>\n",
       "      <td>21</td>\n",
       "      <td>2103</td>\n",
       "      <td>9</td>\n",
       "      <td>48</td>\n",
       "      <td>23</td>\n",
       "      <td>47.9</td>\n",
       "      <td>308</td>\n",
       "      <td>36.5</td>\n",
       "      <td>53.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1130</th>\n",
       "      <td>Sun</td>\n",
       "      <td>10</td>\n",
       "      <td>36</td>\n",
       "      <td>NYJ</td>\n",
       "      <td>1</td>\n",
       "      <td>BUF</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>41</td>\n",
       "      <td>...</td>\n",
       "      <td>2771</td>\n",
       "      <td>12</td>\n",
       "      <td>1866</td>\n",
       "      <td>19</td>\n",
       "      <td>45</td>\n",
       "      <td>23</td>\n",
       "      <td>51.1</td>\n",
       "      <td>285</td>\n",
       "      <td>30.8</td>\n",
       "      <td>45.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>860</th>\n",
       "      <td>Sun</td>\n",
       "      <td>16</td>\n",
       "      <td>33</td>\n",
       "      <td>LAR</td>\n",
       "      <td>0</td>\n",
       "      <td>MIN</td>\n",
       "      <td>2</td>\n",
       "      <td>24</td>\n",
       "      <td>12</td>\n",
       "      <td>51</td>\n",
       "      <td>...</td>\n",
       "      <td>4300</td>\n",
       "      <td>29</td>\n",
       "      <td>2222</td>\n",
       "      <td>15</td>\n",
       "      <td>59</td>\n",
       "      <td>33</td>\n",
       "      <td>55.9</td>\n",
       "      <td>391</td>\n",
       "      <td>36.4</td>\n",
       "      <td>50.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1126</th>\n",
       "      <td>Mon</td>\n",
       "      <td>6</td>\n",
       "      <td>33</td>\n",
       "      <td>TEN</td>\n",
       "      <td>1</td>\n",
       "      <td>BUF</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>41</td>\n",
       "      <td>...</td>\n",
       "      <td>2771</td>\n",
       "      <td>12</td>\n",
       "      <td>1866</td>\n",
       "      <td>19</td>\n",
       "      <td>45</td>\n",
       "      <td>23</td>\n",
       "      <td>51.1</td>\n",
       "      <td>285</td>\n",
       "      <td>30.8</td>\n",
       "      <td>45.7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1011 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Day  Week  Age Team  Home  Opp  Dome  RANK  PTS  SACKS  ...  PASS YDS  \\\n",
       "32    Sun    16   27  WAS     1  CAR     0    18   18     29  ...      3825   \n",
       "156   Sun     5   23  ARI     0  NYJ     1    26    8     31  ...      4409   \n",
       "382   Thu     1   24  KAN     1  HOU     1    27    6     34  ...      4104   \n",
       "1166  Sun     8   44  TAM     0  NOR     1     4   12     46  ...      3821   \n",
       "365   Thu     5   31  CHI     1  TAM     0     9    8     48  ...      3945   \n",
       "...   ...   ...  ...  ...   ...  ...   ...   ...  ...    ...  ...       ...   \n",
       "1044  Sun    17   23  BAL     1  LAR     1    15    0     49  ...      4109   \n",
       "1095  Thu    11   24  ATL     1  NWE     1     2   18     36  ...      3181   \n",
       "1130  Sun    10   36  NYJ     1  BUF     0     1    8     41  ...      2771   \n",
       "860   Sun    16   33  LAR     0  MIN     2    24   12     51  ...      4300   \n",
       "1126  Mon     6   33  TEN     1  BUF     0     1    8     41  ...      2771   \n",
       "\n",
       "      PASS TD  RUSH YDS  RUSH TD  RZ ATT  RZ TD  RZ TD%   1D   3D%   4D%  \n",
       "32         28      1936       17      57     36    63.2  360  49.2  60.0  \n",
       "156        34      1792       16      60     36    60.0  381  44.6  41.7  \n",
       "382        30      2564       24      63     40    63.5  390  47.5  52.4  \n",
       "1166       20      1589       12      46     20    43.5  304  37.1  42.9  \n",
       "365        29      1289       10      51     32    62.7  319  40.0  56.0  \n",
       "...       ...       ...      ...     ...    ...     ...  ...   ...   ...  \n",
       "1044       17      1754       18      56     29    51.8  347  41.3  53.1  \n",
       "1095       21      2103        9      48     23    47.9  308  36.5  53.1  \n",
       "1130       12      1866       19      45     23    51.1  285  30.8  45.7  \n",
       "860        29      2222       15      59     33    55.9  391  36.4  50.0  \n",
       "1126       12      1866       19      45     23    51.1  285  30.8  45.7  \n",
       "\n",
       "[1011 rows x 23 columns]"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale_datasets(X_train_ohe, X_test_ohe):\n",
    "    standard_scaler = StandardScaler()\n",
    "    X_train_scaled = pd.DataFrame(\n",
    "        standard_scaler.fit_transform(X_train_ohe),\n",
    "        columns=X_train_ohe.columns\n",
    "  )\n",
    "    X_test_scaled = pd.DataFrame(\n",
    "        standard_scaler.transform(X_test_ohe),\n",
    "        columns = X_test_ohe.columns\n",
    "  )\n",
    "    return X_train_scaled, X_test_scaled\n",
    "X_train_scaled, X_test_scaled = scale_datasets(X_train_ohe, X_test_ohe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_units1 = 32\n",
    "hidden_units2 = 64\n",
    "hidden_units3 = 128\n",
    "learning_rate = 0.01\n",
    "# Creating model using the Sequential in tensorflow\n",
    "def build_model_using_sequential():\n",
    "    model = Sequential([\n",
    "        Dense(hidden_units1, kernel_initializer='normal', activation='relu'),\n",
    "        Dropout(0.2),\n",
    "        Dense(hidden_units2, kernel_initializer='normal', activation='relu'),\n",
    "        Dropout(0.2),\n",
    "        Dense(hidden_units3, kernel_initializer='normal', activation='relu'),\n",
    "        Dense(1, kernel_initializer='normal', activation='linear')\n",
    "      ])\n",
    "    return model\n",
    "# build the model\n",
    "model = build_model_using_sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.2164 - accuracy: 0.0025 - val_loss: 1.1506 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.2060 - accuracy: 0.0037 - val_loss: 1.1959 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.2006 - accuracy: 0.0025 - val_loss: 1.2168 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.1865 - accuracy: 0.0037 - val_loss: 1.1928 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.1831 - accuracy: 0.0037 - val_loss: 1.2050 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.1925 - accuracy: 0.0025 - val_loss: 1.1598 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.1942 - accuracy: 0.0025 - val_loss: 1.1387 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.1834 - accuracy: 0.0025 - val_loss: 1.1392 - val_accuracy: 0.0000e+00\n",
      "Epoch 9/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.1774 - accuracy: 0.0037 - val_loss: 1.2225 - val_accuracy: 0.0000e+00\n",
      "Epoch 10/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.1663 - accuracy: 0.0037 - val_loss: 1.1890 - val_accuracy: 0.0000e+00\n",
      "Epoch 11/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.1847 - accuracy: 0.0037 - val_loss: 1.3084 - val_accuracy: 0.0000e+00\n",
      "Epoch 12/1000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.1998 - accuracy: 0.0037 - val_loss: 1.1605 - val_accuracy: 0.0000e+00\n",
      "Epoch 13/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.1855 - accuracy: 0.0037 - val_loss: 1.1910 - val_accuracy: 0.0000e+00\n",
      "Epoch 14/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.1873 - accuracy: 0.0037 - val_loss: 1.1850 - val_accuracy: 0.0000e+00\n",
      "Epoch 15/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.1682 - accuracy: 0.0037 - val_loss: 1.1874 - val_accuracy: 0.0000e+00\n",
      "Epoch 16/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.1739 - accuracy: 0.0012 - val_loss: 1.2539 - val_accuracy: 0.0000e+00\n",
      "Epoch 17/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.1636 - accuracy: 0.0037 - val_loss: 1.2611 - val_accuracy: 0.0000e+00\n",
      "Epoch 18/1000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.1644 - accuracy: 0.0037 - val_loss: 1.1772 - val_accuracy: 0.0000e+00\n",
      "Epoch 19/1000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.1691 - accuracy: 0.0025 - val_loss: 1.1910 - val_accuracy: 0.0000e+00\n",
      "Epoch 20/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.1633 - accuracy: 0.0037 - val_loss: 1.2007 - val_accuracy: 0.0000e+00\n",
      "Epoch 21/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.1676 - accuracy: 0.0037 - val_loss: 1.0965 - val_accuracy: 0.0000e+00\n",
      "Epoch 22/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.1810 - accuracy: 0.0037 - val_loss: 1.1562 - val_accuracy: 0.0000e+00\n",
      "Epoch 23/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.1616 - accuracy: 0.0025 - val_loss: 1.1737 - val_accuracy: 0.0000e+00\n",
      "Epoch 24/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.1904 - accuracy: 0.0037 - val_loss: 1.1752 - val_accuracy: 0.0000e+00\n",
      "Epoch 25/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.1609 - accuracy: 0.0025 - val_loss: 1.2008 - val_accuracy: 0.0000e+00\n",
      "Epoch 26/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.1529 - accuracy: 0.0037 - val_loss: 1.1817 - val_accuracy: 0.0000e+00\n",
      "Epoch 27/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.1707 - accuracy: 0.0037 - val_loss: 1.1837 - val_accuracy: 0.0000e+00\n",
      "Epoch 28/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.1627 - accuracy: 0.0025 - val_loss: 1.2341 - val_accuracy: 0.0000e+00\n",
      "Epoch 29/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.1613 - accuracy: 0.0037 - val_loss: 1.2249 - val_accuracy: 0.0000e+00\n",
      "Epoch 30/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.1463 - accuracy: 0.0025 - val_loss: 1.2829 - val_accuracy: 0.0000e+00\n",
      "Epoch 31/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.1650 - accuracy: 0.0037 - val_loss: 1.2086 - val_accuracy: 0.0000e+00\n",
      "Epoch 32/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.1665 - accuracy: 0.0037 - val_loss: 1.2464 - val_accuracy: 0.0000e+00\n",
      "Epoch 33/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.1709 - accuracy: 0.0025 - val_loss: 1.2151 - val_accuracy: 0.0000e+00\n",
      "Epoch 34/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.1842 - accuracy: 0.0037 - val_loss: 1.1610 - val_accuracy: 0.0000e+00\n",
      "Epoch 35/1000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.1708 - accuracy: 0.0025 - val_loss: 1.1882 - val_accuracy: 0.0000e+00\n",
      "Epoch 36/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.1648 - accuracy: 0.0025 - val_loss: 1.1349 - val_accuracy: 0.0000e+00\n",
      "Epoch 37/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.1598 - accuracy: 0.0037 - val_loss: 1.2024 - val_accuracy: 0.0000e+00\n",
      "Epoch 38/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.1633 - accuracy: 0.0025 - val_loss: 1.1403 - val_accuracy: 0.0000e+00\n",
      "Epoch 39/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.1855 - accuracy: 0.0025 - val_loss: 1.2814 - val_accuracy: 0.0000e+00\n",
      "Epoch 40/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.1628 - accuracy: 0.0025 - val_loss: 1.2975 - val_accuracy: 0.0000e+00\n",
      "Epoch 41/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.1754 - accuracy: 0.0025 - val_loss: 1.1933 - val_accuracy: 0.0000e+00\n",
      "Epoch 42/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.1505 - accuracy: 0.0037 - val_loss: 1.2109 - val_accuracy: 0.0000e+00\n",
      "Epoch 43/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.1579 - accuracy: 0.0012 - val_loss: 1.2883 - val_accuracy: 0.0000e+00\n",
      "Epoch 44/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.1437 - accuracy: 0.0025 - val_loss: 1.2729 - val_accuracy: 0.0000e+00\n",
      "Epoch 45/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.1627 - accuracy: 0.0037 - val_loss: 1.1699 - val_accuracy: 0.0000e+00\n",
      "Epoch 46/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.1709 - accuracy: 0.0025 - val_loss: 1.1741 - val_accuracy: 0.0000e+00\n",
      "Epoch 47/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.1940 - accuracy: 0.0025 - val_loss: 1.1960 - val_accuracy: 0.0000e+00\n",
      "Epoch 48/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.1908 - accuracy: 0.0025 - val_loss: 1.1866 - val_accuracy: 0.0000e+00\n",
      "Epoch 49/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.1688 - accuracy: 0.0025 - val_loss: 1.1311 - val_accuracy: 0.0000e+00\n",
      "Epoch 50/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.1545 - accuracy: 0.0025 - val_loss: 1.1857 - val_accuracy: 0.0000e+00\n",
      "Epoch 51/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.1494 - accuracy: 0.0012 - val_loss: 1.1893 - val_accuracy: 0.0000e+00\n",
      "Epoch 52/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.1650 - accuracy: 0.0025 - val_loss: 1.2092 - val_accuracy: 0.0000e+00\n",
      "Epoch 53/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.1491 - accuracy: 0.0025 - val_loss: 1.1795 - val_accuracy: 0.0000e+00\n",
      "Epoch 54/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.1562 - accuracy: 0.0025 - val_loss: 1.2170 - val_accuracy: 0.0000e+00\n",
      "Epoch 55/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.1545 - accuracy: 0.0025 - val_loss: 1.2021 - val_accuracy: 0.0000e+00\n",
      "Epoch 56/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.1411 - accuracy: 0.0025 - val_loss: 1.2408 - val_accuracy: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.1415 - accuracy: 0.0012 - val_loss: 1.3457 - val_accuracy: 0.0000e+00\n",
      "Epoch 58/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.1301 - accuracy: 0.0025 - val_loss: 1.2927 - val_accuracy: 0.0000e+00\n",
      "Epoch 59/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.1454 - accuracy: 0.0037 - val_loss: 1.2453 - val_accuracy: 0.0000e+00\n",
      "Epoch 60/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.1478 - accuracy: 0.0037 - val_loss: 1.2008 - val_accuracy: 0.0000e+00\n",
      "Epoch 61/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.1522 - accuracy: 0.0025 - val_loss: 1.3151 - val_accuracy: 0.0000e+00\n",
      "Epoch 62/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.1492 - accuracy: 0.0037 - val_loss: 1.2393 - val_accuracy: 0.0000e+00\n",
      "Epoch 63/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.1668 - accuracy: 0.0025 - val_loss: 1.1934 - val_accuracy: 0.0000e+00\n",
      "Epoch 64/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.1590 - accuracy: 0.0025 - val_loss: 1.2016 - val_accuracy: 0.0000e+00\n",
      "Epoch 65/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.1313 - accuracy: 0.0012 - val_loss: 1.2193 - val_accuracy: 0.0000e+00\n",
      "Epoch 66/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.1503 - accuracy: 0.0025 - val_loss: 1.2445 - val_accuracy: 0.0000e+00\n",
      "Epoch 67/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.1510 - accuracy: 0.0025 - val_loss: 1.3262 - val_accuracy: 0.0000e+00\n",
      "Epoch 68/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.1214 - accuracy: 0.0025 - val_loss: 1.3218 - val_accuracy: 0.0000e+00\n",
      "Epoch 69/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.1449 - accuracy: 0.0037 - val_loss: 1.2702 - val_accuracy: 0.0000e+00\n",
      "Epoch 70/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.1366 - accuracy: 0.0025 - val_loss: 1.2988 - val_accuracy: 0.0000e+00\n",
      "Epoch 71/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.1559 - accuracy: 0.0037 - val_loss: 1.3008 - val_accuracy: 0.0000e+00\n",
      "Epoch 72/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.1383 - accuracy: 0.0037 - val_loss: 1.2158 - val_accuracy: 0.0000e+00\n",
      "Epoch 73/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.1354 - accuracy: 0.0037 - val_loss: 1.1641 - val_accuracy: 0.0000e+00\n",
      "Epoch 74/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.1351 - accuracy: 0.0025 - val_loss: 1.2025 - val_accuracy: 0.0000e+00\n",
      "Epoch 75/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.1348 - accuracy: 0.0037 - val_loss: 1.1568 - val_accuracy: 0.0000e+00\n",
      "Epoch 76/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.1438 - accuracy: 0.0025 - val_loss: 1.2489 - val_accuracy: 0.0000e+00\n",
      "Epoch 77/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.1382 - accuracy: 0.0012 - val_loss: 1.2048 - val_accuracy: 0.0000e+00\n",
      "Epoch 78/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.1214 - accuracy: 0.0025 - val_loss: 1.2677 - val_accuracy: 0.0000e+00\n",
      "Epoch 79/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.1309 - accuracy: 0.0037 - val_loss: 1.2238 - val_accuracy: 0.0000e+00\n",
      "Epoch 80/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.1255 - accuracy: 0.0037 - val_loss: 1.2652 - val_accuracy: 0.0000e+00\n",
      "Epoch 81/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.1334 - accuracy: 0.0037 - val_loss: 1.1803 - val_accuracy: 0.0000e+00\n",
      "Epoch 82/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.1488 - accuracy: 0.0037 - val_loss: 1.2087 - val_accuracy: 0.0000e+00\n",
      "Epoch 83/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.1847 - accuracy: 0.0025 - val_loss: 1.1898 - val_accuracy: 0.0000e+00\n",
      "Epoch 84/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.1606 - accuracy: 0.0037 - val_loss: 1.1592 - val_accuracy: 0.0000e+00\n",
      "Epoch 85/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.1543 - accuracy: 0.0025 - val_loss: 1.2224 - val_accuracy: 0.0000e+00\n",
      "Epoch 86/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.1427 - accuracy: 0.0037 - val_loss: 1.1703 - val_accuracy: 0.0000e+00\n",
      "Epoch 87/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.1525 - accuracy: 0.0012 - val_loss: 1.2644 - val_accuracy: 0.0000e+00\n",
      "Epoch 88/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.1368 - accuracy: 0.0025 - val_loss: 1.2053 - val_accuracy: 0.0000e+00\n",
      "Epoch 89/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.1458 - accuracy: 0.0025 - val_loss: 1.3085 - val_accuracy: 0.0000e+00\n",
      "Epoch 90/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.1782 - accuracy: 0.0025 - val_loss: 1.1879 - val_accuracy: 0.0000e+00\n",
      "Epoch 91/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.1608 - accuracy: 0.0037 - val_loss: 1.2189 - val_accuracy: 0.0000e+00\n",
      "Epoch 92/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.1533 - accuracy: 0.0037 - val_loss: 1.2465 - val_accuracy: 0.0000e+00\n",
      "Epoch 93/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.1427 - accuracy: 0.0025 - val_loss: 1.2913 - val_accuracy: 0.0000e+00\n",
      "Epoch 94/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.1418 - accuracy: 0.0037 - val_loss: 1.2093 - val_accuracy: 0.0000e+00\n",
      "Epoch 95/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.1421 - accuracy: 0.0037 - val_loss: 1.2146 - val_accuracy: 0.0000e+00\n",
      "Epoch 96/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.1316 - accuracy: 0.0037 - val_loss: 1.1984 - val_accuracy: 0.0000e+00\n",
      "Epoch 97/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.1348 - accuracy: 0.0037 - val_loss: 1.2500 - val_accuracy: 0.0000e+00\n",
      "Epoch 98/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.1355 - accuracy: 0.0037 - val_loss: 1.2271 - val_accuracy: 0.0000e+00\n",
      "Epoch 99/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.1144 - accuracy: 0.0037 - val_loss: 1.2003 - val_accuracy: 0.0000e+00\n",
      "Epoch 100/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.1297 - accuracy: 0.0037 - val_loss: 1.1892 - val_accuracy: 0.0000e+00\n",
      "Epoch 101/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.1388 - accuracy: 0.0037 - val_loss: 1.1942 - val_accuracy: 0.0000e+00\n",
      "Epoch 102/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.1538 - accuracy: 0.0025 - val_loss: 1.2498 - val_accuracy: 0.0000e+00\n",
      "Epoch 103/1000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.1303 - accuracy: 0.0012 - val_loss: 1.2265 - val_accuracy: 0.0000e+00\n",
      "Epoch 104/1000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.1318 - accuracy: 0.0037 - val_loss: 1.2174 - val_accuracy: 0.0000e+00\n",
      "Epoch 105/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.1281 - accuracy: 0.0037 - val_loss: 1.2989 - val_accuracy: 0.0000e+00\n",
      "Epoch 106/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.1241 - accuracy: 0.0037 - val_loss: 1.2837 - val_accuracy: 0.0000e+00\n",
      "Epoch 107/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.1388 - accuracy: 0.0037 - val_loss: 1.2839 - val_accuracy: 0.0000e+00\n",
      "Epoch 108/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.1246 - accuracy: 0.0025 - val_loss: 1.2239 - val_accuracy: 0.0000e+00\n",
      "Epoch 109/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.1199 - accuracy: 0.0025 - val_loss: 1.2338 - val_accuracy: 0.0000e+00\n",
      "Epoch 110/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.1255 - accuracy: 0.0037 - val_loss: 1.2385 - val_accuracy: 0.0000e+00\n",
      "Epoch 111/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.1232 - accuracy: 0.0037 - val_loss: 1.1757 - val_accuracy: 0.0000e+00\n",
      "Epoch 112/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.1090 - accuracy: 0.0037 - val_loss: 1.2791 - val_accuracy: 0.0000e+00\n",
      "Epoch 113/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.1218 - accuracy: 0.0000e+00 - val_loss: 1.3119 - val_accuracy: 0.0000e+00\n",
      "Epoch 114/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.1405 - accuracy: 0.0037 - val_loss: 1.3086 - val_accuracy: 0.0000e+00\n",
      "Epoch 115/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.1346 - accuracy: 0.0037 - val_loss: 1.2449 - val_accuracy: 0.0000e+00\n",
      "Epoch 116/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.1161 - accuracy: 0.0037 - val_loss: 1.2290 - val_accuracy: 0.0000e+00\n",
      "Epoch 117/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.1286 - accuracy: 0.0037 - val_loss: 1.2114 - val_accuracy: 0.0000e+00\n",
      "Epoch 118/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.1148 - accuracy: 0.0012 - val_loss: 1.2136 - val_accuracy: 0.0000e+00\n",
      "Epoch 119/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.1037 - accuracy: 0.0025 - val_loss: 1.2714 - val_accuracy: 0.0000e+00\n",
      "Epoch 120/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.1181 - accuracy: 0.0037 - val_loss: 1.2535 - val_accuracy: 0.0000e+00\n",
      "Epoch 121/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.1267 - accuracy: 0.0037 - val_loss: 1.2797 - val_accuracy: 0.0000e+00\n",
      "Epoch 122/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.1229 - accuracy: 0.0025 - val_loss: 1.2446 - val_accuracy: 0.0000e+00\n",
      "Epoch 123/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.1121 - accuracy: 0.0037 - val_loss: 1.2918 - val_accuracy: 0.0000e+00\n",
      "Epoch 124/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.1304 - accuracy: 0.0025 - val_loss: 1.2941 - val_accuracy: 0.0000e+00\n",
      "Epoch 125/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.1398 - accuracy: 0.0025 - val_loss: 1.1694 - val_accuracy: 0.0000e+00\n",
      "Epoch 126/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.1479 - accuracy: 0.0025 - val_loss: 1.1908 - val_accuracy: 0.0000e+00\n",
      "Epoch 127/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.1426 - accuracy: 0.0025 - val_loss: 1.1655 - val_accuracy: 0.0000e+00\n",
      "Epoch 128/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.1302 - accuracy: 0.0037 - val_loss: 1.2025 - val_accuracy: 0.0000e+00\n",
      "Epoch 129/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.1276 - accuracy: 0.0037 - val_loss: 1.2499 - val_accuracy: 0.0000e+00\n",
      "Epoch 130/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.1462 - accuracy: 0.0037 - val_loss: 1.2217 - val_accuracy: 0.0000e+00\n",
      "Epoch 131/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.1280 - accuracy: 0.0037 - val_loss: 1.2216 - val_accuracy: 0.0000e+00\n",
      "Epoch 132/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.1261 - accuracy: 0.0025 - val_loss: 1.1706 - val_accuracy: 0.0000e+00\n",
      "Epoch 133/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.1293 - accuracy: 0.0037 - val_loss: 1.2619 - val_accuracy: 0.0000e+00\n",
      "Epoch 134/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.1367 - accuracy: 0.0025 - val_loss: 1.1979 - val_accuracy: 0.0000e+00\n",
      "Epoch 135/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.1321 - accuracy: 0.0037 - val_loss: 1.2282 - val_accuracy: 0.0000e+00\n",
      "Epoch 136/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.1156 - accuracy: 0.0025 - val_loss: 1.2060 - val_accuracy: 0.0000e+00\n",
      "Epoch 137/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.1197 - accuracy: 0.0012 - val_loss: 1.1655 - val_accuracy: 0.0000e+00\n",
      "Epoch 138/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.1164 - accuracy: 0.0037 - val_loss: 1.1824 - val_accuracy: 0.0000e+00\n",
      "Epoch 139/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.1232 - accuracy: 0.0037 - val_loss: 1.1895 - val_accuracy: 0.0000e+00\n",
      "Epoch 140/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.1208 - accuracy: 0.0037 - val_loss: 1.2005 - val_accuracy: 0.0000e+00\n",
      "Epoch 141/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.1121 - accuracy: 0.0037 - val_loss: 1.2003 - val_accuracy: 0.0000e+00\n",
      "Epoch 142/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.1243 - accuracy: 0.0037 - val_loss: 1.1876 - val_accuracy: 0.0000e+00\n",
      "Epoch 143/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.1179 - accuracy: 0.0025 - val_loss: 1.1816 - val_accuracy: 0.0000e+00\n",
      "Epoch 144/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.1169 - accuracy: 0.0025 - val_loss: 1.1745 - val_accuracy: 0.0000e+00\n",
      "Epoch 145/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.1296 - accuracy: 0.0037 - val_loss: 1.1890 - val_accuracy: 0.0000e+00\n",
      "Epoch 146/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.1129 - accuracy: 0.0037 - val_loss: 1.2468 - val_accuracy: 0.0000e+00\n",
      "Epoch 147/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.1152 - accuracy: 0.0025 - val_loss: 1.2353 - val_accuracy: 0.0000e+00\n",
      "Epoch 148/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.1193 - accuracy: 0.0037 - val_loss: 1.2626 - val_accuracy: 0.0000e+00\n",
      "Epoch 149/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.1353 - accuracy: 0.0025 - val_loss: 1.2127 - val_accuracy: 0.0000e+00\n",
      "Epoch 150/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.1175 - accuracy: 0.0037 - val_loss: 1.2615 - val_accuracy: 0.0000e+00\n",
      "Epoch 151/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.1308 - accuracy: 0.0025 - val_loss: 1.1928 - val_accuracy: 0.0000e+00\n",
      "Epoch 152/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.1461 - accuracy: 0.0037 - val_loss: 1.1562 - val_accuracy: 0.0000e+00\n",
      "Epoch 153/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.1314 - accuracy: 0.0037 - val_loss: 1.2158 - val_accuracy: 0.0000e+00\n",
      "Epoch 154/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.1327 - accuracy: 0.0012 - val_loss: 1.3029 - val_accuracy: 0.0000e+00\n",
      "Epoch 155/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.1163 - accuracy: 0.0037 - val_loss: 1.2894 - val_accuracy: 0.0000e+00\n",
      "Epoch 156/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.1113 - accuracy: 0.0025 - val_loss: 1.3280 - val_accuracy: 0.0000e+00\n",
      "Epoch 157/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.1211 - accuracy: 0.0025 - val_loss: 1.2116 - val_accuracy: 0.0000e+00\n",
      "Epoch 158/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.1179 - accuracy: 0.0037 - val_loss: 1.1628 - val_accuracy: 0.0000e+00\n",
      "Epoch 159/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.1122 - accuracy: 0.0037 - val_loss: 1.1810 - val_accuracy: 0.0000e+00\n",
      "Epoch 160/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.1056 - accuracy: 0.0037 - val_loss: 1.2391 - val_accuracy: 0.0000e+00\n",
      "Epoch 161/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.1150 - accuracy: 0.0025 - val_loss: 1.2340 - val_accuracy: 0.0000e+00\n",
      "Epoch 162/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.1144 - accuracy: 0.0037 - val_loss: 1.2673 - val_accuracy: 0.0000e+00\n",
      "Epoch 163/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.1121 - accuracy: 0.0037 - val_loss: 1.2522 - val_accuracy: 0.0000e+00\n",
      "Epoch 164/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.1160 - accuracy: 0.0025 - val_loss: 1.2269 - val_accuracy: 0.0000e+00\n",
      "Epoch 165/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.1051 - accuracy: 0.0037 - val_loss: 1.2100 - val_accuracy: 0.0000e+00\n",
      "Epoch 166/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.1096 - accuracy: 0.0025 - val_loss: 1.2459 - val_accuracy: 0.0000e+00\n",
      "Epoch 167/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13/13 [==============================] - 0s 2ms/step - loss: 0.1259 - accuracy: 0.0012 - val_loss: 1.1967 - val_accuracy: 0.0000e+00\n",
      "Epoch 168/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.1055 - accuracy: 0.0037 - val_loss: 1.2376 - val_accuracy: 0.0000e+00\n",
      "Epoch 169/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.1229 - accuracy: 0.0025 - val_loss: 1.2163 - val_accuracy: 0.0000e+00\n",
      "Epoch 170/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.1165 - accuracy: 0.0037 - val_loss: 1.2216 - val_accuracy: 0.0000e+00\n",
      "Epoch 171/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.1148 - accuracy: 0.0025 - val_loss: 1.2402 - val_accuracy: 0.0000e+00\n",
      "Epoch 172/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.1272 - accuracy: 0.0037 - val_loss: 1.1917 - val_accuracy: 0.0000e+00\n",
      "Epoch 173/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.1155 - accuracy: 0.0037 - val_loss: 1.2389 - val_accuracy: 0.0000e+00\n",
      "Epoch 174/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.1179 - accuracy: 0.0037 - val_loss: 1.2487 - val_accuracy: 0.0000e+00\n",
      "Epoch 175/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.1068 - accuracy: 0.0025 - val_loss: 1.2961 - val_accuracy: 0.0000e+00\n",
      "Epoch 176/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.1156 - accuracy: 0.0025 - val_loss: 1.2765 - val_accuracy: 0.0000e+00\n",
      "Epoch 177/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0982 - accuracy: 0.0037 - val_loss: 1.3185 - val_accuracy: 0.0000e+00\n",
      "Epoch 178/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.1254 - accuracy: 0.0025 - val_loss: 1.2557 - val_accuracy: 0.0000e+00\n",
      "Epoch 179/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.1112 - accuracy: 0.0012 - val_loss: 1.3166 - val_accuracy: 0.0000e+00\n",
      "Epoch 180/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.1263 - accuracy: 0.0025 - val_loss: 1.2137 - val_accuracy: 0.0000e+00\n",
      "Epoch 181/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.1228 - accuracy: 0.0012 - val_loss: 1.2493 - val_accuracy: 0.0000e+00\n",
      "Epoch 182/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.1092 - accuracy: 0.0025 - val_loss: 1.2352 - val_accuracy: 0.0000e+00\n",
      "Epoch 183/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.1442 - accuracy: 0.0025 - val_loss: 1.2605 - val_accuracy: 0.0000e+00\n",
      "Epoch 184/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.1304 - accuracy: 0.0037 - val_loss: 1.1981 - val_accuracy: 0.0000e+00\n",
      "Epoch 185/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.1249 - accuracy: 0.0025 - val_loss: 1.2180 - val_accuracy: 0.0000e+00\n",
      "Epoch 186/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.1238 - accuracy: 0.0025 - val_loss: 1.2341 - val_accuracy: 0.0000e+00\n",
      "Epoch 187/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.1251 - accuracy: 0.0025 - val_loss: 1.2674 - val_accuracy: 0.0000e+00\n",
      "Epoch 188/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.1314 - accuracy: 0.0025 - val_loss: 1.2167 - val_accuracy: 0.0000e+00\n",
      "Epoch 189/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.1379 - accuracy: 0.0037 - val_loss: 1.2199 - val_accuracy: 0.0000e+00\n",
      "Epoch 190/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.1316 - accuracy: 0.0037 - val_loss: 1.2133 - val_accuracy: 0.0000e+00\n",
      "Epoch 191/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.1109 - accuracy: 0.0037 - val_loss: 1.2290 - val_accuracy: 0.0000e+00\n",
      "Epoch 192/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.1220 - accuracy: 0.0037 - val_loss: 1.2331 - val_accuracy: 0.0000e+00\n",
      "Epoch 193/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.1178 - accuracy: 0.0025 - val_loss: 1.2508 - val_accuracy: 0.0000e+00\n",
      "Epoch 194/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.1323 - accuracy: 0.0037 - val_loss: 1.2277 - val_accuracy: 0.0000e+00\n",
      "Epoch 195/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.1228 - accuracy: 0.0012 - val_loss: 1.2378 - val_accuracy: 0.0000e+00\n",
      "Epoch 196/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.1214 - accuracy: 0.0037 - val_loss: 1.2494 - val_accuracy: 0.0000e+00\n",
      "Epoch 197/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.1278 - accuracy: 0.0037 - val_loss: 1.2430 - val_accuracy: 0.0000e+00\n",
      "Epoch 198/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.1325 - accuracy: 0.0037 - val_loss: 1.2503 - val_accuracy: 0.0000e+00\n",
      "Epoch 199/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.1225 - accuracy: 0.0037 - val_loss: 1.1843 - val_accuracy: 0.0000e+00\n",
      "Epoch 200/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.1240 - accuracy: 0.0037 - val_loss: 1.2206 - val_accuracy: 0.0000e+00\n",
      "Epoch 201/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.1368 - accuracy: 0.0025 - val_loss: 1.2176 - val_accuracy: 0.0000e+00\n",
      "Epoch 202/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.1138 - accuracy: 0.0037 - val_loss: 1.2672 - val_accuracy: 0.0000e+00\n",
      "Epoch 203/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.1167 - accuracy: 0.0012 - val_loss: 1.2165 - val_accuracy: 0.0000e+00\n",
      "Epoch 204/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.1277 - accuracy: 0.0037 - val_loss: 1.1924 - val_accuracy: 0.0000e+00\n",
      "Epoch 205/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.1066 - accuracy: 0.0025 - val_loss: 1.1811 - val_accuracy: 0.0000e+00\n",
      "Epoch 206/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0946 - accuracy: 0.0037 - val_loss: 1.2023 - val_accuracy: 0.0000e+00\n",
      "Epoch 207/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.1147 - accuracy: 0.0037 - val_loss: 1.2137 - val_accuracy: 0.0000e+00\n",
      "Epoch 208/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.1157 - accuracy: 0.0037 - val_loss: 1.2151 - val_accuracy: 0.0000e+00\n",
      "Epoch 209/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.1064 - accuracy: 0.0025 - val_loss: 1.2124 - val_accuracy: 0.0000e+00\n",
      "Epoch 210/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.1128 - accuracy: 0.0012 - val_loss: 1.2141 - val_accuracy: 0.0000e+00\n",
      "Epoch 211/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.1098 - accuracy: 0.0025 - val_loss: 1.2062 - val_accuracy: 0.0000e+00\n",
      "Epoch 212/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.1036 - accuracy: 0.0025 - val_loss: 1.2405 - val_accuracy: 0.0000e+00\n",
      "Epoch 213/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.1230 - accuracy: 0.0025 - val_loss: 1.2580 - val_accuracy: 0.0000e+00\n",
      "Epoch 214/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.1307 - accuracy: 0.0037 - val_loss: 1.2302 - val_accuracy: 0.0000e+00\n",
      "Epoch 215/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.1115 - accuracy: 0.0025 - val_loss: 1.1766 - val_accuracy: 0.0000e+00\n",
      "Epoch 216/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.1109 - accuracy: 0.0012 - val_loss: 1.2276 - val_accuracy: 0.0000e+00\n",
      "Epoch 217/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.1058 - accuracy: 0.0012 - val_loss: 1.2607 - val_accuracy: 0.0000e+00\n",
      "Epoch 218/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.1141 - accuracy: 0.0025 - val_loss: 1.2565 - val_accuracy: 0.0000e+00\n",
      "Epoch 219/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.1154 - accuracy: 0.0025 - val_loss: 1.2533 - val_accuracy: 0.0000e+00\n",
      "Epoch 220/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.1070 - accuracy: 0.0025 - val_loss: 1.2220 - val_accuracy: 0.0000e+00\n",
      "Epoch 221/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.1157 - accuracy: 0.0037 - val_loss: 1.1968 - val_accuracy: 0.0000e+00\n",
      "Epoch 222/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.1147 - accuracy: 0.0025 - val_loss: 1.2555 - val_accuracy: 0.0000e+00\n",
      "Epoch 223/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.1146 - accuracy: 0.0025 - val_loss: 1.2132 - val_accuracy: 0.0000e+00\n",
      "Epoch 224/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.1176 - accuracy: 0.0025 - val_loss: 1.2510 - val_accuracy: 0.0000e+00\n",
      "Epoch 225/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.1169 - accuracy: 0.0037 - val_loss: 1.2687 - val_accuracy: 0.0000e+00\n",
      "Epoch 226/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.1189 - accuracy: 0.0025 - val_loss: 1.2410 - val_accuracy: 0.0000e+00\n",
      "Epoch 227/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.1122 - accuracy: 0.0037 - val_loss: 1.2036 - val_accuracy: 0.0000e+00\n",
      "Epoch 228/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.1144 - accuracy: 0.0025 - val_loss: 1.2448 - val_accuracy: 0.0000e+00\n",
      "Epoch 229/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.1104 - accuracy: 0.0037 - val_loss: 1.2044 - val_accuracy: 0.0000e+00\n",
      "Epoch 230/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.1055 - accuracy: 0.0025 - val_loss: 1.1991 - val_accuracy: 0.0000e+00\n",
      "Epoch 231/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.1127 - accuracy: 0.0037 - val_loss: 1.2456 - val_accuracy: 0.0000e+00\n",
      "Epoch 232/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.1226 - accuracy: 0.0037 - val_loss: 1.2780 - val_accuracy: 0.0000e+00\n",
      "Epoch 233/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.1215 - accuracy: 0.0037 - val_loss: 1.2028 - val_accuracy: 0.0000e+00\n",
      "Epoch 234/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.1152 - accuracy: 0.0025 - val_loss: 1.1722 - val_accuracy: 0.0000e+00\n",
      "Epoch 235/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.1183 - accuracy: 0.0037 - val_loss: 1.1743 - val_accuracy: 0.0000e+00\n",
      "Epoch 236/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.1107 - accuracy: 0.0012 - val_loss: 1.2115 - val_accuracy: 0.0000e+00\n",
      "Epoch 237/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.1195 - accuracy: 0.0025 - val_loss: 1.2051 - val_accuracy: 0.0000e+00\n",
      "Epoch 238/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.1410 - accuracy: 0.0012 - val_loss: 1.1885 - val_accuracy: 0.0000e+00\n",
      "Epoch 239/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.1144 - accuracy: 0.0025 - val_loss: 1.2161 - val_accuracy: 0.0000e+00\n",
      "Epoch 240/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.1050 - accuracy: 0.0037 - val_loss: 1.2310 - val_accuracy: 0.0000e+00\n",
      "Epoch 241/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.1163 - accuracy: 0.0012 - val_loss: 1.1833 - val_accuracy: 0.0000e+00\n",
      "Epoch 242/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.1282 - accuracy: 0.0037 - val_loss: 1.1684 - val_accuracy: 0.0000e+00\n",
      "Epoch 243/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.1197 - accuracy: 0.0037 - val_loss: 1.2432 - val_accuracy: 0.0000e+00\n",
      "Epoch 244/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.1282 - accuracy: 0.0025 - val_loss: 1.1408 - val_accuracy: 0.0000e+00\n",
      "Epoch 245/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.1198 - accuracy: 0.0025 - val_loss: 1.1988 - val_accuracy: 0.0000e+00\n",
      "Epoch 246/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.1366 - accuracy: 0.0037 - val_loss: 1.1539 - val_accuracy: 0.0000e+00\n",
      "Epoch 247/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.1243 - accuracy: 0.0012 - val_loss: 1.1904 - val_accuracy: 0.0000e+00\n",
      "Epoch 248/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.1297 - accuracy: 0.0025 - val_loss: 1.2057 - val_accuracy: 0.0000e+00\n",
      "Epoch 249/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.1195 - accuracy: 0.0037 - val_loss: 1.1259 - val_accuracy: 0.0000e+00\n",
      "Epoch 250/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.1112 - accuracy: 0.0000e+00 - val_loss: 1.1633 - val_accuracy: 0.0000e+00\n",
      "Epoch 251/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0930 - accuracy: 0.0037 - val_loss: 1.1649 - val_accuracy: 0.0000e+00\n",
      "Epoch 252/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0918 - accuracy: 0.0012 - val_loss: 1.1722 - val_accuracy: 0.0000e+00\n",
      "Epoch 253/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.1124 - accuracy: 0.0037 - val_loss: 1.1874 - val_accuracy: 0.0000e+00\n",
      "Epoch 254/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0994 - accuracy: 0.0037 - val_loss: 1.2683 - val_accuracy: 0.0000e+00\n",
      "Epoch 255/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0980 - accuracy: 0.0012 - val_loss: 1.2379 - val_accuracy: 0.0000e+00\n",
      "Epoch 256/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.1101 - accuracy: 0.0037 - val_loss: 1.1965 - val_accuracy: 0.0000e+00\n",
      "Epoch 257/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.1150 - accuracy: 0.0037 - val_loss: 1.2419 - val_accuracy: 0.0000e+00\n",
      "Epoch 258/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0962 - accuracy: 0.0025 - val_loss: 1.2218 - val_accuracy: 0.0000e+00\n",
      "Epoch 259/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.1060 - accuracy: 0.0025 - val_loss: 1.1560 - val_accuracy: 0.0000e+00\n",
      "Epoch 260/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.1098 - accuracy: 0.0025 - val_loss: 1.1942 - val_accuracy: 0.0000e+00\n",
      "Epoch 261/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0935 - accuracy: 0.0025 - val_loss: 1.1848 - val_accuracy: 0.0000e+00\n",
      "Epoch 262/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.1045 - accuracy: 0.0025 - val_loss: 1.2134 - val_accuracy: 0.0000e+00\n",
      "Epoch 263/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.1144 - accuracy: 0.0025 - val_loss: 1.1524 - val_accuracy: 0.0000e+00\n",
      "Epoch 264/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.1024 - accuracy: 0.0025 - val_loss: 1.2220 - val_accuracy: 0.0000e+00\n",
      "Epoch 265/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0875 - accuracy: 0.0037 - val_loss: 1.1920 - val_accuracy: 0.0000e+00\n",
      "Epoch 266/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.1009 - accuracy: 0.0025 - val_loss: 1.2519 - val_accuracy: 0.0000e+00\n",
      "Epoch 267/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.1117 - accuracy: 0.0025 - val_loss: 1.2493 - val_accuracy: 0.0000e+00\n",
      "Epoch 268/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.1044 - accuracy: 0.0037 - val_loss: 1.2832 - val_accuracy: 0.0000e+00\n",
      "Epoch 269/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0901 - accuracy: 0.0037 - val_loss: 1.2819 - val_accuracy: 0.0000e+00\n",
      "Epoch 270/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0833 - accuracy: 0.0037 - val_loss: 1.2458 - val_accuracy: 0.0000e+00\n",
      "Epoch 271/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0891 - accuracy: 0.0012 - val_loss: 1.1943 - val_accuracy: 0.0000e+00\n",
      "Epoch 272/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0988 - accuracy: 0.0025 - val_loss: 1.2486 - val_accuracy: 0.0000e+00\n",
      "Epoch 273/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0896 - accuracy: 0.0025 - val_loss: 1.2371 - val_accuracy: 0.0000e+00\n",
      "Epoch 274/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0996 - accuracy: 0.0025 - val_loss: 1.2084 - val_accuracy: 0.0000e+00\n",
      "Epoch 275/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.1108 - accuracy: 0.0025 - val_loss: 1.2510 - val_accuracy: 0.0000e+00\n",
      "Epoch 276/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0930 - accuracy: 0.0037 - val_loss: 1.2167 - val_accuracy: 0.0000e+00\n",
      "Epoch 277/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0816 - accuracy: 0.0037 - val_loss: 1.2169 - val_accuracy: 0.0000e+00\n",
      "Epoch 278/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0914 - accuracy: 0.0025 - val_loss: 1.2032 - val_accuracy: 0.0000e+00\n",
      "Epoch 279/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0916 - accuracy: 0.0037 - val_loss: 1.2046 - val_accuracy: 0.0000e+00\n",
      "Epoch 280/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0979 - accuracy: 0.0025 - val_loss: 1.2479 - val_accuracy: 0.0000e+00\n",
      "Epoch 281/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0875 - accuracy: 0.0037 - val_loss: 1.2155 - val_accuracy: 0.0000e+00\n",
      "Epoch 282/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.1042 - accuracy: 0.0037 - val_loss: 1.2804 - val_accuracy: 0.0000e+00\n",
      "Epoch 283/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.1131 - accuracy: 0.0025 - val_loss: 1.2376 - val_accuracy: 0.0000e+00\n",
      "Epoch 284/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0932 - accuracy: 0.0025 - val_loss: 1.2549 - val_accuracy: 0.0000e+00\n",
      "Epoch 285/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.1035 - accuracy: 0.0037 - val_loss: 1.2250 - val_accuracy: 0.0000e+00\n",
      "Epoch 286/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0994 - accuracy: 0.0037 - val_loss: 1.2734 - val_accuracy: 0.0000e+00\n",
      "Epoch 287/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.1091 - accuracy: 0.0025 - val_loss: 1.2511 - val_accuracy: 0.0000e+00\n",
      "Epoch 288/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0911 - accuracy: 0.0025 - val_loss: 1.2375 - val_accuracy: 0.0000e+00\n",
      "Epoch 289/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0893 - accuracy: 0.0025 - val_loss: 1.2123 - val_accuracy: 0.0000e+00\n",
      "Epoch 290/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0993 - accuracy: 0.0025 - val_loss: 1.2164 - val_accuracy: 0.0000e+00\n",
      "Epoch 291/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0937 - accuracy: 0.0037 - val_loss: 1.1963 - val_accuracy: 0.0000e+00\n",
      "Epoch 292/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0818 - accuracy: 0.0025 - val_loss: 1.2547 - val_accuracy: 0.0000e+00\n",
      "Epoch 293/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0954 - accuracy: 0.0025 - val_loss: 1.2030 - val_accuracy: 0.0000e+00\n",
      "Epoch 294/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0880 - accuracy: 0.0037 - val_loss: 1.2190 - val_accuracy: 0.0000e+00\n",
      "Epoch 295/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.1021 - accuracy: 0.0037 - val_loss: 1.2158 - val_accuracy: 0.0000e+00\n",
      "Epoch 296/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.1109 - accuracy: 0.0000e+00 - val_loss: 1.2364 - val_accuracy: 0.0000e+00\n",
      "Epoch 297/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.1108 - accuracy: 0.0037 - val_loss: 1.2943 - val_accuracy: 0.0000e+00\n",
      "Epoch 298/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0906 - accuracy: 0.0037 - val_loss: 1.2240 - val_accuracy: 0.0000e+00\n",
      "Epoch 299/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.1064 - accuracy: 0.0012 - val_loss: 1.2321 - val_accuracy: 0.0000e+00\n",
      "Epoch 300/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.1060 - accuracy: 0.0037 - val_loss: 1.1723 - val_accuracy: 0.0000e+00\n",
      "Epoch 301/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0986 - accuracy: 0.0037 - val_loss: 1.2198 - val_accuracy: 0.0000e+00\n",
      "Epoch 302/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0972 - accuracy: 0.0037 - val_loss: 1.1996 - val_accuracy: 0.0000e+00\n",
      "Epoch 303/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.1117 - accuracy: 0.0037 - val_loss: 1.1828 - val_accuracy: 0.0000e+00\n",
      "Epoch 304/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0928 - accuracy: 0.0025 - val_loss: 1.1760 - val_accuracy: 0.0000e+00\n",
      "Epoch 305/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.1030 - accuracy: 0.0037 - val_loss: 1.1675 - val_accuracy: 0.0000e+00\n",
      "Epoch 306/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.1154 - accuracy: 0.0037 - val_loss: 1.1742 - val_accuracy: 0.0000e+00\n",
      "Epoch 307/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0923 - accuracy: 0.0025 - val_loss: 1.2454 - val_accuracy: 0.0000e+00\n",
      "Epoch 308/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.1089 - accuracy: 0.0025 - val_loss: 1.2382 - val_accuracy: 0.0000e+00\n",
      "Epoch 309/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.1008 - accuracy: 0.0037 - val_loss: 1.3130 - val_accuracy: 0.0000e+00\n",
      "Epoch 310/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.1038 - accuracy: 0.0012 - val_loss: 1.2548 - val_accuracy: 0.0000e+00\n",
      "Epoch 311/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.1180 - accuracy: 0.0025 - val_loss: 1.1595 - val_accuracy: 0.0000e+00\n",
      "Epoch 312/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0954 - accuracy: 0.0025 - val_loss: 1.2402 - val_accuracy: 0.0000e+00\n",
      "Epoch 313/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.1047 - accuracy: 0.0025 - val_loss: 1.2120 - val_accuracy: 0.0000e+00\n",
      "Epoch 314/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.1098 - accuracy: 0.0037 - val_loss: 1.2021 - val_accuracy: 0.0000e+00\n",
      "Epoch 315/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0956 - accuracy: 0.0025 - val_loss: 1.2055 - val_accuracy: 0.0000e+00\n",
      "Epoch 316/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.1093 - accuracy: 0.0025 - val_loss: 1.2013 - val_accuracy: 0.0000e+00\n",
      "Epoch 317/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.1062 - accuracy: 0.0012 - val_loss: 1.1986 - val_accuracy: 0.0000e+00\n",
      "Epoch 318/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.1104 - accuracy: 0.0037 - val_loss: 1.1874 - val_accuracy: 0.0000e+00\n",
      "Epoch 319/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.1064 - accuracy: 0.0037 - val_loss: 1.2163 - val_accuracy: 0.0000e+00\n",
      "Epoch 320/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.1157 - accuracy: 0.0037 - val_loss: 1.1971 - val_accuracy: 0.0000e+00\n",
      "Epoch 321/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.1116 - accuracy: 0.0012 - val_loss: 1.1117 - val_accuracy: 0.0000e+00\n",
      "Epoch 322/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.1176 - accuracy: 0.0025 - val_loss: 1.1555 - val_accuracy: 0.0000e+00\n",
      "Epoch 323/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.1048 - accuracy: 0.0037 - val_loss: 1.1976 - val_accuracy: 0.0000e+00\n",
      "Epoch 324/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0977 - accuracy: 0.0012 - val_loss: 1.1966 - val_accuracy: 0.0000e+00\n",
      "Epoch 325/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.1208 - accuracy: 0.0025 - val_loss: 1.2121 - val_accuracy: 0.0000e+00\n",
      "Epoch 326/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.1094 - accuracy: 0.0037 - val_loss: 1.1910 - val_accuracy: 0.0000e+00\n",
      "Epoch 327/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.1036 - accuracy: 0.0025 - val_loss: 1.2294 - val_accuracy: 0.0000e+00\n",
      "Epoch 328/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.1025 - accuracy: 0.0025 - val_loss: 1.2248 - val_accuracy: 0.0000e+00\n",
      "Epoch 329/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0870 - accuracy: 0.0025 - val_loss: 1.2167 - val_accuracy: 0.0000e+00\n",
      "Epoch 330/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0954 - accuracy: 0.0037 - val_loss: 1.1792 - val_accuracy: 0.0000e+00\n",
      "Epoch 331/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0959 - accuracy: 0.0037 - val_loss: 1.1845 - val_accuracy: 0.0000e+00\n",
      "Epoch 332/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.1067 - accuracy: 0.0025 - val_loss: 1.1507 - val_accuracy: 0.0000e+00\n",
      "Epoch 333/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0959 - accuracy: 0.0012 - val_loss: 1.2285 - val_accuracy: 0.0000e+00\n",
      "Epoch 334/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.1098 - accuracy: 0.0037 - val_loss: 1.2301 - val_accuracy: 0.0000e+00\n",
      "Epoch 335/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.1044 - accuracy: 0.0037 - val_loss: 1.1395 - val_accuracy: 0.0000e+00\n",
      "Epoch 336/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.1019 - accuracy: 0.0037 - val_loss: 1.2197 - val_accuracy: 0.0000e+00\n",
      "Epoch 337/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0923 - accuracy: 0.0025 - val_loss: 1.1834 - val_accuracy: 0.0000e+00\n",
      "Epoch 338/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0986 - accuracy: 0.0037 - val_loss: 1.1936 - val_accuracy: 0.0000e+00\n",
      "Epoch 339/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0934 - accuracy: 0.0037 - val_loss: 1.1644 - val_accuracy: 0.0000e+00\n",
      "Epoch 340/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.1086 - accuracy: 0.0025 - val_loss: 1.1107 - val_accuracy: 0.0000e+00\n",
      "Epoch 341/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0996 - accuracy: 0.0025 - val_loss: 1.1250 - val_accuracy: 0.0000e+00\n",
      "Epoch 342/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.1001 - accuracy: 0.0025 - val_loss: 1.1573 - val_accuracy: 0.0000e+00\n",
      "Epoch 343/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0938 - accuracy: 0.0025 - val_loss: 1.1426 - val_accuracy: 0.0000e+00\n",
      "Epoch 344/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.1081 - accuracy: 0.0025 - val_loss: 1.1123 - val_accuracy: 0.0000e+00\n",
      "Epoch 345/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0993 - accuracy: 0.0025 - val_loss: 1.1584 - val_accuracy: 0.0000e+00\n",
      "Epoch 346/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0934 - accuracy: 0.0025 - val_loss: 1.1325 - val_accuracy: 0.0000e+00\n",
      "Epoch 347/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0960 - accuracy: 0.0037 - val_loss: 1.1543 - val_accuracy: 0.0000e+00\n",
      "Epoch 348/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0973 - accuracy: 0.0025 - val_loss: 1.1676 - val_accuracy: 0.0000e+00\n",
      "Epoch 349/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.1276 - accuracy: 0.0037 - val_loss: 1.1391 - val_accuracy: 0.0000e+00\n",
      "Epoch 350/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.1132 - accuracy: 0.0037 - val_loss: 1.2441 - val_accuracy: 0.0000e+00\n",
      "Epoch 351/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.1061 - accuracy: 0.0025 - val_loss: 1.2159 - val_accuracy: 0.0000e+00\n",
      "Epoch 352/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0970 - accuracy: 0.0037 - val_loss: 1.1784 - val_accuracy: 0.0000e+00\n",
      "Epoch 353/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0963 - accuracy: 0.0037 - val_loss: 1.1917 - val_accuracy: 0.0000e+00\n",
      "Epoch 354/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.1039 - accuracy: 0.0037 - val_loss: 1.1277 - val_accuracy: 0.0000e+00\n",
      "Epoch 355/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0999 - accuracy: 0.0025 - val_loss: 1.1763 - val_accuracy: 0.0000e+00\n",
      "Epoch 356/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.1127 - accuracy: 0.0025 - val_loss: 1.1465 - val_accuracy: 0.0000e+00\n",
      "Epoch 357/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.1221 - accuracy: 0.0025 - val_loss: 1.1704 - val_accuracy: 0.0000e+00\n",
      "Epoch 358/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0995 - accuracy: 0.0025 - val_loss: 1.2439 - val_accuracy: 0.0000e+00\n",
      "Epoch 359/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0928 - accuracy: 0.0037 - val_loss: 1.2318 - val_accuracy: 0.0000e+00\n",
      "Epoch 360/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0954 - accuracy: 0.0025 - val_loss: 1.1989 - val_accuracy: 0.0000e+00\n",
      "Epoch 361/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0909 - accuracy: 0.0025 - val_loss: 1.1920 - val_accuracy: 0.0000e+00\n",
      "Epoch 362/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0894 - accuracy: 0.0037 - val_loss: 1.2607 - val_accuracy: 0.0000e+00\n",
      "Epoch 363/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0954 - accuracy: 0.0037 - val_loss: 1.2025 - val_accuracy: 0.0000e+00\n",
      "Epoch 364/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0960 - accuracy: 0.0037 - val_loss: 1.1970 - val_accuracy: 0.0000e+00\n",
      "Epoch 365/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0958 - accuracy: 0.0025 - val_loss: 1.2400 - val_accuracy: 0.0000e+00\n",
      "Epoch 366/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0941 - accuracy: 0.0037 - val_loss: 1.2231 - val_accuracy: 0.0000e+00\n",
      "Epoch 367/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0969 - accuracy: 0.0037 - val_loss: 1.2004 - val_accuracy: 0.0000e+00\n",
      "Epoch 368/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0831 - accuracy: 0.0025 - val_loss: 1.1877 - val_accuracy: 0.0000e+00\n",
      "Epoch 369/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0907 - accuracy: 0.0037 - val_loss: 1.2843 - val_accuracy: 0.0000e+00\n",
      "Epoch 370/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0947 - accuracy: 0.0025 - val_loss: 1.2004 - val_accuracy: 0.0000e+00\n",
      "Epoch 371/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.1087 - accuracy: 0.0025 - val_loss: 1.2533 - val_accuracy: 0.0000e+00\n",
      "Epoch 372/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0995 - accuracy: 0.0037 - val_loss: 1.2513 - val_accuracy: 0.0000e+00\n",
      "Epoch 373/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0871 - accuracy: 0.0025 - val_loss: 1.2795 - val_accuracy: 0.0000e+00\n",
      "Epoch 374/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0902 - accuracy: 0.0025 - val_loss: 1.2074 - val_accuracy: 0.0000e+00\n",
      "Epoch 375/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.1158 - accuracy: 0.0012 - val_loss: 1.2587 - val_accuracy: 0.0000e+00\n",
      "Epoch 376/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.1077 - accuracy: 0.0025 - val_loss: 1.1999 - val_accuracy: 0.0000e+00\n",
      "Epoch 377/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0905 - accuracy: 0.0012 - val_loss: 1.2117 - val_accuracy: 0.0000e+00\n",
      "Epoch 378/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0887 - accuracy: 0.0012 - val_loss: 1.2353 - val_accuracy: 0.0000e+00\n",
      "Epoch 379/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0950 - accuracy: 0.0025 - val_loss: 1.2263 - val_accuracy: 0.0000e+00\n",
      "Epoch 380/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.1006 - accuracy: 0.0012 - val_loss: 1.1709 - val_accuracy: 0.0000e+00\n",
      "Epoch 381/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0996 - accuracy: 0.0012 - val_loss: 1.1916 - val_accuracy: 0.0000e+00\n",
      "Epoch 382/1000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0988 - accuracy: 0.0037 - val_loss: 1.2237 - val_accuracy: 0.0000e+00\n",
      "Epoch 383/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.1120 - accuracy: 0.0037 - val_loss: 1.2135 - val_accuracy: 0.0000e+00\n",
      "Epoch 384/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0910 - accuracy: 0.0037 - val_loss: 1.2141 - val_accuracy: 0.0000e+00\n",
      "Epoch 385/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0892 - accuracy: 0.0012 - val_loss: 1.2232 - val_accuracy: 0.0000e+00\n",
      "Epoch 386/1000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0966 - accuracy: 0.0025 - val_loss: 1.1900 - val_accuracy: 0.0000e+00\n",
      "Epoch 387/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0963 - accuracy: 0.0012 - val_loss: 1.2185 - val_accuracy: 0.0000e+00\n",
      "Epoch 388/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0803 - accuracy: 0.0025 - val_loss: 1.1827 - val_accuracy: 0.0000e+00\n",
      "Epoch 389/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0851 - accuracy: 0.0025 - val_loss: 1.2037 - val_accuracy: 0.0000e+00\n",
      "Epoch 390/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.1076 - accuracy: 0.0037 - val_loss: 1.1363 - val_accuracy: 0.0000e+00\n",
      "Epoch 391/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0935 - accuracy: 0.0012 - val_loss: 1.1810 - val_accuracy: 0.0000e+00\n",
      "Epoch 392/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0904 - accuracy: 0.0012 - val_loss: 1.1877 - val_accuracy: 0.0000e+00\n",
      "Epoch 393/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.1056 - accuracy: 0.0025 - val_loss: 1.2044 - val_accuracy: 0.0000e+00\n",
      "Epoch 394/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0920 - accuracy: 0.0012 - val_loss: 1.1871 - val_accuracy: 0.0000e+00\n",
      "Epoch 395/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0785 - accuracy: 0.0025 - val_loss: 1.1980 - val_accuracy: 0.0000e+00\n",
      "Epoch 396/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0790 - accuracy: 0.0025 - val_loss: 1.2192 - val_accuracy: 0.0000e+00\n",
      "Epoch 397/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0815 - accuracy: 0.0037 - val_loss: 1.2299 - val_accuracy: 0.0000e+00\n",
      "Epoch 398/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.1079 - accuracy: 0.0025 - val_loss: 1.2459 - val_accuracy: 0.0000e+00\n",
      "Epoch 399/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0933 - accuracy: 0.0025 - val_loss: 1.1752 - val_accuracy: 0.0000e+00\n",
      "Epoch 400/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0975 - accuracy: 0.0025 - val_loss: 1.1918 - val_accuracy: 0.0000e+00\n",
      "Epoch 401/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.1235 - accuracy: 0.0025 - val_loss: 1.1986 - val_accuracy: 0.0000e+00\n",
      "Epoch 402/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0939 - accuracy: 0.0037 - val_loss: 1.2224 - val_accuracy: 0.0000e+00\n",
      "Epoch 403/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0855 - accuracy: 0.0037 - val_loss: 1.2040 - val_accuracy: 0.0000e+00\n",
      "Epoch 404/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0946 - accuracy: 0.0025 - val_loss: 1.1438 - val_accuracy: 0.0000e+00\n",
      "Epoch 405/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.1131 - accuracy: 0.0025 - val_loss: 1.1980 - val_accuracy: 0.0000e+00\n",
      "Epoch 406/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.1001 - accuracy: 0.0025 - val_loss: 1.2126 - val_accuracy: 0.0000e+00\n",
      "Epoch 407/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0772 - accuracy: 0.0025 - val_loss: 1.1920 - val_accuracy: 0.0000e+00\n",
      "Epoch 408/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.1055 - accuracy: 0.0025 - val_loss: 1.2111 - val_accuracy: 0.0000e+00\n",
      "Epoch 409/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0812 - accuracy: 0.0037 - val_loss: 1.1961 - val_accuracy: 0.0000e+00\n",
      "Epoch 410/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0824 - accuracy: 0.0037 - val_loss: 1.2160 - val_accuracy: 0.0000e+00\n",
      "Epoch 411/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0882 - accuracy: 0.0037 - val_loss: 1.2426 - val_accuracy: 0.0000e+00\n",
      "Epoch 412/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0761 - accuracy: 0.0025 - val_loss: 1.2366 - val_accuracy: 0.0000e+00\n",
      "Epoch 413/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0876 - accuracy: 0.0025 - val_loss: 1.2423 - val_accuracy: 0.0000e+00\n",
      "Epoch 414/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.1016 - accuracy: 0.0037 - val_loss: 1.1711 - val_accuracy: 0.0000e+00\n",
      "Epoch 415/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0883 - accuracy: 0.0012 - val_loss: 1.1906 - val_accuracy: 0.0000e+00\n",
      "Epoch 416/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0891 - accuracy: 0.0012 - val_loss: 1.1522 - val_accuracy: 0.0000e+00\n",
      "Epoch 417/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0880 - accuracy: 0.0037 - val_loss: 1.1433 - val_accuracy: 0.0000e+00\n",
      "Epoch 418/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0857 - accuracy: 0.0025 - val_loss: 1.1747 - val_accuracy: 0.0000e+00\n",
      "Epoch 419/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0825 - accuracy: 0.0012 - val_loss: 1.2003 - val_accuracy: 0.0000e+00\n",
      "Epoch 420/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0722 - accuracy: 0.0025 - val_loss: 1.2403 - val_accuracy: 0.0000e+00\n",
      "Epoch 421/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0751 - accuracy: 0.0037 - val_loss: 1.2464 - val_accuracy: 0.0000e+00\n",
      "Epoch 422/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0794 - accuracy: 0.0025 - val_loss: 1.2035 - val_accuracy: 0.0000e+00\n",
      "Epoch 423/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0981 - accuracy: 0.0025 - val_loss: 1.2327 - val_accuracy: 0.0000e+00\n",
      "Epoch 424/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.1004 - accuracy: 0.0025 - val_loss: 1.1994 - val_accuracy: 0.0000e+00\n",
      "Epoch 425/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0881 - accuracy: 0.0025 - val_loss: 1.1778 - val_accuracy: 0.0000e+00\n",
      "Epoch 426/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0870 - accuracy: 0.0037 - val_loss: 1.1432 - val_accuracy: 0.0000e+00\n",
      "Epoch 427/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0805 - accuracy: 0.0037 - val_loss: 1.1852 - val_accuracy: 0.0000e+00\n",
      "Epoch 428/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.1064 - accuracy: 0.0025 - val_loss: 1.1619 - val_accuracy: 0.0000e+00\n",
      "Epoch 429/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0865 - accuracy: 0.0037 - val_loss: 1.2616 - val_accuracy: 0.0000e+00\n",
      "Epoch 430/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0863 - accuracy: 0.0025 - val_loss: 1.2689 - val_accuracy: 0.0000e+00\n",
      "Epoch 431/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0949 - accuracy: 0.0037 - val_loss: 1.2676 - val_accuracy: 0.0000e+00\n",
      "Epoch 432/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0985 - accuracy: 0.0025 - val_loss: 1.2718 - val_accuracy: 0.0000e+00\n",
      "Epoch 433/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0865 - accuracy: 0.0025 - val_loss: 1.1850 - val_accuracy: 0.0000e+00\n",
      "Epoch 434/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0950 - accuracy: 0.0025 - val_loss: 1.1710 - val_accuracy: 0.0000e+00\n",
      "Epoch 435/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0893 - accuracy: 0.0000e+00 - val_loss: 1.2175 - val_accuracy: 0.0000e+00\n",
      "Epoch 436/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0861 - accuracy: 0.0025 - val_loss: 1.2736 - val_accuracy: 0.0000e+00\n",
      "Epoch 437/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0923 - accuracy: 0.0012 - val_loss: 1.2239 - val_accuracy: 0.0000e+00\n",
      "Epoch 438/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0835 - accuracy: 0.0037 - val_loss: 1.2585 - val_accuracy: 0.0000e+00\n",
      "Epoch 439/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0823 - accuracy: 0.0025 - val_loss: 1.2031 - val_accuracy: 0.0000e+00\n",
      "Epoch 440/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0997 - accuracy: 0.0012 - val_loss: 1.2676 - val_accuracy: 0.0000e+00\n",
      "Epoch 441/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0909 - accuracy: 0.0037 - val_loss: 1.2039 - val_accuracy: 0.0000e+00\n",
      "Epoch 442/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0858 - accuracy: 0.0012 - val_loss: 1.1798 - val_accuracy: 0.0000e+00\n",
      "Epoch 443/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0946 - accuracy: 0.0025 - val_loss: 1.2326 - val_accuracy: 0.0000e+00\n",
      "Epoch 444/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0844 - accuracy: 0.0037 - val_loss: 1.2189 - val_accuracy: 0.0000e+00\n",
      "Epoch 445/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0840 - accuracy: 0.0025 - val_loss: 1.1878 - val_accuracy: 0.0000e+00\n",
      "Epoch 446/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0837 - accuracy: 0.0012 - val_loss: 1.1534 - val_accuracy: 0.0000e+00\n",
      "Epoch 447/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0892 - accuracy: 0.0037 - val_loss: 1.1901 - val_accuracy: 0.0000e+00\n",
      "Epoch 448/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0902 - accuracy: 0.0037 - val_loss: 1.2095 - val_accuracy: 0.0000e+00\n",
      "Epoch 449/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0777 - accuracy: 0.0025 - val_loss: 1.1943 - val_accuracy: 0.0000e+00\n",
      "Epoch 450/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0721 - accuracy: 0.0037 - val_loss: 1.2300 - val_accuracy: 0.0000e+00\n",
      "Epoch 451/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0765 - accuracy: 0.0025 - val_loss: 1.2082 - val_accuracy: 0.0000e+00\n",
      "Epoch 452/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0747 - accuracy: 0.0025 - val_loss: 1.2258 - val_accuracy: 0.0000e+00\n",
      "Epoch 453/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0844 - accuracy: 0.0025 - val_loss: 1.1938 - val_accuracy: 0.0000e+00\n",
      "Epoch 454/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0843 - accuracy: 0.0037 - val_loss: 1.2000 - val_accuracy: 0.0000e+00\n",
      "Epoch 455/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0883 - accuracy: 0.0025 - val_loss: 1.1607 - val_accuracy: 0.0000e+00\n",
      "Epoch 456/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0873 - accuracy: 0.0025 - val_loss: 1.2346 - val_accuracy: 0.0000e+00\n",
      "Epoch 457/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0819 - accuracy: 0.0037 - val_loss: 1.2435 - val_accuracy: 0.0000e+00\n",
      "Epoch 458/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0965 - accuracy: 0.0025 - val_loss: 1.2112 - val_accuracy: 0.0000e+00\n",
      "Epoch 459/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0833 - accuracy: 0.0025 - val_loss: 1.1987 - val_accuracy: 0.0000e+00\n",
      "Epoch 460/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0937 - accuracy: 0.0037 - val_loss: 1.1686 - val_accuracy: 0.0000e+00\n",
      "Epoch 461/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0788 - accuracy: 0.0037 - val_loss: 1.2238 - val_accuracy: 0.0000e+00\n",
      "Epoch 462/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0765 - accuracy: 0.0037 - val_loss: 1.2570 - val_accuracy: 0.0000e+00\n",
      "Epoch 463/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0794 - accuracy: 0.0012 - val_loss: 1.2817 - val_accuracy: 0.0000e+00\n",
      "Epoch 464/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0933 - accuracy: 0.0012 - val_loss: 1.2073 - val_accuracy: 0.0000e+00\n",
      "Epoch 465/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0877 - accuracy: 0.0037 - val_loss: 1.1647 - val_accuracy: 0.0000e+00\n",
      "Epoch 466/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0837 - accuracy: 0.0012 - val_loss: 1.1975 - val_accuracy: 0.0000e+00\n",
      "Epoch 467/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.1002 - accuracy: 0.0037 - val_loss: 1.1574 - val_accuracy: 0.0000e+00\n",
      "Epoch 468/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0844 - accuracy: 0.0037 - val_loss: 1.2452 - val_accuracy: 0.0000e+00\n",
      "Epoch 469/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0920 - accuracy: 0.0037 - val_loss: 1.2177 - val_accuracy: 0.0000e+00\n",
      "Epoch 470/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0875 - accuracy: 0.0037 - val_loss: 1.1775 - val_accuracy: 0.0000e+00\n",
      "Epoch 471/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0947 - accuracy: 0.0025 - val_loss: 1.1612 - val_accuracy: 0.0000e+00\n",
      "Epoch 472/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.1015 - accuracy: 0.0037 - val_loss: 1.1984 - val_accuracy: 0.0000e+00\n",
      "Epoch 473/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0938 - accuracy: 0.0025 - val_loss: 1.2110 - val_accuracy: 0.0000e+00\n",
      "Epoch 474/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0712 - accuracy: 0.0012 - val_loss: 1.2001 - val_accuracy: 0.0000e+00\n",
      "Epoch 475/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.1023 - accuracy: 0.0037 - val_loss: 1.2197 - val_accuracy: 0.0000e+00\n",
      "Epoch 476/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0867 - accuracy: 0.0025 - val_loss: 1.1882 - val_accuracy: 0.0000e+00\n",
      "Epoch 477/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0830 - accuracy: 0.0025 - val_loss: 1.1678 - val_accuracy: 0.0000e+00\n",
      "Epoch 478/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0939 - accuracy: 0.0037 - val_loss: 1.1965 - val_accuracy: 0.0000e+00\n",
      "Epoch 479/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0867 - accuracy: 0.0012 - val_loss: 1.1904 - val_accuracy: 0.0000e+00\n",
      "Epoch 480/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0789 - accuracy: 0.0025 - val_loss: 1.2360 - val_accuracy: 0.0000e+00\n",
      "Epoch 481/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0827 - accuracy: 0.0037 - val_loss: 1.1762 - val_accuracy: 0.0000e+00\n",
      "Epoch 482/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0700 - accuracy: 0.0025 - val_loss: 1.2034 - val_accuracy: 0.0000e+00\n",
      "Epoch 483/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0780 - accuracy: 0.0025 - val_loss: 1.2242 - val_accuracy: 0.0000e+00\n",
      "Epoch 484/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0797 - accuracy: 0.0025 - val_loss: 1.1992 - val_accuracy: 0.0000e+00\n",
      "Epoch 485/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0763 - accuracy: 0.0025 - val_loss: 1.1965 - val_accuracy: 0.0000e+00\n",
      "Epoch 486/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0931 - accuracy: 0.0025 - val_loss: 1.2035 - val_accuracy: 0.0000e+00\n",
      "Epoch 487/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.1052 - accuracy: 0.0025 - val_loss: 1.1817 - val_accuracy: 0.0000e+00\n",
      "Epoch 488/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0869 - accuracy: 0.0037 - val_loss: 1.2314 - val_accuracy: 0.0000e+00\n",
      "Epoch 489/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.1042 - accuracy: 0.0012 - val_loss: 1.2358 - val_accuracy: 0.0000e+00\n",
      "Epoch 490/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0916 - accuracy: 0.0037 - val_loss: 1.2061 - val_accuracy: 0.0000e+00\n",
      "Epoch 491/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0899 - accuracy: 0.0037 - val_loss: 1.2619 - val_accuracy: 0.0000e+00\n",
      "Epoch 492/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0946 - accuracy: 0.0037 - val_loss: 1.2231 - val_accuracy: 0.0000e+00\n",
      "Epoch 493/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0992 - accuracy: 0.0037 - val_loss: 1.1796 - val_accuracy: 0.0000e+00\n",
      "Epoch 494/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0876 - accuracy: 0.0012 - val_loss: 1.1925 - val_accuracy: 0.0000e+00\n",
      "Epoch 495/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0952 - accuracy: 0.0037 - val_loss: 1.2112 - val_accuracy: 0.0000e+00\n",
      "Epoch 496/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.1018 - accuracy: 0.0025 - val_loss: 1.2259 - val_accuracy: 0.0000e+00\n",
      "Epoch 497/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0917 - accuracy: 0.0037 - val_loss: 1.1924 - val_accuracy: 0.0000e+00\n",
      "Epoch 498/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0740 - accuracy: 0.0037 - val_loss: 1.1552 - val_accuracy: 0.0000e+00\n",
      "Epoch 499/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0792 - accuracy: 0.0037 - val_loss: 1.1777 - val_accuracy: 0.0000e+00\n",
      "Epoch 500/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0873 - accuracy: 0.0037 - val_loss: 1.1642 - val_accuracy: 0.0000e+00\n",
      "Epoch 501/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0985 - accuracy: 0.0025 - val_loss: 1.2112 - val_accuracy: 0.0000e+00\n",
      "Epoch 502/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.1109 - accuracy: 0.0037 - val_loss: 1.1984 - val_accuracy: 0.0000e+00\n",
      "Epoch 503/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0885 - accuracy: 0.0025 - val_loss: 1.2271 - val_accuracy: 0.0000e+00\n",
      "Epoch 504/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0827 - accuracy: 0.0037 - val_loss: 1.2156 - val_accuracy: 0.0000e+00\n",
      "Epoch 505/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0861 - accuracy: 0.0025 - val_loss: 1.1967 - val_accuracy: 0.0000e+00\n",
      "Epoch 506/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.1005 - accuracy: 0.0037 - val_loss: 1.1867 - val_accuracy: 0.0000e+00\n",
      "Epoch 507/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0992 - accuracy: 0.0037 - val_loss: 1.1953 - val_accuracy: 0.0000e+00\n",
      "Epoch 508/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0788 - accuracy: 0.0037 - val_loss: 1.1658 - val_accuracy: 0.0000e+00\n",
      "Epoch 509/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0816 - accuracy: 0.0025 - val_loss: 1.1560 - val_accuracy: 0.0000e+00\n",
      "Epoch 510/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.1078 - accuracy: 0.0025 - val_loss: 1.1480 - val_accuracy: 0.0000e+00\n",
      "Epoch 511/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0963 - accuracy: 0.0037 - val_loss: 1.1630 - val_accuracy: 0.0000e+00\n",
      "Epoch 512/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.1128 - accuracy: 0.0037 - val_loss: 1.2059 - val_accuracy: 0.0000e+00\n",
      "Epoch 513/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0897 - accuracy: 0.0025 - val_loss: 1.1792 - val_accuracy: 0.0000e+00\n",
      "Epoch 514/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0969 - accuracy: 0.0037 - val_loss: 1.1380 - val_accuracy: 0.0000e+00\n",
      "Epoch 515/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0872 - accuracy: 0.0037 - val_loss: 1.1746 - val_accuracy: 0.0000e+00\n",
      "Epoch 516/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0818 - accuracy: 0.0037 - val_loss: 1.1597 - val_accuracy: 0.0000e+00\n",
      "Epoch 517/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0832 - accuracy: 0.0037 - val_loss: 1.1679 - val_accuracy: 0.0000e+00\n",
      "Epoch 518/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0915 - accuracy: 0.0037 - val_loss: 1.1852 - val_accuracy: 0.0000e+00\n",
      "Epoch 519/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0888 - accuracy: 0.0037 - val_loss: 1.1485 - val_accuracy: 0.0000e+00\n",
      "Epoch 520/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0952 - accuracy: 0.0012 - val_loss: 1.1688 - val_accuracy: 0.0000e+00\n",
      "Epoch 521/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0965 - accuracy: 0.0012 - val_loss: 1.2103 - val_accuracy: 0.0000e+00\n",
      "Epoch 522/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0852 - accuracy: 0.0037 - val_loss: 1.1910 - val_accuracy: 0.0000e+00\n",
      "Epoch 523/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0941 - accuracy: 0.0025 - val_loss: 1.1194 - val_accuracy: 0.0000e+00\n",
      "Epoch 524/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0989 - accuracy: 0.0025 - val_loss: 1.1183 - val_accuracy: 0.0000e+00\n",
      "Epoch 525/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.1170 - accuracy: 0.0037 - val_loss: 1.1512 - val_accuracy: 0.0000e+00\n",
      "Epoch 526/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.1126 - accuracy: 0.0025 - val_loss: 1.1641 - val_accuracy: 0.0000e+00\n",
      "Epoch 527/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.1061 - accuracy: 0.0012 - val_loss: 1.1295 - val_accuracy: 0.0000e+00\n",
      "Epoch 528/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.1035 - accuracy: 0.0037 - val_loss: 1.1475 - val_accuracy: 0.0000e+00\n",
      "Epoch 529/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0919 - accuracy: 0.0037 - val_loss: 1.1717 - val_accuracy: 0.0000e+00\n",
      "Epoch 530/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0917 - accuracy: 0.0025 - val_loss: 1.1561 - val_accuracy: 0.0000e+00\n",
      "Epoch 531/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0876 - accuracy: 0.0025 - val_loss: 1.1094 - val_accuracy: 0.0000e+00\n",
      "Epoch 532/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0936 - accuracy: 0.0037 - val_loss: 1.1419 - val_accuracy: 0.0000e+00\n",
      "Epoch 533/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0878 - accuracy: 0.0037 - val_loss: 1.1255 - val_accuracy: 0.0000e+00\n",
      "Epoch 534/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0904 - accuracy: 0.0037 - val_loss: 1.0971 - val_accuracy: 0.0000e+00\n",
      "Epoch 535/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.1143 - accuracy: 0.0037 - val_loss: 1.1177 - val_accuracy: 0.0000e+00\n",
      "Epoch 536/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.1155 - accuracy: 0.0025 - val_loss: 1.1318 - val_accuracy: 0.0000e+00\n",
      "Epoch 537/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0926 - accuracy: 0.0037 - val_loss: 1.1471 - val_accuracy: 0.0000e+00\n",
      "Epoch 538/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0895 - accuracy: 0.0025 - val_loss: 1.1671 - val_accuracy: 0.0000e+00\n",
      "Epoch 539/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0918 - accuracy: 0.0037 - val_loss: 1.1427 - val_accuracy: 0.0000e+00\n",
      "Epoch 540/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0918 - accuracy: 0.0037 - val_loss: 1.1199 - val_accuracy: 0.0000e+00\n",
      "Epoch 541/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0906 - accuracy: 0.0037 - val_loss: 1.1119 - val_accuracy: 0.0000e+00\n",
      "Epoch 542/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0844 - accuracy: 0.0037 - val_loss: 1.1199 - val_accuracy: 0.0000e+00\n",
      "Epoch 543/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0815 - accuracy: 0.0012 - val_loss: 1.1251 - val_accuracy: 0.0000e+00\n",
      "Epoch 544/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0923 - accuracy: 0.0037 - val_loss: 1.1823 - val_accuracy: 0.0000e+00\n",
      "Epoch 545/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0870 - accuracy: 0.0037 - val_loss: 1.1344 - val_accuracy: 0.0000e+00\n",
      "Epoch 546/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0906 - accuracy: 0.0025 - val_loss: 1.2048 - val_accuracy: 0.0000e+00\n",
      "Epoch 547/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0845 - accuracy: 0.0025 - val_loss: 1.2203 - val_accuracy: 0.0000e+00\n",
      "Epoch 548/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0782 - accuracy: 0.0012 - val_loss: 1.2061 - val_accuracy: 0.0000e+00\n",
      "Epoch 549/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.1007 - accuracy: 0.0037 - val_loss: 1.1442 - val_accuracy: 0.0000e+00\n",
      "Epoch 550/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0839 - accuracy: 0.0037 - val_loss: 1.1844 - val_accuracy: 0.0000e+00\n",
      "Epoch 551/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0781 - accuracy: 0.0012 - val_loss: 1.1816 - val_accuracy: 0.0000e+00\n",
      "Epoch 552/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0907 - accuracy: 0.0025 - val_loss: 1.1938 - val_accuracy: 0.0000e+00\n",
      "Epoch 553/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0929 - accuracy: 0.0025 - val_loss: 1.1846 - val_accuracy: 0.0000e+00\n",
      "Epoch 554/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0796 - accuracy: 0.0025 - val_loss: 1.1821 - val_accuracy: 0.0000e+00\n",
      "Epoch 555/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0799 - accuracy: 0.0012 - val_loss: 1.1936 - val_accuracy: 0.0000e+00\n",
      "Epoch 556/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0775 - accuracy: 0.0025 - val_loss: 1.1875 - val_accuracy: 0.0000e+00\n",
      "Epoch 557/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0825 - accuracy: 0.0025 - val_loss: 1.2012 - val_accuracy: 0.0000e+00\n",
      "Epoch 558/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0695 - accuracy: 0.0025 - val_loss: 1.1827 - val_accuracy: 0.0000e+00\n",
      "Epoch 559/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0764 - accuracy: 0.0025 - val_loss: 1.1889 - val_accuracy: 0.0000e+00\n",
      "Epoch 560/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0718 - accuracy: 0.0037 - val_loss: 1.1861 - val_accuracy: 0.0000e+00\n",
      "Epoch 561/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0860 - accuracy: 0.0025 - val_loss: 1.1937 - val_accuracy: 0.0000e+00\n",
      "Epoch 562/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0713 - accuracy: 0.0025 - val_loss: 1.1572 - val_accuracy: 0.0000e+00\n",
      "Epoch 563/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0678 - accuracy: 0.0012 - val_loss: 1.1916 - val_accuracy: 0.0000e+00\n",
      "Epoch 564/1000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0784 - accuracy: 0.0025 - val_loss: 1.1749 - val_accuracy: 0.0000e+00\n",
      "Epoch 565/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0644 - accuracy: 0.0025 - val_loss: 1.1899 - val_accuracy: 0.0000e+00\n",
      "Epoch 566/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0737 - accuracy: 0.0037 - val_loss: 1.1776 - val_accuracy: 0.0000e+00\n",
      "Epoch 567/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0803 - accuracy: 0.0012 - val_loss: 1.1418 - val_accuracy: 0.0000e+00\n",
      "Epoch 568/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0789 - accuracy: 0.0037 - val_loss: 1.1195 - val_accuracy: 0.0000e+00\n",
      "Epoch 569/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0829 - accuracy: 0.0025 - val_loss: 1.1540 - val_accuracy: 0.0000e+00\n",
      "Epoch 570/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0781 - accuracy: 0.0025 - val_loss: 1.1621 - val_accuracy: 0.0000e+00\n",
      "Epoch 571/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0706 - accuracy: 0.0025 - val_loss: 1.1870 - val_accuracy: 0.0000e+00\n",
      "Epoch 572/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0710 - accuracy: 0.0025 - val_loss: 1.1945 - val_accuracy: 0.0000e+00\n",
      "Epoch 573/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0897 - accuracy: 0.0025 - val_loss: 1.2071 - val_accuracy: 0.0000e+00\n",
      "Epoch 574/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0714 - accuracy: 0.0025 - val_loss: 1.2027 - val_accuracy: 0.0000e+00\n",
      "Epoch 575/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0742 - accuracy: 0.0025 - val_loss: 1.1892 - val_accuracy: 0.0000e+00\n",
      "Epoch 576/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0709 - accuracy: 0.0012 - val_loss: 1.1759 - val_accuracy: 0.0000e+00\n",
      "Epoch 577/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0724 - accuracy: 0.0025 - val_loss: 1.1304 - val_accuracy: 0.0000e+00\n",
      "Epoch 578/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0826 - accuracy: 0.0025 - val_loss: 1.1368 - val_accuracy: 0.0000e+00\n",
      "Epoch 579/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0920 - accuracy: 0.0037 - val_loss: 1.1385 - val_accuracy: 0.0000e+00\n",
      "Epoch 580/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0979 - accuracy: 0.0037 - val_loss: 1.1479 - val_accuracy: 0.0000e+00\n",
      "Epoch 581/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0817 - accuracy: 0.0025 - val_loss: 1.1441 - val_accuracy: 0.0000e+00\n",
      "Epoch 582/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0937 - accuracy: 0.0025 - val_loss: 1.1236 - val_accuracy: 0.0000e+00\n",
      "Epoch 583/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0851 - accuracy: 0.0025 - val_loss: 1.1192 - val_accuracy: 0.0000e+00\n",
      "Epoch 584/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0980 - accuracy: 0.0025 - val_loss: 1.1396 - val_accuracy: 0.0000e+00\n",
      "Epoch 585/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0880 - accuracy: 0.0037 - val_loss: 1.1847 - val_accuracy: 0.0000e+00\n",
      "Epoch 586/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0798 - accuracy: 0.0025 - val_loss: 1.1914 - val_accuracy: 0.0000e+00\n",
      "Epoch 587/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0759 - accuracy: 0.0025 - val_loss: 1.1715 - val_accuracy: 0.0000e+00\n",
      "Epoch 588/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0773 - accuracy: 0.0025 - val_loss: 1.1699 - val_accuracy: 0.0000e+00\n",
      "Epoch 589/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0877 - accuracy: 0.0012 - val_loss: 1.1424 - val_accuracy: 0.0000e+00\n",
      "Epoch 590/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0754 - accuracy: 0.0025 - val_loss: 1.1838 - val_accuracy: 0.0000e+00\n",
      "Epoch 591/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0767 - accuracy: 0.0037 - val_loss: 1.1860 - val_accuracy: 0.0000e+00\n",
      "Epoch 592/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0798 - accuracy: 0.0025 - val_loss: 1.1790 - val_accuracy: 0.0000e+00\n",
      "Epoch 593/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0867 - accuracy: 0.0025 - val_loss: 1.2148 - val_accuracy: 0.0000e+00\n",
      "Epoch 594/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0740 - accuracy: 0.0037 - val_loss: 1.1387 - val_accuracy: 0.0000e+00\n",
      "Epoch 595/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0747 - accuracy: 0.0037 - val_loss: 1.1491 - val_accuracy: 0.0000e+00\n",
      "Epoch 596/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0720 - accuracy: 0.0025 - val_loss: 1.1887 - val_accuracy: 0.0000e+00\n",
      "Epoch 597/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0708 - accuracy: 0.0025 - val_loss: 1.1968 - val_accuracy: 0.0000e+00\n",
      "Epoch 598/1000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0749 - accuracy: 0.0025 - val_loss: 1.1784 - val_accuracy: 0.0000e+00\n",
      "Epoch 599/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0763 - accuracy: 0.0037 - val_loss: 1.1272 - val_accuracy: 0.0000e+00\n",
      "Epoch 600/1000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0938 - accuracy: 0.0037 - val_loss: 1.1687 - val_accuracy: 0.0000e+00\n",
      "Epoch 601/1000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0719 - accuracy: 0.0037 - val_loss: 1.1271 - val_accuracy: 0.0000e+00\n",
      "Epoch 602/1000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0939 - accuracy: 0.0037 - val_loss: 1.1416 - val_accuracy: 0.0000e+00\n",
      "Epoch 603/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0803 - accuracy: 0.0037 - val_loss: 1.1620 - val_accuracy: 0.0000e+00\n",
      "Epoch 604/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0839 - accuracy: 0.0025 - val_loss: 1.1833 - val_accuracy: 0.0000e+00\n",
      "Epoch 605/1000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0745 - accuracy: 0.0025 - val_loss: 1.1506 - val_accuracy: 0.0000e+00\n",
      "Epoch 606/1000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0741 - accuracy: 0.0025 - val_loss: 1.1640 - val_accuracy: 0.0000e+00\n",
      "Epoch 607/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0700 - accuracy: 0.0025 - val_loss: 1.1423 - val_accuracy: 0.0000e+00\n",
      "Epoch 608/1000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0673 - accuracy: 0.0037 - val_loss: 1.1597 - val_accuracy: 0.0000e+00\n",
      "Epoch 609/1000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0852 - accuracy: 0.0012 - val_loss: 1.1534 - val_accuracy: 0.0000e+00\n",
      "Epoch 610/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0711 - accuracy: 0.0025 - val_loss: 1.1554 - val_accuracy: 0.0000e+00\n",
      "Epoch 611/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0784 - accuracy: 0.0025 - val_loss: 1.1588 - val_accuracy: 0.0000e+00\n",
      "Epoch 612/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0794 - accuracy: 0.0012 - val_loss: 1.1448 - val_accuracy: 0.0000e+00\n",
      "Epoch 613/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0726 - accuracy: 0.0037 - val_loss: 1.1623 - val_accuracy: 0.0000e+00\n",
      "Epoch 614/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0817 - accuracy: 0.0037 - val_loss: 1.1369 - val_accuracy: 0.0000e+00\n",
      "Epoch 615/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0783 - accuracy: 0.0012 - val_loss: 1.1221 - val_accuracy: 0.0000e+00\n",
      "Epoch 616/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0767 - accuracy: 0.0012 - val_loss: 1.1432 - val_accuracy: 0.0000e+00\n",
      "Epoch 617/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0835 - accuracy: 0.0025 - val_loss: 1.1410 - val_accuracy: 0.0000e+00\n",
      "Epoch 618/1000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0741 - accuracy: 0.0037 - val_loss: 1.1252 - val_accuracy: 0.0000e+00\n",
      "Epoch 619/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0670 - accuracy: 0.0037 - val_loss: 1.1537 - val_accuracy: 0.0000e+00\n",
      "Epoch 620/1000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0802 - accuracy: 0.0025 - val_loss: 1.1496 - val_accuracy: 0.0000e+00\n",
      "Epoch 621/1000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0858 - accuracy: 0.0037 - val_loss: 1.1462 - val_accuracy: 0.0000e+00\n",
      "Epoch 622/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0696 - accuracy: 0.0037 - val_loss: 1.1608 - val_accuracy: 0.0000e+00\n",
      "Epoch 623/1000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0741 - accuracy: 0.0037 - val_loss: 1.1703 - val_accuracy: 0.0000e+00\n",
      "Epoch 624/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0765 - accuracy: 0.0037 - val_loss: 1.1340 - val_accuracy: 0.0000e+00\n",
      "Epoch 625/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0671 - accuracy: 0.0025 - val_loss: 1.1165 - val_accuracy: 0.0000e+00\n",
      "Epoch 626/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0806 - accuracy: 0.0037 - val_loss: 1.1371 - val_accuracy: 0.0000e+00\n",
      "Epoch 627/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0958 - accuracy: 0.0037 - val_loss: 1.1315 - val_accuracy: 0.0000e+00\n",
      "Epoch 628/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0816 - accuracy: 0.0037 - val_loss: 1.1496 - val_accuracy: 0.0000e+00\n",
      "Epoch 629/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0915 - accuracy: 0.0037 - val_loss: 1.1811 - val_accuracy: 0.0000e+00\n",
      "Epoch 630/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0872 - accuracy: 0.0025 - val_loss: 1.1722 - val_accuracy: 0.0000e+00\n",
      "Epoch 631/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0963 - accuracy: 0.0037 - val_loss: 1.1818 - val_accuracy: 0.0000e+00\n",
      "Epoch 632/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0773 - accuracy: 0.0037 - val_loss: 1.1071 - val_accuracy: 0.0000e+00\n",
      "Epoch 633/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0839 - accuracy: 0.0025 - val_loss: 1.1319 - val_accuracy: 0.0000e+00\n",
      "Epoch 634/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0846 - accuracy: 0.0025 - val_loss: 1.1540 - val_accuracy: 0.0000e+00\n",
      "Epoch 635/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0865 - accuracy: 0.0025 - val_loss: 1.1606 - val_accuracy: 0.0000e+00\n",
      "Epoch 636/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0732 - accuracy: 0.0037 - val_loss: 1.1735 - val_accuracy: 0.0000e+00\n",
      "Epoch 637/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0691 - accuracy: 0.0025 - val_loss: 1.1657 - val_accuracy: 0.0000e+00\n",
      "Epoch 638/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0900 - accuracy: 0.0012 - val_loss: 1.1619 - val_accuracy: 0.0000e+00\n",
      "Epoch 639/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0886 - accuracy: 0.0025 - val_loss: 1.1877 - val_accuracy: 0.0000e+00\n",
      "Epoch 640/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0954 - accuracy: 0.0037 - val_loss: 1.1163 - val_accuracy: 0.0000e+00\n",
      "Epoch 641/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0774 - accuracy: 0.0025 - val_loss: 1.1380 - val_accuracy: 0.0000e+00\n",
      "Epoch 642/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0815 - accuracy: 0.0037 - val_loss: 1.0880 - val_accuracy: 0.0000e+00\n",
      "Epoch 643/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0701 - accuracy: 0.0037 - val_loss: 1.1017 - val_accuracy: 0.0000e+00\n",
      "Epoch 644/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0787 - accuracy: 0.0037 - val_loss: 1.1217 - val_accuracy: 0.0000e+00\n",
      "Epoch 645/1000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0787 - accuracy: 0.0025 - val_loss: 1.2086 - val_accuracy: 0.0000e+00\n",
      "Epoch 646/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0658 - accuracy: 0.0037 - val_loss: 1.1706 - val_accuracy: 0.0000e+00\n",
      "Epoch 647/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0724 - accuracy: 0.0037 - val_loss: 1.1297 - val_accuracy: 0.0000e+00\n",
      "Epoch 648/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0761 - accuracy: 0.0037 - val_loss: 1.1182 - val_accuracy: 0.0000e+00\n",
      "Epoch 649/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0807 - accuracy: 0.0025 - val_loss: 1.1200 - val_accuracy: 0.0000e+00\n",
      "Epoch 650/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0779 - accuracy: 0.0025 - val_loss: 1.1441 - val_accuracy: 0.0000e+00\n",
      "Epoch 651/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0828 - accuracy: 0.0025 - val_loss: 1.1731 - val_accuracy: 0.0000e+00\n",
      "Epoch 652/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0735 - accuracy: 0.0025 - val_loss: 1.1573 - val_accuracy: 0.0000e+00\n",
      "Epoch 653/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0919 - accuracy: 0.0012 - val_loss: 1.1447 - val_accuracy: 0.0000e+00\n",
      "Epoch 654/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0967 - accuracy: 0.0012 - val_loss: 1.1625 - val_accuracy: 0.0000e+00\n",
      "Epoch 655/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0859 - accuracy: 0.0012 - val_loss: 1.1495 - val_accuracy: 0.0000e+00\n",
      "Epoch 656/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0867 - accuracy: 0.0037 - val_loss: 1.1915 - val_accuracy: 0.0000e+00\n",
      "Epoch 657/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0910 - accuracy: 0.0012 - val_loss: 1.1813 - val_accuracy: 0.0000e+00\n",
      "Epoch 658/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0997 - accuracy: 0.0025 - val_loss: 1.1564 - val_accuracy: 0.0000e+00\n",
      "Epoch 659/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.1000 - accuracy: 0.0025 - val_loss: 1.2049 - val_accuracy: 0.0000e+00\n",
      "Epoch 660/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0827 - accuracy: 0.0025 - val_loss: 1.1843 - val_accuracy: 0.0000e+00\n",
      "Epoch 661/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0823 - accuracy: 0.0025 - val_loss: 1.1845 - val_accuracy: 0.0000e+00\n",
      "Epoch 662/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0800 - accuracy: 0.0037 - val_loss: 1.1544 - val_accuracy: 0.0000e+00\n",
      "Epoch 663/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0812 - accuracy: 0.0025 - val_loss: 1.1299 - val_accuracy: 0.0000e+00\n",
      "Epoch 664/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0927 - accuracy: 0.0025 - val_loss: 1.1454 - val_accuracy: 0.0000e+00\n",
      "Epoch 665/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0829 - accuracy: 0.0025 - val_loss: 1.1665 - val_accuracy: 0.0000e+00\n",
      "Epoch 666/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0768 - accuracy: 0.0025 - val_loss: 1.1563 - val_accuracy: 0.0000e+00\n",
      "Epoch 667/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0790 - accuracy: 0.0012 - val_loss: 1.1949 - val_accuracy: 0.0000e+00\n",
      "Epoch 668/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0721 - accuracy: 0.0025 - val_loss: 1.1789 - val_accuracy: 0.0000e+00\n",
      "Epoch 669/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0891 - accuracy: 0.0025 - val_loss: 1.1670 - val_accuracy: 0.0000e+00\n",
      "Epoch 670/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0750 - accuracy: 0.0025 - val_loss: 1.1623 - val_accuracy: 0.0000e+00\n",
      "Epoch 671/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0877 - accuracy: 0.0000e+00 - val_loss: 1.1495 - val_accuracy: 0.0000e+00\n",
      "Epoch 672/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0768 - accuracy: 0.0012 - val_loss: 1.1343 - val_accuracy: 0.0000e+00\n",
      "Epoch 673/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0887 - accuracy: 0.0025 - val_loss: 1.1754 - val_accuracy: 0.0000e+00\n",
      "Epoch 674/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0856 - accuracy: 0.0037 - val_loss: 1.1914 - val_accuracy: 0.0000e+00\n",
      "Epoch 675/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0913 - accuracy: 0.0037 - val_loss: 1.1772 - val_accuracy: 0.0000e+00\n",
      "Epoch 676/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.1005 - accuracy: 0.0012 - val_loss: 1.1453 - val_accuracy: 0.0000e+00\n",
      "Epoch 677/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.1006 - accuracy: 0.0012 - val_loss: 1.1241 - val_accuracy: 0.0000e+00\n",
      "Epoch 678/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0778 - accuracy: 0.0025 - val_loss: 1.1450 - val_accuracy: 0.0000e+00\n",
      "Epoch 679/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.1017 - accuracy: 0.0037 - val_loss: 1.1664 - val_accuracy: 0.0000e+00\n",
      "Epoch 680/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0868 - accuracy: 0.0037 - val_loss: 1.1623 - val_accuracy: 0.0000e+00\n",
      "Epoch 681/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0816 - accuracy: 0.0025 - val_loss: 1.1447 - val_accuracy: 0.0000e+00\n",
      "Epoch 682/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0908 - accuracy: 0.0012 - val_loss: 1.1804 - val_accuracy: 0.0000e+00\n",
      "Epoch 683/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.1020 - accuracy: 0.0025 - val_loss: 1.1617 - val_accuracy: 0.0000e+00\n",
      "Epoch 684/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0785 - accuracy: 0.0025 - val_loss: 1.1777 - val_accuracy: 0.0000e+00\n",
      "Epoch 685/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.1128 - accuracy: 0.0025 - val_loss: 1.1624 - val_accuracy: 0.0000e+00\n",
      "Epoch 686/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0987 - accuracy: 0.0025 - val_loss: 1.1402 - val_accuracy: 0.0000e+00\n",
      "Epoch 687/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.1051 - accuracy: 0.0025 - val_loss: 1.1226 - val_accuracy: 0.0000e+00\n",
      "Epoch 688/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0923 - accuracy: 0.0025 - val_loss: 1.1583 - val_accuracy: 0.0000e+00\n",
      "Epoch 689/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0859 - accuracy: 0.0000e+00 - val_loss: 1.1449 - val_accuracy: 0.0000e+00\n",
      "Epoch 690/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0854 - accuracy: 0.0037 - val_loss: 1.1670 - val_accuracy: 0.0000e+00\n",
      "Epoch 691/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0822 - accuracy: 0.0037 - val_loss: 1.1644 - val_accuracy: 0.0000e+00\n",
      "Epoch 692/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0738 - accuracy: 0.0025 - val_loss: 1.2000 - val_accuracy: 0.0000e+00\n",
      "Epoch 693/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0729 - accuracy: 0.0025 - val_loss: 1.2025 - val_accuracy: 0.0000e+00\n",
      "Epoch 694/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0755 - accuracy: 0.0025 - val_loss: 1.2238 - val_accuracy: 0.0000e+00\n",
      "Epoch 695/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0693 - accuracy: 0.0037 - val_loss: 1.1823 - val_accuracy: 0.0000e+00\n",
      "Epoch 696/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0777 - accuracy: 0.0025 - val_loss: 1.1380 - val_accuracy: 0.0000e+00\n",
      "Epoch 697/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0682 - accuracy: 0.0025 - val_loss: 1.1456 - val_accuracy: 0.0000e+00\n",
      "Epoch 698/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0750 - accuracy: 0.0025 - val_loss: 1.1781 - val_accuracy: 0.0000e+00\n",
      "Epoch 699/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0750 - accuracy: 0.0012 - val_loss: 1.2167 - val_accuracy: 0.0000e+00\n",
      "Epoch 700/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0795 - accuracy: 0.0025 - val_loss: 1.1535 - val_accuracy: 0.0000e+00\n",
      "Epoch 701/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0798 - accuracy: 0.0037 - val_loss: 1.1288 - val_accuracy: 0.0000e+00\n",
      "Epoch 702/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0677 - accuracy: 0.0025 - val_loss: 1.1395 - val_accuracy: 0.0000e+00\n",
      "Epoch 703/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.0692 - accuracy: 0.0025 - val_loss: 1.1592 - val_accuracy: 0.0000e+00\n",
      "Epoch 704/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.0700 - accuracy: 0.0025 - val_loss: 1.1744 - val_accuracy: 0.0000e+00\n",
      "Epoch 705/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0688 - accuracy: 0.0037 - val_loss: 1.1566 - val_accuracy: 0.0000e+00\n",
      "Epoch 706/1000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0781 - accuracy: 0.0025 - val_loss: 1.1615 - val_accuracy: 0.0000e+00\n",
      "Epoch 707/1000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0851 - accuracy: 0.0025 - val_loss: 1.1545 - val_accuracy: 0.0000e+00\n",
      "Epoch 708/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0720 - accuracy: 0.0025 - val_loss: 1.1500 - val_accuracy: 0.0000e+00\n",
      "Epoch 709/1000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0779 - accuracy: 0.0025 - val_loss: 1.1539 - val_accuracy: 0.0000e+00\n",
      "Epoch 710/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0758 - accuracy: 0.0037 - val_loss: 1.1820 - val_accuracy: 0.0000e+00\n",
      "Epoch 711/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0720 - accuracy: 0.0037 - val_loss: 1.1231 - val_accuracy: 0.0000e+00\n",
      "Epoch 712/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0678 - accuracy: 0.0025 - val_loss: 1.1200 - val_accuracy: 0.0000e+00\n",
      "Epoch 713/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0700 - accuracy: 0.0037 - val_loss: 1.1619 - val_accuracy: 0.0000e+00\n",
      "Epoch 714/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0768 - accuracy: 0.0037 - val_loss: 1.1042 - val_accuracy: 0.0000e+00\n",
      "Epoch 715/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0856 - accuracy: 0.0037 - val_loss: 1.1323 - val_accuracy: 0.0000e+00\n",
      "Epoch 716/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0730 - accuracy: 0.0000e+00 - val_loss: 1.1420 - val_accuracy: 0.0000e+00\n",
      "Epoch 717/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0825 - accuracy: 0.0025 - val_loss: 1.1973 - val_accuracy: 0.0000e+00\n",
      "Epoch 718/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0788 - accuracy: 0.0037 - val_loss: 1.1842 - val_accuracy: 0.0000e+00\n",
      "Epoch 719/1000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0786 - accuracy: 0.0025 - val_loss: 1.0890 - val_accuracy: 0.0000e+00\n",
      "Epoch 720/1000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0868 - accuracy: 0.0025 - val_loss: 1.1253 - val_accuracy: 0.0000e+00\n",
      "Epoch 721/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.1028 - accuracy: 0.0012 - val_loss: 1.1436 - val_accuracy: 0.0000e+00\n",
      "Epoch 722/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.0735 - accuracy: 0.0025 - val_loss: 1.1950 - val_accuracy: 0.0000e+00\n",
      "Epoch 723/1000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0888 - accuracy: 0.0025 - val_loss: 1.1861 - val_accuracy: 0.0000e+00\n",
      "Epoch 724/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.0775 - accuracy: 0.0025 - val_loss: 1.1996 - val_accuracy: 0.0000e+00\n",
      "Epoch 725/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0740 - accuracy: 0.0037 - val_loss: 1.1769 - val_accuracy: 0.0000e+00\n",
      "Epoch 726/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0742 - accuracy: 0.0037 - val_loss: 1.1513 - val_accuracy: 0.0000e+00\n",
      "Epoch 727/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0804 - accuracy: 0.0037 - val_loss: 1.1914 - val_accuracy: 0.0000e+00\n",
      "Epoch 728/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0725 - accuracy: 0.0025 - val_loss: 1.1920 - val_accuracy: 0.0000e+00\n",
      "Epoch 729/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0769 - accuracy: 0.0025 - val_loss: 1.1432 - val_accuracy: 0.0000e+00\n",
      "Epoch 730/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0683 - accuracy: 0.0037 - val_loss: 1.1124 - val_accuracy: 0.0000e+00\n",
      "Epoch 731/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0690 - accuracy: 0.0037 - val_loss: 1.1630 - val_accuracy: 0.0000e+00\n",
      "Epoch 732/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0674 - accuracy: 0.0012 - val_loss: 1.1617 - val_accuracy: 0.0000e+00\n",
      "Epoch 733/1000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0704 - accuracy: 0.0025 - val_loss: 1.1465 - val_accuracy: 0.0000e+00\n",
      "Epoch 734/1000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0756 - accuracy: 0.0025 - val_loss: 1.1071 - val_accuracy: 0.0000e+00\n",
      "Epoch 735/1000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0669 - accuracy: 0.0025 - val_loss: 1.1199 - val_accuracy: 0.0000e+00\n",
      "Epoch 736/1000\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 0.0742 - accuracy: 0.0025 - val_loss: 1.1513 - val_accuracy: 0.0000e+00\n",
      "Epoch 737/1000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0608 - accuracy: 0.0037 - val_loss: 1.1475 - val_accuracy: 0.0000e+00\n",
      "Epoch 738/1000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0615 - accuracy: 0.0012 - val_loss: 1.1590 - val_accuracy: 0.0000e+00\n",
      "Epoch 739/1000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0650 - accuracy: 0.0012 - val_loss: 1.1561 - val_accuracy: 0.0000e+00\n",
      "Epoch 740/1000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0714 - accuracy: 0.0025 - val_loss: 1.2103 - val_accuracy: 0.0000e+00\n",
      "Epoch 741/1000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0722 - accuracy: 0.0025 - val_loss: 1.2005 - val_accuracy: 0.0000e+00\n",
      "Epoch 742/1000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0688 - accuracy: 0.0025 - val_loss: 1.1986 - val_accuracy: 0.0000e+00\n",
      "Epoch 743/1000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0641 - accuracy: 0.0037 - val_loss: 1.1349 - val_accuracy: 0.0000e+00\n",
      "Epoch 744/1000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0779 - accuracy: 0.0037 - val_loss: 1.1445 - val_accuracy: 0.0000e+00\n",
      "Epoch 745/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0685 - accuracy: 0.0025 - val_loss: 1.1419 - val_accuracy: 0.0000e+00\n",
      "Epoch 746/1000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0770 - accuracy: 0.0025 - val_loss: 1.1236 - val_accuracy: 0.0000e+00\n",
      "Epoch 747/1000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0640 - accuracy: 0.0025 - val_loss: 1.1446 - val_accuracy: 0.0000e+00\n",
      "Epoch 748/1000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0674 - accuracy: 0.0012 - val_loss: 1.1530 - val_accuracy: 0.0000e+00\n",
      "Epoch 749/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0753 - accuracy: 0.0025 - val_loss: 1.1200 - val_accuracy: 0.0000e+00\n",
      "Epoch 750/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0709 - accuracy: 0.0025 - val_loss: 1.1464 - val_accuracy: 0.0000e+00\n",
      "Epoch 751/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0746 - accuracy: 0.0025 - val_loss: 1.1277 - val_accuracy: 0.0000e+00\n",
      "Epoch 752/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0680 - accuracy: 0.0025 - val_loss: 1.1290 - val_accuracy: 0.0000e+00\n",
      "Epoch 753/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0669 - accuracy: 0.0025 - val_loss: 1.1055 - val_accuracy: 0.0000e+00\n",
      "Epoch 754/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0671 - accuracy: 0.0025 - val_loss: 1.0917 - val_accuracy: 0.0000e+00\n",
      "Epoch 755/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0612 - accuracy: 0.0037 - val_loss: 1.1216 - val_accuracy: 0.0000e+00\n",
      "Epoch 756/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0693 - accuracy: 0.0037 - val_loss: 1.1092 - val_accuracy: 0.0000e+00\n",
      "Epoch 757/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0663 - accuracy: 0.0037 - val_loss: 1.1359 - val_accuracy: 0.0000e+00\n",
      "Epoch 758/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0693 - accuracy: 0.0012 - val_loss: 1.1529 - val_accuracy: 0.0000e+00\n",
      "Epoch 759/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0716 - accuracy: 0.0025 - val_loss: 1.1618 - val_accuracy: 0.0000e+00\n",
      "Epoch 760/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0783 - accuracy: 0.0025 - val_loss: 1.1835 - val_accuracy: 0.0000e+00\n",
      "Epoch 761/1000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0747 - accuracy: 0.0037 - val_loss: 1.1711 - val_accuracy: 0.0000e+00\n",
      "Epoch 762/1000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0636 - accuracy: 0.0037 - val_loss: 1.1494 - val_accuracy: 0.0000e+00\n",
      "Epoch 763/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0772 - accuracy: 0.0037 - val_loss: 1.1402 - val_accuracy: 0.0000e+00\n",
      "Epoch 764/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0786 - accuracy: 0.0037 - val_loss: 1.1704 - val_accuracy: 0.0000e+00\n",
      "Epoch 765/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0775 - accuracy: 0.0025 - val_loss: 1.1324 - val_accuracy: 0.0000e+00\n",
      "Epoch 766/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0775 - accuracy: 0.0037 - val_loss: 1.1833 - val_accuracy: 0.0000e+00\n",
      "Epoch 767/1000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0813 - accuracy: 0.0025 - val_loss: 1.1786 - val_accuracy: 0.0000e+00\n",
      "Epoch 768/1000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0687 - accuracy: 0.0025 - val_loss: 1.1975 - val_accuracy: 0.0000e+00\n",
      "Epoch 769/1000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0645 - accuracy: 0.0012 - val_loss: 1.1423 - val_accuracy: 0.0000e+00\n",
      "Epoch 770/1000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0775 - accuracy: 0.0025 - val_loss: 1.1766 - val_accuracy: 0.0000e+00\n",
      "Epoch 771/1000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0765 - accuracy: 0.0037 - val_loss: 1.1614 - val_accuracy: 0.0000e+00\n",
      "Epoch 772/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0807 - accuracy: 0.0037 - val_loss: 1.1411 - val_accuracy: 0.0000e+00\n",
      "Epoch 773/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0759 - accuracy: 0.0037 - val_loss: 1.1362 - val_accuracy: 0.0000e+00\n",
      "Epoch 774/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0754 - accuracy: 0.0000e+00 - val_loss: 1.1897 - val_accuracy: 0.0000e+00\n",
      "Epoch 775/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0568 - accuracy: 0.0025 - val_loss: 1.2024 - val_accuracy: 0.0000e+00\n",
      "Epoch 776/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0777 - accuracy: 0.0025 - val_loss: 1.1964 - val_accuracy: 0.0000e+00\n",
      "Epoch 777/1000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0783 - accuracy: 0.0025 - val_loss: 1.1731 - val_accuracy: 0.0000e+00\n",
      "Epoch 778/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0798 - accuracy: 0.0037 - val_loss: 1.1387 - val_accuracy: 0.0000e+00\n",
      "Epoch 779/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0736 - accuracy: 0.0037 - val_loss: 1.1274 - val_accuracy: 0.0000e+00\n",
      "Epoch 780/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0715 - accuracy: 0.0025 - val_loss: 1.1666 - val_accuracy: 0.0000e+00\n",
      "Epoch 781/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0850 - accuracy: 0.0037 - val_loss: 1.1939 - val_accuracy: 0.0000e+00\n",
      "Epoch 782/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0661 - accuracy: 0.0025 - val_loss: 1.1602 - val_accuracy: 0.0000e+00\n",
      "Epoch 783/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0716 - accuracy: 0.0025 - val_loss: 1.1298 - val_accuracy: 0.0000e+00\n",
      "Epoch 784/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0787 - accuracy: 0.0012 - val_loss: 1.1566 - val_accuracy: 0.0000e+00\n",
      "Epoch 785/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0805 - accuracy: 0.0025 - val_loss: 1.1228 - val_accuracy: 0.0000e+00\n",
      "Epoch 786/1000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0686 - accuracy: 0.0025 - val_loss: 1.1518 - val_accuracy: 0.0000e+00\n",
      "Epoch 787/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0670 - accuracy: 0.0037 - val_loss: 1.1412 - val_accuracy: 0.0000e+00\n",
      "Epoch 788/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0679 - accuracy: 0.0037 - val_loss: 1.1594 - val_accuracy: 0.0000e+00\n",
      "Epoch 789/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0714 - accuracy: 0.0012 - val_loss: 1.1791 - val_accuracy: 0.0000e+00\n",
      "Epoch 790/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0669 - accuracy: 0.0025 - val_loss: 1.1646 - val_accuracy: 0.0000e+00\n",
      "Epoch 791/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0638 - accuracy: 0.0025 - val_loss: 1.1197 - val_accuracy: 0.0000e+00\n",
      "Epoch 792/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0690 - accuracy: 0.0037 - val_loss: 1.1398 - val_accuracy: 0.0000e+00\n",
      "Epoch 793/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0616 - accuracy: 0.0000e+00 - val_loss: 1.1335 - val_accuracy: 0.0000e+00\n",
      "Epoch 794/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0729 - accuracy: 0.0012 - val_loss: 1.1609 - val_accuracy: 0.0000e+00\n",
      "Epoch 795/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0678 - accuracy: 0.0025 - val_loss: 1.1696 - val_accuracy: 0.0000e+00\n",
      "Epoch 796/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0702 - accuracy: 0.0025 - val_loss: 1.1056 - val_accuracy: 0.0000e+00\n",
      "Epoch 797/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0732 - accuracy: 0.0037 - val_loss: 1.1175 - val_accuracy: 0.0000e+00\n",
      "Epoch 798/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0564 - accuracy: 0.0025 - val_loss: 1.1131 - val_accuracy: 0.0000e+00\n",
      "Epoch 799/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0609 - accuracy: 0.0025 - val_loss: 1.1432 - val_accuracy: 0.0000e+00\n",
      "Epoch 800/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0641 - accuracy: 0.0025 - val_loss: 1.1548 - val_accuracy: 0.0000e+00\n",
      "Epoch 801/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0671 - accuracy: 0.0025 - val_loss: 1.1071 - val_accuracy: 0.0000e+00\n",
      "Epoch 802/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0739 - accuracy: 0.0025 - val_loss: 1.0971 - val_accuracy: 0.0000e+00\n",
      "Epoch 803/1000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0825 - accuracy: 0.0012 - val_loss: 1.1036 - val_accuracy: 0.0000e+00\n",
      "Epoch 804/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0694 - accuracy: 0.0025 - val_loss: 1.1333 - val_accuracy: 0.0000e+00\n",
      "Epoch 805/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0811 - accuracy: 0.0012 - val_loss: 1.1175 - val_accuracy: 0.0000e+00\n",
      "Epoch 806/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0658 - accuracy: 0.0025 - val_loss: 1.1542 - val_accuracy: 0.0000e+00\n",
      "Epoch 807/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0728 - accuracy: 0.0037 - val_loss: 1.0887 - val_accuracy: 0.0000e+00\n",
      "Epoch 808/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0612 - accuracy: 0.0012 - val_loss: 1.1206 - val_accuracy: 0.0000e+00\n",
      "Epoch 809/1000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0698 - accuracy: 0.0012 - val_loss: 1.1023 - val_accuracy: 0.0000e+00\n",
      "Epoch 810/1000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0763 - accuracy: 0.0037 - val_loss: 1.0903 - val_accuracy: 0.0000e+00\n",
      "Epoch 811/1000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0832 - accuracy: 0.0037 - val_loss: 1.0997 - val_accuracy: 0.0000e+00\n",
      "Epoch 812/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0655 - accuracy: 0.0037 - val_loss: 1.1029 - val_accuracy: 0.0000e+00\n",
      "Epoch 813/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0758 - accuracy: 0.0037 - val_loss: 1.1375 - val_accuracy: 0.0000e+00\n",
      "Epoch 814/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0728 - accuracy: 0.0025 - val_loss: 1.1008 - val_accuracy: 0.0000e+00\n",
      "Epoch 815/1000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0613 - accuracy: 0.0037 - val_loss: 1.1147 - val_accuracy: 0.0000e+00\n",
      "Epoch 816/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0715 - accuracy: 0.0037 - val_loss: 1.1748 - val_accuracy: 0.0000e+00\n",
      "Epoch 817/1000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0767 - accuracy: 0.0025 - val_loss: 1.1699 - val_accuracy: 0.0000e+00\n",
      "Epoch 818/1000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0693 - accuracy: 0.0037 - val_loss: 1.1503 - val_accuracy: 0.0000e+00\n",
      "Epoch 819/1000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0755 - accuracy: 0.0037 - val_loss: 1.1490 - val_accuracy: 0.0000e+00\n",
      "Epoch 820/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0718 - accuracy: 0.0025 - val_loss: 1.1452 - val_accuracy: 0.0000e+00\n",
      "Epoch 821/1000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0630 - accuracy: 0.0037 - val_loss: 1.1694 - val_accuracy: 0.0000e+00\n",
      "Epoch 822/1000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0832 - accuracy: 0.0037 - val_loss: 1.1488 - val_accuracy: 0.0000e+00\n",
      "Epoch 823/1000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0675 - accuracy: 0.0025 - val_loss: 1.1398 - val_accuracy: 0.0000e+00\n",
      "Epoch 824/1000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0851 - accuracy: 0.0025 - val_loss: 1.1272 - val_accuracy: 0.0000e+00\n",
      "Epoch 825/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0705 - accuracy: 0.0025 - val_loss: 1.1230 - val_accuracy: 0.0000e+00\n",
      "Epoch 826/1000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0790 - accuracy: 0.0037 - val_loss: 1.1607 - val_accuracy: 0.0000e+00\n",
      "Epoch 827/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0701 - accuracy: 0.0037 - val_loss: 1.2329 - val_accuracy: 0.0000e+00\n",
      "Epoch 828/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0769 - accuracy: 0.0012 - val_loss: 1.1419 - val_accuracy: 0.0000e+00\n",
      "Epoch 829/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0881 - accuracy: 0.0037 - val_loss: 1.1391 - val_accuracy: 0.0000e+00\n",
      "Epoch 830/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0682 - accuracy: 0.0037 - val_loss: 1.1198 - val_accuracy: 0.0000e+00\n",
      "Epoch 831/1000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0841 - accuracy: 0.0037 - val_loss: 1.1404 - val_accuracy: 0.0000e+00\n",
      "Epoch 832/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0613 - accuracy: 0.0037 - val_loss: 1.1775 - val_accuracy: 0.0000e+00\n",
      "Epoch 833/1000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0776 - accuracy: 0.0037 - val_loss: 1.1292 - val_accuracy: 0.0000e+00\n",
      "Epoch 834/1000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.1030 - accuracy: 0.0025 - val_loss: 1.1818 - val_accuracy: 0.0000e+00\n",
      "Epoch 835/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0939 - accuracy: 0.0037 - val_loss: 1.1622 - val_accuracy: 0.0000e+00\n",
      "Epoch 836/1000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0871 - accuracy: 0.0025 - val_loss: 1.1397 - val_accuracy: 0.0000e+00\n",
      "Epoch 837/1000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0751 - accuracy: 0.0037 - val_loss: 1.1536 - val_accuracy: 0.0000e+00\n",
      "Epoch 838/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0672 - accuracy: 0.0025 - val_loss: 1.1457 - val_accuracy: 0.0000e+00\n",
      "Epoch 839/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0735 - accuracy: 0.0025 - val_loss: 1.1820 - val_accuracy: 0.0000e+00\n",
      "Epoch 840/1000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0780 - accuracy: 0.0025 - val_loss: 1.1534 - val_accuracy: 0.0000e+00\n",
      "Epoch 841/1000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0627 - accuracy: 0.0025 - val_loss: 1.1110 - val_accuracy: 0.0000e+00\n",
      "Epoch 842/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0733 - accuracy: 0.0025 - val_loss: 1.1378 - val_accuracy: 0.0000e+00\n",
      "Epoch 843/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0771 - accuracy: 0.0025 - val_loss: 1.1609 - val_accuracy: 0.0000e+00\n",
      "Epoch 844/1000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0781 - accuracy: 0.0025 - val_loss: 1.1430 - val_accuracy: 0.0000e+00\n",
      "Epoch 845/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0860 - accuracy: 0.0012 - val_loss: 1.1846 - val_accuracy: 0.0000e+00\n",
      "Epoch 846/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0686 - accuracy: 0.0037 - val_loss: 1.1921 - val_accuracy: 0.0000e+00\n",
      "Epoch 847/1000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0792 - accuracy: 0.0025 - val_loss: 1.1697 - val_accuracy: 0.0000e+00\n",
      "Epoch 848/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0683 - accuracy: 0.0025 - val_loss: 1.1898 - val_accuracy: 0.0000e+00\n",
      "Epoch 849/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0843 - accuracy: 0.0037 - val_loss: 1.1409 - val_accuracy: 0.0000e+00\n",
      "Epoch 850/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0753 - accuracy: 0.0025 - val_loss: 1.1383 - val_accuracy: 0.0000e+00\n",
      "Epoch 851/1000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0725 - accuracy: 0.0025 - val_loss: 1.1320 - val_accuracy: 0.0000e+00\n",
      "Epoch 852/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0655 - accuracy: 0.0025 - val_loss: 1.1331 - val_accuracy: 0.0000e+00\n",
      "Epoch 853/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0628 - accuracy: 0.0025 - val_loss: 1.1733 - val_accuracy: 0.0000e+00\n",
      "Epoch 854/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0568 - accuracy: 0.0037 - val_loss: 1.1636 - val_accuracy: 0.0000e+00\n",
      "Epoch 855/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0605 - accuracy: 0.0037 - val_loss: 1.1470 - val_accuracy: 0.0000e+00\n",
      "Epoch 856/1000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0702 - accuracy: 0.0025 - val_loss: 1.1680 - val_accuracy: 0.0000e+00\n",
      "Epoch 857/1000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0692 - accuracy: 0.0025 - val_loss: 1.1404 - val_accuracy: 0.0000e+00\n",
      "Epoch 858/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0711 - accuracy: 0.0025 - val_loss: 1.1541 - val_accuracy: 0.0000e+00\n",
      "Epoch 859/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0734 - accuracy: 0.0012 - val_loss: 1.1689 - val_accuracy: 0.0000e+00\n",
      "Epoch 860/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0899 - accuracy: 0.0025 - val_loss: 1.1336 - val_accuracy: 0.0000e+00\n",
      "Epoch 861/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0614 - accuracy: 0.0025 - val_loss: 1.1868 - val_accuracy: 0.0000e+00\n",
      "Epoch 862/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0696 - accuracy: 0.0025 - val_loss: 1.1743 - val_accuracy: 0.0000e+00\n",
      "Epoch 863/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0691 - accuracy: 0.0025 - val_loss: 1.1912 - val_accuracy: 0.0000e+00\n",
      "Epoch 864/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0754 - accuracy: 0.0025 - val_loss: 1.1541 - val_accuracy: 0.0000e+00\n",
      "Epoch 865/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0645 - accuracy: 0.0025 - val_loss: 1.1130 - val_accuracy: 0.0000e+00\n",
      "Epoch 866/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0672 - accuracy: 0.0025 - val_loss: 1.1531 - val_accuracy: 0.0000e+00\n",
      "Epoch 867/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0804 - accuracy: 0.0025 - val_loss: 1.1407 - val_accuracy: 0.0000e+00\n",
      "Epoch 868/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0822 - accuracy: 0.0025 - val_loss: 1.1114 - val_accuracy: 0.0000e+00\n",
      "Epoch 869/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0859 - accuracy: 0.0012 - val_loss: 1.1043 - val_accuracy: 0.0000e+00\n",
      "Epoch 870/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0717 - accuracy: 0.0025 - val_loss: 1.1698 - val_accuracy: 0.0000e+00\n",
      "Epoch 871/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0909 - accuracy: 0.0025 - val_loss: 1.1568 - val_accuracy: 0.0000e+00\n",
      "Epoch 872/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0999 - accuracy: 0.0025 - val_loss: 1.1346 - val_accuracy: 0.0000e+00\n",
      "Epoch 873/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0798 - accuracy: 0.0012 - val_loss: 1.0648 - val_accuracy: 0.0000e+00\n",
      "Epoch 874/1000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0843 - accuracy: 0.0025 - val_loss: 1.0929 - val_accuracy: 0.0000e+00\n",
      "Epoch 875/1000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0780 - accuracy: 0.0025 - val_loss: 1.0866 - val_accuracy: 0.0000e+00\n",
      "Epoch 876/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0912 - accuracy: 0.0037 - val_loss: 1.1189 - val_accuracy: 0.0000e+00\n",
      "Epoch 877/1000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0791 - accuracy: 0.0037 - val_loss: 1.0864 - val_accuracy: 0.0000e+00\n",
      "Epoch 878/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0764 - accuracy: 0.0025 - val_loss: 1.1076 - val_accuracy: 0.0000e+00\n",
      "Epoch 879/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0858 - accuracy: 0.0012 - val_loss: 1.0731 - val_accuracy: 0.0000e+00\n",
      "Epoch 880/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0848 - accuracy: 0.0025 - val_loss: 1.0605 - val_accuracy: 0.0000e+00\n",
      "Epoch 881/1000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0837 - accuracy: 0.0025 - val_loss: 1.0793 - val_accuracy: 0.0000e+00\n",
      "Epoch 882/1000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0641 - accuracy: 0.0025 - val_loss: 1.0779 - val_accuracy: 0.0000e+00\n",
      "Epoch 883/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0849 - accuracy: 0.0037 - val_loss: 1.0894 - val_accuracy: 0.0000e+00\n",
      "Epoch 884/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0834 - accuracy: 0.0037 - val_loss: 1.1087 - val_accuracy: 0.0000e+00\n",
      "Epoch 885/1000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0774 - accuracy: 0.0025 - val_loss: 1.1438 - val_accuracy: 0.0000e+00\n",
      "Epoch 886/1000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0840 - accuracy: 0.0025 - val_loss: 1.1779 - val_accuracy: 0.0000e+00\n",
      "Epoch 887/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0769 - accuracy: 0.0037 - val_loss: 1.1100 - val_accuracy: 0.0000e+00\n",
      "Epoch 888/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0895 - accuracy: 0.0025 - val_loss: 1.0696 - val_accuracy: 0.0000e+00\n",
      "Epoch 889/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0830 - accuracy: 0.0025 - val_loss: 1.1169 - val_accuracy: 0.0000e+00\n",
      "Epoch 890/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0752 - accuracy: 0.0037 - val_loss: 1.1253 - val_accuracy: 0.0000e+00\n",
      "Epoch 891/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0793 - accuracy: 0.0012 - val_loss: 1.1493 - val_accuracy: 0.0000e+00\n",
      "Epoch 892/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0678 - accuracy: 0.0037 - val_loss: 1.1404 - val_accuracy: 0.0000e+00\n",
      "Epoch 893/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0795 - accuracy: 0.0025 - val_loss: 1.1022 - val_accuracy: 0.0000e+00\n",
      "Epoch 894/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0732 - accuracy: 0.0037 - val_loss: 1.1718 - val_accuracy: 0.0000e+00\n",
      "Epoch 895/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0658 - accuracy: 0.0037 - val_loss: 1.1906 - val_accuracy: 0.0000e+00\n",
      "Epoch 896/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0803 - accuracy: 0.0037 - val_loss: 1.1593 - val_accuracy: 0.0000e+00\n",
      "Epoch 897/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0742 - accuracy: 0.0025 - val_loss: 1.1451 - val_accuracy: 0.0000e+00\n",
      "Epoch 898/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0822 - accuracy: 0.0000e+00 - val_loss: 1.0943 - val_accuracy: 0.0000e+00\n",
      "Epoch 899/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0739 - accuracy: 0.0012 - val_loss: 1.1423 - val_accuracy: 0.0000e+00\n",
      "Epoch 900/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0735 - accuracy: 0.0025 - val_loss: 1.0886 - val_accuracy: 0.0000e+00\n",
      "Epoch 901/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0907 - accuracy: 0.0037 - val_loss: 1.1140 - val_accuracy: 0.0000e+00\n",
      "Epoch 902/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0787 - accuracy: 0.0025 - val_loss: 1.1798 - val_accuracy: 0.0000e+00\n",
      "Epoch 903/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0691 - accuracy: 0.0037 - val_loss: 1.1490 - val_accuracy: 0.0000e+00\n",
      "Epoch 904/1000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0786 - accuracy: 0.0037 - val_loss: 1.1574 - val_accuracy: 0.0000e+00\n",
      "Epoch 905/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0617 - accuracy: 0.0012 - val_loss: 1.1406 - val_accuracy: 0.0000e+00\n",
      "Epoch 906/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0817 - accuracy: 0.0025 - val_loss: 1.1414 - val_accuracy: 0.0000e+00\n",
      "Epoch 907/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0732 - accuracy: 0.0037 - val_loss: 1.1251 - val_accuracy: 0.0000e+00\n",
      "Epoch 908/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0918 - accuracy: 0.0025 - val_loss: 1.1673 - val_accuracy: 0.0000e+00\n",
      "Epoch 909/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0658 - accuracy: 0.0037 - val_loss: 1.1437 - val_accuracy: 0.0000e+00\n",
      "Epoch 910/1000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0721 - accuracy: 0.0025 - val_loss: 1.1374 - val_accuracy: 0.0000e+00\n",
      "Epoch 911/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0626 - accuracy: 0.0037 - val_loss: 1.1695 - val_accuracy: 0.0000e+00\n",
      "Epoch 912/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0583 - accuracy: 0.0037 - val_loss: 1.1526 - val_accuracy: 0.0000e+00\n",
      "Epoch 913/1000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0750 - accuracy: 0.0025 - val_loss: 1.1495 - val_accuracy: 0.0000e+00\n",
      "Epoch 914/1000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0701 - accuracy: 0.0037 - val_loss: 1.1287 - val_accuracy: 0.0000e+00\n",
      "Epoch 915/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0612 - accuracy: 0.0037 - val_loss: 1.1111 - val_accuracy: 0.0000e+00\n",
      "Epoch 916/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0635 - accuracy: 0.0012 - val_loss: 1.1676 - val_accuracy: 0.0000e+00\n",
      "Epoch 917/1000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0635 - accuracy: 0.0037 - val_loss: 1.1472 - val_accuracy: 0.0000e+00\n",
      "Epoch 918/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0654 - accuracy: 0.0037 - val_loss: 1.1936 - val_accuracy: 0.0000e+00\n",
      "Epoch 919/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0731 - accuracy: 0.0037 - val_loss: 1.1405 - val_accuracy: 0.0000e+00\n",
      "Epoch 920/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0669 - accuracy: 0.0037 - val_loss: 1.1020 - val_accuracy: 0.0000e+00\n",
      "Epoch 921/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0629 - accuracy: 0.0025 - val_loss: 1.1142 - val_accuracy: 0.0000e+00\n",
      "Epoch 922/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0637 - accuracy: 0.0025 - val_loss: 1.1132 - val_accuracy: 0.0000e+00\n",
      "Epoch 923/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0728 - accuracy: 0.0025 - val_loss: 1.1276 - val_accuracy: 0.0000e+00\n",
      "Epoch 924/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0638 - accuracy: 0.0025 - val_loss: 1.1334 - val_accuracy: 0.0000e+00\n",
      "Epoch 925/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0764 - accuracy: 0.0012 - val_loss: 1.1468 - val_accuracy: 0.0000e+00\n",
      "Epoch 926/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0607 - accuracy: 0.0025 - val_loss: 1.1598 - val_accuracy: 0.0000e+00\n",
      "Epoch 927/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0649 - accuracy: 0.0012 - val_loss: 1.1050 - val_accuracy: 0.0000e+00\n",
      "Epoch 928/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0691 - accuracy: 0.0025 - val_loss: 1.1228 - val_accuracy: 0.0000e+00\n",
      "Epoch 929/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0633 - accuracy: 0.0025 - val_loss: 1.1728 - val_accuracy: 0.0000e+00\n",
      "Epoch 930/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0709 - accuracy: 0.0025 - val_loss: 1.0972 - val_accuracy: 0.0000e+00\n",
      "Epoch 931/1000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0642 - accuracy: 0.0025 - val_loss: 1.1508 - val_accuracy: 0.0000e+00\n",
      "Epoch 932/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0766 - accuracy: 0.0025 - val_loss: 1.1484 - val_accuracy: 0.0000e+00\n",
      "Epoch 933/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0857 - accuracy: 0.0012 - val_loss: 1.1744 - val_accuracy: 0.0000e+00\n",
      "Epoch 934/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0709 - accuracy: 0.0012 - val_loss: 1.1075 - val_accuracy: 0.0000e+00\n",
      "Epoch 935/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0767 - accuracy: 0.0000e+00 - val_loss: 1.1318 - val_accuracy: 0.0000e+00\n",
      "Epoch 936/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0588 - accuracy: 0.0025 - val_loss: 1.1421 - val_accuracy: 0.0000e+00\n",
      "Epoch 937/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0592 - accuracy: 0.0037 - val_loss: 1.1046 - val_accuracy: 0.0000e+00\n",
      "Epoch 938/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0633 - accuracy: 0.0037 - val_loss: 1.1564 - val_accuracy: 0.0000e+00\n",
      "Epoch 939/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0604 - accuracy: 0.0037 - val_loss: 1.1973 - val_accuracy: 0.0000e+00\n",
      "Epoch 940/1000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0635 - accuracy: 0.0037 - val_loss: 1.1364 - val_accuracy: 0.0000e+00\n",
      "Epoch 941/1000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0652 - accuracy: 0.0037 - val_loss: 1.1645 - val_accuracy: 0.0000e+00\n",
      "Epoch 942/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0585 - accuracy: 0.0037 - val_loss: 1.1789 - val_accuracy: 0.0000e+00\n",
      "Epoch 943/1000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0661 - accuracy: 0.0037 - val_loss: 1.1460 - val_accuracy: 0.0000e+00\n",
      "Epoch 944/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0618 - accuracy: 0.0012 - val_loss: 1.0787 - val_accuracy: 0.0000e+00\n",
      "Epoch 945/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0809 - accuracy: 0.0025 - val_loss: 1.1358 - val_accuracy: 0.0000e+00\n",
      "Epoch 946/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0656 - accuracy: 0.0012 - val_loss: 1.1703 - val_accuracy: 0.0000e+00\n",
      "Epoch 947/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0716 - accuracy: 0.0025 - val_loss: 1.1531 - val_accuracy: 0.0000e+00\n",
      "Epoch 948/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0611 - accuracy: 0.0025 - val_loss: 1.1226 - val_accuracy: 0.0000e+00\n",
      "Epoch 949/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0679 - accuracy: 0.0025 - val_loss: 1.1412 - val_accuracy: 0.0000e+00\n",
      "Epoch 950/1000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0588 - accuracy: 0.0025 - val_loss: 1.1250 - val_accuracy: 0.0000e+00\n",
      "Epoch 951/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0856 - accuracy: 0.0025 - val_loss: 1.1575 - val_accuracy: 0.0000e+00\n",
      "Epoch 952/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0802 - accuracy: 0.0012 - val_loss: 1.1442 - val_accuracy: 0.0000e+00\n",
      "Epoch 953/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0615 - accuracy: 0.0025 - val_loss: 1.1677 - val_accuracy: 0.0000e+00\n",
      "Epoch 954/1000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0651 - accuracy: 0.0025 - val_loss: 1.1376 - val_accuracy: 0.0000e+00\n",
      "Epoch 955/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0614 - accuracy: 0.0025 - val_loss: 1.1381 - val_accuracy: 0.0000e+00\n",
      "Epoch 956/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0671 - accuracy: 0.0012 - val_loss: 1.1469 - val_accuracy: 0.0000e+00\n",
      "Epoch 957/1000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0576 - accuracy: 0.0025 - val_loss: 1.1205 - val_accuracy: 0.0000e+00\n",
      "Epoch 958/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0595 - accuracy: 0.0025 - val_loss: 1.1198 - val_accuracy: 0.0000e+00\n",
      "Epoch 959/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0589 - accuracy: 0.0037 - val_loss: 1.1532 - val_accuracy: 0.0000e+00\n",
      "Epoch 960/1000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0647 - accuracy: 0.0037 - val_loss: 1.1027 - val_accuracy: 0.0000e+00\n",
      "Epoch 961/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0792 - accuracy: 0.0037 - val_loss: 1.1136 - val_accuracy: 0.0000e+00\n",
      "Epoch 962/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0654 - accuracy: 0.0037 - val_loss: 1.1517 - val_accuracy: 0.0000e+00\n",
      "Epoch 963/1000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0594 - accuracy: 0.0025 - val_loss: 1.1169 - val_accuracy: 0.0000e+00\n",
      "Epoch 964/1000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0744 - accuracy: 0.0037 - val_loss: 1.0816 - val_accuracy: 0.0000e+00\n",
      "Epoch 965/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0601 - accuracy: 0.0025 - val_loss: 1.1272 - val_accuracy: 0.0000e+00\n",
      "Epoch 966/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0602 - accuracy: 0.0025 - val_loss: 1.1266 - val_accuracy: 0.0000e+00\n",
      "Epoch 967/1000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0734 - accuracy: 0.0037 - val_loss: 1.0965 - val_accuracy: 0.0000e+00\n",
      "Epoch 968/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0843 - accuracy: 0.0037 - val_loss: 1.1100 - val_accuracy: 0.0000e+00\n",
      "Epoch 969/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0576 - accuracy: 0.0025 - val_loss: 1.1380 - val_accuracy: 0.0000e+00\n",
      "Epoch 970/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0792 - accuracy: 0.0025 - val_loss: 1.1345 - val_accuracy: 0.0000e+00\n",
      "Epoch 971/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0677 - accuracy: 0.0025 - val_loss: 1.0833 - val_accuracy: 0.0000e+00\n",
      "Epoch 972/1000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0639 - accuracy: 0.0037 - val_loss: 1.1155 - val_accuracy: 0.0000e+00\n",
      "Epoch 973/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0694 - accuracy: 0.0037 - val_loss: 1.1415 - val_accuracy: 0.0000e+00\n",
      "Epoch 974/1000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0605 - accuracy: 0.0025 - val_loss: 1.1654 - val_accuracy: 0.0000e+00\n",
      "Epoch 975/1000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0687 - accuracy: 0.0025 - val_loss: 1.1472 - val_accuracy: 0.0000e+00\n",
      "Epoch 976/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0606 - accuracy: 0.0037 - val_loss: 1.1333 - val_accuracy: 0.0000e+00\n",
      "Epoch 977/1000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0611 - accuracy: 0.0037 - val_loss: 1.1470 - val_accuracy: 0.0000e+00\n",
      "Epoch 978/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0597 - accuracy: 0.0037 - val_loss: 1.1499 - val_accuracy: 0.0000e+00\n",
      "Epoch 979/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0678 - accuracy: 0.0037 - val_loss: 1.1633 - val_accuracy: 0.0000e+00\n",
      "Epoch 980/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0570 - accuracy: 0.0037 - val_loss: 1.1559 - val_accuracy: 0.0000e+00\n",
      "Epoch 981/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0681 - accuracy: 0.0025 - val_loss: 1.1093 - val_accuracy: 0.0000e+00\n",
      "Epoch 982/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0683 - accuracy: 0.0025 - val_loss: 1.1428 - val_accuracy: 0.0000e+00\n",
      "Epoch 983/1000\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0687 - accuracy: 0.0037 - val_loss: 1.1372 - val_accuracy: 0.0000e+00\n",
      "Epoch 984/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0694 - accuracy: 0.0037 - val_loss: 1.1371 - val_accuracy: 0.0000e+00\n",
      "Epoch 985/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0659 - accuracy: 0.0025 - val_loss: 1.1489 - val_accuracy: 0.0000e+00\n",
      "Epoch 986/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0699 - accuracy: 0.0025 - val_loss: 1.1398 - val_accuracy: 0.0000e+00\n",
      "Epoch 987/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0571 - accuracy: 0.0012 - val_loss: 1.1431 - val_accuracy: 0.0000e+00\n",
      "Epoch 988/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0866 - accuracy: 0.0025 - val_loss: 1.1666 - val_accuracy: 0.0000e+00\n",
      "Epoch 989/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0636 - accuracy: 0.0037 - val_loss: 1.1355 - val_accuracy: 0.0000e+00\n",
      "Epoch 990/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0707 - accuracy: 0.0012 - val_loss: 1.1822 - val_accuracy: 0.0000e+00\n",
      "Epoch 991/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0557 - accuracy: 0.0025 - val_loss: 1.1328 - val_accuracy: 0.0000e+00\n",
      "Epoch 992/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0676 - accuracy: 0.0037 - val_loss: 1.1674 - val_accuracy: 0.0000e+00\n",
      "Epoch 993/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0502 - accuracy: 0.0037 - val_loss: 1.1465 - val_accuracy: 0.0000e+00\n",
      "Epoch 994/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0746 - accuracy: 0.0037 - val_loss: 1.1723 - val_accuracy: 0.0000e+00\n",
      "Epoch 995/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0691 - accuracy: 0.0037 - val_loss: 1.1680 - val_accuracy: 0.0000e+00\n",
      "Epoch 996/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0624 - accuracy: 0.0037 - val_loss: 1.1382 - val_accuracy: 0.0000e+00\n",
      "Epoch 997/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0830 - accuracy: 0.0025 - val_loss: 1.1563 - val_accuracy: 0.0000e+00\n",
      "Epoch 998/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0612 - accuracy: 0.0025 - val_loss: 1.1752 - val_accuracy: 0.0000e+00\n",
      "Epoch 999/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0702 - accuracy: 0.0037 - val_loss: 1.1400 - val_accuracy: 0.0000e+00\n",
      "Epoch 1000/1000\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0602 - accuracy: 0.0037 - val_loss: 1.1706 - val_accuracy: 0.0000e+00\n"
     ]
    }
   ],
   "source": [
    "# loss function\n",
    "msle = MeanSquaredLogarithmicError()\n",
    "model.compile(\n",
    "    loss=msle, \n",
    "    optimizer=Adam(learning_rate=learning_rate), \n",
    "    metrics=['accuracy']\n",
    ")\n",
    "# train the model\n",
    "history = model.fit(\n",
    "    X_train_CT, \n",
    "    y_train, \n",
    "    epochs=1000, \n",
    "    batch_size=64,\n",
    "    validation_split=0.2\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (learn-env)",
   "language": "python",
   "name": "learn-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
